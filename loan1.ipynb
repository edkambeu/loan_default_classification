{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/edkambeu/loan_default_classification/blob/main/loan1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qq1WBdYLCZ3A"
      },
      "outputs": [],
      "source": [
        "#Loading tensorflow \n",
        "import tensorflow as tf \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2BPAmVfDP3-",
        "outputId": "703e083e-8fa4-4179-b5ba-e04dd5b78ce4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.12.0\n"
          ]
        }
      ],
      "source": [
        "#Checking tensorflow version \n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CrxaQ7mpEEdU"
      },
      "outputs": [],
      "source": [
        "#Importing required libraries \n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import MinMaxScaler \n",
        "from sklearn.compose import make_column_transformer\n",
        "from sklearn import metrics \n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NAejGHDzPuwT"
      },
      "outputs": [],
      "source": [
        "#Loading data\n",
        "data = pd.read_csv(\"as1-bank.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vq6Jo0qFQLO7",
        "outputId": "7c86a22b-dffd-4cf8-8306-a7858ae23779"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of rows : 7842\n",
            "Number of columns : 14\n"
          ]
        }
      ],
      "source": [
        "#Shape of the data\n",
        "print('Number of rows :',data.shape[0])\n",
        "print('Number of columns :', data.shape[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "id": "FqcmLABgTFm0",
        "outputId": "b14c7cc6-f744-46d9-ea33-304bb7f26b91"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   age  marital  education default  balance housing loan  contact  duration  \\\n",
              "0   33        1          2      no      882      no   no        1        39   \n",
              "1   42        0          1      no     -247     yes  yes        1       519   \n",
              "2   33        1          1      no     3444     yes   no        1       144   \n",
              "3   36        1          2      no     2415     yes   no        1        73   \n",
              "4   36        1          2      no        0     yes   no        1       140   \n",
              "\n",
              "   campaign  pdays  previous  poutcome    y  \n",
              "0         1    151         3         0   no  \n",
              "1         1    166         1         2  yes  \n",
              "2         1     91         4         0  yes  \n",
              "3         1     86         4         2   no  \n",
              "4         1    143         3         0  yes  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-55ea988b-fc8d-45f7-95ef-5724e2e4d5f9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>marital</th>\n",
              "      <th>education</th>\n",
              "      <th>default</th>\n",
              "      <th>balance</th>\n",
              "      <th>housing</th>\n",
              "      <th>loan</th>\n",
              "      <th>contact</th>\n",
              "      <th>duration</th>\n",
              "      <th>campaign</th>\n",
              "      <th>pdays</th>\n",
              "      <th>previous</th>\n",
              "      <th>poutcome</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>no</td>\n",
              "      <td>882</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>1</td>\n",
              "      <td>39</td>\n",
              "      <td>1</td>\n",
              "      <td>151</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>42</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>no</td>\n",
              "      <td>-247</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>1</td>\n",
              "      <td>519</td>\n",
              "      <td>1</td>\n",
              "      <td>166</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>no</td>\n",
              "      <td>3444</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>1</td>\n",
              "      <td>144</td>\n",
              "      <td>1</td>\n",
              "      <td>91</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>36</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>no</td>\n",
              "      <td>2415</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>1</td>\n",
              "      <td>73</td>\n",
              "      <td>1</td>\n",
              "      <td>86</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>36</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>no</td>\n",
              "      <td>0</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>1</td>\n",
              "      <td>140</td>\n",
              "      <td>1</td>\n",
              "      <td>143</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-55ea988b-fc8d-45f7-95ef-5724e2e4d5f9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-55ea988b-fc8d-45f7-95ef-5724e2e4d5f9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-55ea988b-fc8d-45f7-95ef-5724e2e4d5f9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "#View the data \n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "WnxT2A05fdJL",
        "outputId": "1683c31a-3a35-4ded-815e-c921b6a01a99"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               age      marital    education       balance      contact  \\\n",
              "count  7842.000000  7842.000000  7842.000000   7842.000000  7842.000000   \n",
              "mean     40.783856     0.800179     1.206707   1552.343280     0.074598   \n",
              "std      11.282964     0.621418     0.649716   3084.580003     0.262759   \n",
              "min      18.000000     0.000000     0.000000  -1884.000000     0.000000   \n",
              "25%      32.000000     0.000000     1.000000    162.000000     0.000000   \n",
              "50%      38.000000     1.000000     1.000000    595.000000     0.000000   \n",
              "75%      47.000000     1.000000     2.000000   1733.750000     0.000000   \n",
              "max      89.000000     2.000000     2.000000  81204.000000     1.000000   \n",
              "\n",
              "          duration     campaign        pdays     previous     poutcome  \n",
              "count  7842.000000  7842.000000  7842.000000  7842.000000  7842.000000  \n",
              "mean    261.290615     2.064269   223.252869     3.184264     0.626498  \n",
              "std     236.203272     1.566109   111.830127     4.614190     0.824863  \n",
              "min       5.000000     1.000000     1.000000     1.000000     0.000000  \n",
              "25%     113.000000     1.000000   133.000000     1.000000     0.000000  \n",
              "50%     194.000000     2.000000   195.000000     2.000000     0.000000  \n",
              "75%     324.000000     2.000000   326.000000     4.000000     1.000000  \n",
              "max    2219.000000    16.000000   871.000000   275.000000     2.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bf9a4488-dcb8-4cef-828c-2d25b852adef\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>marital</th>\n",
              "      <th>education</th>\n",
              "      <th>balance</th>\n",
              "      <th>contact</th>\n",
              "      <th>duration</th>\n",
              "      <th>campaign</th>\n",
              "      <th>pdays</th>\n",
              "      <th>previous</th>\n",
              "      <th>poutcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>7842.000000</td>\n",
              "      <td>7842.000000</td>\n",
              "      <td>7842.000000</td>\n",
              "      <td>7842.000000</td>\n",
              "      <td>7842.000000</td>\n",
              "      <td>7842.000000</td>\n",
              "      <td>7842.000000</td>\n",
              "      <td>7842.000000</td>\n",
              "      <td>7842.000000</td>\n",
              "      <td>7842.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>40.783856</td>\n",
              "      <td>0.800179</td>\n",
              "      <td>1.206707</td>\n",
              "      <td>1552.343280</td>\n",
              "      <td>0.074598</td>\n",
              "      <td>261.290615</td>\n",
              "      <td>2.064269</td>\n",
              "      <td>223.252869</td>\n",
              "      <td>3.184264</td>\n",
              "      <td>0.626498</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>11.282964</td>\n",
              "      <td>0.621418</td>\n",
              "      <td>0.649716</td>\n",
              "      <td>3084.580003</td>\n",
              "      <td>0.262759</td>\n",
              "      <td>236.203272</td>\n",
              "      <td>1.566109</td>\n",
              "      <td>111.830127</td>\n",
              "      <td>4.614190</td>\n",
              "      <td>0.824863</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>18.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-1884.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>32.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>162.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>113.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>133.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>38.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>595.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>194.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>195.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>47.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1733.750000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>324.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>326.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>89.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>81204.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2219.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>871.000000</td>\n",
              "      <td>275.000000</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bf9a4488-dcb8-4cef-828c-2d25b852adef')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bf9a4488-dcb8-4cef-828c-2d25b852adef button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bf9a4488-dcb8-4cef-828c-2d25b852adef');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "#Describe the data \n",
        "data.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mpyqov-Uf2tt",
        "outputId": "f0f70c98-0ada-4bd8-f118-489248dd0913"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "age           int64\n",
            "marital       int64\n",
            "education     int64\n",
            "default      object\n",
            "balance       int64\n",
            "housing      object\n",
            "loan         object\n",
            "contact       int64\n",
            "duration      int64\n",
            "campaign      int64\n",
            "pdays         int64\n",
            "previous      int64\n",
            "poutcome      int64\n",
            "y            object\n",
            "dtype: object\n"
          ]
        }
      ],
      "source": [
        "#Check data types\n",
        "print(data.dtypes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mBnJOFV1g8gt",
        "outputId": "629c34ae-a932-4f74-880d-e56094cc7e48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "age          0\n",
            "marital      0\n",
            "education    0\n",
            "default      0\n",
            "balance      0\n",
            "housing      0\n",
            "loan         0\n",
            "contact      0\n",
            "duration     0\n",
            "campaign     0\n",
            "pdays        0\n",
            "previous     0\n",
            "poutcome     0\n",
            "y            0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "#Check for any missing values \n",
        "print(data.isna().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6uULqQdnjcWj",
        "outputId": "5535bccc-1918-4bf6-9c85-415575efc3dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['default', 'housing', 'loan', 'y'], dtype='object')\n",
            "Index(['age', 'marital', 'education', 'balance', 'contact', 'duration',\n",
            "       'campaign', 'pdays', 'previous', 'poutcome'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "#Extracting categorical features \n",
        "cat_columns = data.select_dtypes(include=['object']).columns\n",
        "print(cat_columns)\n",
        "#Extracting numerical features \n",
        "num_columns = data.select_dtypes(exclude =['object']).columns\n",
        "print(num_columns)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lgrNW5HLtnIl",
        "outputId": "6f384af1-ee39-4fcd-c540-de2970f65671"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "default ['no' 'yes']\n",
            "housing ['no' 'yes']\n",
            "loan ['no' 'yes']\n",
            "y ['no' 'yes']\n"
          ]
        }
      ],
      "source": [
        "#Checking unique values of categorical columns \n",
        "for col in cat_columns:\n",
        "  print(col, data[col].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mQKYNk2rgN7m",
        "outputId": "8f183c7e-f9e6-47ed-fca8-cd0cabbb32d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Proportion of yes labels(%) : 22.77480234634022\n",
            "Proportion of no labels(%) : 77.22519765365978\n",
            "6056\n",
            "7842\n"
          ]
        }
      ],
      "source": [
        "#Proportion of yes  and no labels in the target feature \n",
        "total_yes = len(data[data['y'] == 'yes'])\n",
        "total_no = len(data[data['y'] == 'no'])\n",
        "total_yes_no = total_yes + total_no\n",
        "prop_yes = total_yes / total_yes_no * 100\n",
        "prop_no = total_no / total_yes_no * 100\n",
        "prop_yes = len(data[data['y'] == 'yes'])/len(data) * 100\n",
        "prop_no = len(data[data['y'] == 'no'])/ len(data) * 100 \n",
        "print('Proportion of yes labels(%) :', prop_yes)\n",
        "print('Proportion of no labels(%) :', prop_no)\n",
        "print(total_no)\n",
        "print(total_yes_no)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 569
        },
        "id": "6iVnHml-W6Do",
        "outputId": "eced94bb-0608-46c7-e46d-f49f3faf11a7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'whiskers': [<matplotlib.lines.Line2D at 0x7f9b2b58f0a0>,\n",
              "  <matplotlib.lines.Line2D at 0x7f9b2b58f340>],\n",
              " 'caps': [<matplotlib.lines.Line2D at 0x7f9b2b58f5e0>,\n",
              "  <matplotlib.lines.Line2D at 0x7f9b2b58f880>],\n",
              " 'boxes': [<matplotlib.lines.Line2D at 0x7f9b2b5e2ca0>],\n",
              " 'medians': [<matplotlib.lines.Line2D at 0x7f9b2b58fb20>],\n",
              " 'fliers': [<matplotlib.lines.Line2D at 0x7f9b2b58fdc0>],\n",
              " 'means': []}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "#Check for outliers(plot box plots)\n",
        "#plt.boxplot(data['age'])\n",
        "plt.boxplot(data['poutcome'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "38CyjSxxveEl"
      },
      "outputs": [],
      "source": [
        "#Split data into features and target \n",
        "X = data.drop(['y'], axis = 1)\n",
        "y = data['y']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IRQ8J2bbzNfT",
        "outputId": "820b13e8-79d7-4772-98cc-58e39e0f9972"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(6273, 13) (1569, 13) (6273,) (1569,)\n"
          ]
        }
      ],
      "source": [
        "#Split data into train and test \n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.80, random_state = 1)\n",
        "print( X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "8K8uNvO1B76q",
        "outputId": "67fd0fec-92b5-400c-9016-df21d5e1e405"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     default housing loan\n",
              "6248      no      no   no\n",
              "6102      no      no   no\n",
              "179       no     yes   no\n",
              "2418      no     yes   no\n",
              "4814      no     yes   no"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2da7d1ba-4c05-4c8e-a54e-4ba7051e0f46\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>default</th>\n",
              "      <th>housing</th>\n",
              "      <th>loan</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6248</th>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6102</th>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>179</th>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2418</th>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4814</th>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2da7d1ba-4c05-4c8e-a54e-4ba7051e0f46')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2da7d1ba-4c05-4c8e-a54e-4ba7051e0f46 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2da7d1ba-4c05-4c8e-a54e-4ba7051e0f46');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "cat_features = ['default', 'housing', 'loan']\n",
        "X_train[cat_features].head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "IUhe3y25VF3v",
        "outputId": "4a671c1c-d107-46dc-fdab-912f933a319e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   onehotencoder__default_no  onehotencoder__default_yes  \\\n",
              "0                        1.0                         0.0   \n",
              "1                        1.0                         0.0   \n",
              "2                        1.0                         0.0   \n",
              "3                        1.0                         0.0   \n",
              "4                        1.0                         0.0   \n",
              "\n",
              "   onehotencoder__housing_no  onehotencoder__housing_yes  \\\n",
              "0                        0.0                         1.0   \n",
              "1                        0.0                         1.0   \n",
              "2                        0.0                         1.0   \n",
              "3                        1.0                         0.0   \n",
              "4                        1.0                         0.0   \n",
              "\n",
              "   onehotencoder__loan_no  onehotencoder__loan_yes  minmaxscaler__age  \\\n",
              "0                     1.0                      0.0           0.098592   \n",
              "1                     1.0                      0.0           0.112676   \n",
              "2                     0.0                      1.0           0.549296   \n",
              "3                     1.0                      0.0           0.154930   \n",
              "4                     0.0                      1.0           0.507042   \n",
              "\n",
              "   minmaxscaler__marital  minmaxscaler__education  minmaxscaler__balance  \\\n",
              "0                    0.0                      0.5               0.018210   \n",
              "1                    0.0                      1.0               0.032640   \n",
              "2                    1.0                      0.5               0.023601   \n",
              "3                    0.0                      1.0               0.022903   \n",
              "4                    0.5                      1.0               0.036263   \n",
              "\n",
              "   minmaxscaler__contact  minmaxscaler__duration  minmaxscaler__campaign  \\\n",
              "0                    0.0                0.065168                0.066667   \n",
              "1                    0.0                0.069298                0.000000   \n",
              "2                    0.0                0.074805                0.133333   \n",
              "3                    0.0                0.120698                0.000000   \n",
              "4                    0.0                0.108765                0.000000   \n",
              "\n",
              "   minmaxscaler__pdays  minmaxscaler__previous  minmaxscaler__poutcome  \n",
              "0             0.419394                0.035088                     1.0  \n",
              "1             0.240000                0.000000                     0.0  \n",
              "2             0.296970                0.017544                     0.0  \n",
              "3             0.105455                0.052632                     0.5  \n",
              "4             0.221818                0.122807                     0.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a62b4fbc-59b4-416e-be4b-d8e3b0cf6733\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>onehotencoder__default_no</th>\n",
              "      <th>onehotencoder__default_yes</th>\n",
              "      <th>onehotencoder__housing_no</th>\n",
              "      <th>onehotencoder__housing_yes</th>\n",
              "      <th>onehotencoder__loan_no</th>\n",
              "      <th>onehotencoder__loan_yes</th>\n",
              "      <th>minmaxscaler__age</th>\n",
              "      <th>minmaxscaler__marital</th>\n",
              "      <th>minmaxscaler__education</th>\n",
              "      <th>minmaxscaler__balance</th>\n",
              "      <th>minmaxscaler__contact</th>\n",
              "      <th>minmaxscaler__duration</th>\n",
              "      <th>minmaxscaler__campaign</th>\n",
              "      <th>minmaxscaler__pdays</th>\n",
              "      <th>minmaxscaler__previous</th>\n",
              "      <th>minmaxscaler__poutcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.098592</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.018210</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.065168</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.419394</td>\n",
              "      <td>0.035088</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.112676</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.032640</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.069298</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.240000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.549296</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.023601</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.074805</td>\n",
              "      <td>0.133333</td>\n",
              "      <td>0.296970</td>\n",
              "      <td>0.017544</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.154930</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.022903</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.120698</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.105455</td>\n",
              "      <td>0.052632</td>\n",
              "      <td>0.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.507042</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.036263</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.108765</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.221818</td>\n",
              "      <td>0.122807</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a62b4fbc-59b4-416e-be4b-d8e3b0cf6733')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a62b4fbc-59b4-416e-be4b-d8e3b0cf6733 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a62b4fbc-59b4-416e-be4b-d8e3b0cf6733');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "\n",
        "#Encoding categorical features\n",
        "features_transformer = make_column_transformer([OneHotEncoder(),cat_features],\n",
        "                                              [MinMaxScaler(), num_columns])\n",
        "\n",
        "X_train_transformed = features_transformer.fit_transform(X_train)\n",
        "X_train_transformed_df = pd.DataFrame(X_train_transformed, columns = features_transformer.get_feature_names_out())\n",
        "#X_train_transformed_df.head()\n",
        "X_test_transformed = features_transformer. transform(X_test)\n",
        "X_test_transformed_df = pd.DataFrame(X_test_transformed, columns = features_transformer.get_feature_names_out())\n",
        "X_test_transformed_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "31pHW4GAYCTD"
      },
      "outputs": [],
      "source": [
        "#Encoding the the target feature \n",
        "label_encoder = LabelEncoder()\n",
        "y_train_transformed = label_encoder.fit_transform(y_train)\n",
        "y_train_transformed_df = pd.DataFrame(y_train_transformed,columns = ['y'] )\n",
        "#y_train_transformed_df.head()\n",
        "y_test_transformed = label_encoder.transform(y_test)\n",
        "y_test_transformed_df = pd.DataFrame(y_test_transformed, columns = ['y'])\n",
        "#y_test_transformed_df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vMoUQEEdpwMO"
      },
      "outputs": [],
      "source": [
        "#Build the baseline model \n",
        "input_shape = len(X_train_transformed_df.columns)\n",
        "model = keras.Sequential([layers.Dense(units = 24, input_shape = [input_shape] , activation = 'relu'),\n",
        "                        layers.Dropout(rate = 0.5),\n",
        "                        layers.Dense(units =16, activation = 'relu'),\n",
        "                        layers.Dropout(rate = 0.5),\n",
        "                        layers.Dense(units = 1, activation = 'sigmoid')])\n",
        "#Compile the baseline model\n",
        "model.compile(optimizer = 'Adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9epwX_SvC6IO",
        "outputId": "cda9a513-eaf0-4f0c-8f9f-f0a92affadb8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "2/2 [==============================] - 2s 270ms/step - loss: 0.6575 - accuracy: 0.6347 - val_loss: 0.6080 - val_accuracy: 0.7394\n",
            "Epoch 2/50\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.6399 - accuracy: 0.6532 - val_loss: 0.5992 - val_accuracy: 0.7506\n",
            "Epoch 3/50\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.6275 - accuracy: 0.6696 - val_loss: 0.5910 - val_accuracy: 0.7554\n",
            "Epoch 4/50\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.6212 - accuracy: 0.6861 - val_loss: 0.5836 - val_accuracy: 0.7562\n",
            "Epoch 5/50\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.6169 - accuracy: 0.6885 - val_loss: 0.5769 - val_accuracy: 0.7554\n",
            "Epoch 6/50\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.6064 - accuracy: 0.7011 - val_loss: 0.5709 - val_accuracy: 0.7554\n",
            "Epoch 7/50\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.5954 - accuracy: 0.7166 - val_loss: 0.5651 - val_accuracy: 0.7546\n",
            "Epoch 8/50\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.5852 - accuracy: 0.7260 - val_loss: 0.5595 - val_accuracy: 0.7546\n",
            "Epoch 9/50\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.5855 - accuracy: 0.7296 - val_loss: 0.5541 - val_accuracy: 0.7546\n",
            "Epoch 10/50\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.5802 - accuracy: 0.7383 - val_loss: 0.5492 - val_accuracy: 0.7546\n",
            "Epoch 11/50\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.5785 - accuracy: 0.7371 - val_loss: 0.5446 - val_accuracy: 0.7546\n",
            "Epoch 12/50\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.5687 - accuracy: 0.7489 - val_loss: 0.5405 - val_accuracy: 0.7546\n",
            "Epoch 13/50\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.5648 - accuracy: 0.7533 - val_loss: 0.5367 - val_accuracy: 0.7546\n",
            "Epoch 14/50\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.5607 - accuracy: 0.7571 - val_loss: 0.5333 - val_accuracy: 0.7546\n",
            "Epoch 15/50\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.5594 - accuracy: 0.7559 - val_loss: 0.5303 - val_accuracy: 0.7546\n",
            "Epoch 16/50\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.5602 - accuracy: 0.7523 - val_loss: 0.5276 - val_accuracy: 0.7546\n",
            "Epoch 17/50\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.5440 - accuracy: 0.7631 - val_loss: 0.5251 - val_accuracy: 0.7546\n",
            "Epoch 18/50\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.5521 - accuracy: 0.7607 - val_loss: 0.5227 - val_accuracy: 0.7546\n",
            "Epoch 19/50\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 0.5520 - accuracy: 0.7658 - val_loss: 0.5204 - val_accuracy: 0.7546\n",
            "Epoch 20/50\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.5556 - accuracy: 0.7615 - val_loss: 0.5184 - val_accuracy: 0.7546\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6329f5cf10>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "#Fit the baseline model\n",
        "early_stopping = keras.callbacks.EarlyStopping(monitor = 'loss', patience = 3) \n",
        "model.fit(X_train_transformed_df, y_train_transformed_df,\n",
        "          validation_split = 0.20,\n",
        "          epochs  = 50,\n",
        "          batch_size = 100,\n",
        "          callbacks = [early_stopping]\n",
        "          )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "rzpJ2YYAPO95",
        "outputId": "eaf47ad4-915e-4bbc-aa0a-8151b50d9f02"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       loss  accuracy  val_loss  val_accuracy\n",
              "0  0.657494  0.634715  0.608035      0.739442\n",
              "1  0.639922  0.653248  0.599162      0.750598\n",
              "2  0.627549  0.669589  0.591011      0.755378\n",
              "3  0.621164  0.686130  0.583634      0.756175\n",
              "4  0.616888  0.688521  0.576920      0.755378"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4f3b25ee-29ec-4fed-8f5d-ef260dbf5a6e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.657494</td>\n",
              "      <td>0.634715</td>\n",
              "      <td>0.608035</td>\n",
              "      <td>0.739442</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.639922</td>\n",
              "      <td>0.653248</td>\n",
              "      <td>0.599162</td>\n",
              "      <td>0.750598</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.627549</td>\n",
              "      <td>0.669589</td>\n",
              "      <td>0.591011</td>\n",
              "      <td>0.755378</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.621164</td>\n",
              "      <td>0.686130</td>\n",
              "      <td>0.583634</td>\n",
              "      <td>0.756175</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.616888</td>\n",
              "      <td>0.688521</td>\n",
              "      <td>0.576920</td>\n",
              "      <td>0.755378</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4f3b25ee-29ec-4fed-8f5d-ef260dbf5a6e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4f3b25ee-29ec-4fed-8f5d-ef260dbf5a6e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4f3b25ee-29ec-4fed-8f5d-ef260dbf5a6e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "history_df = pd.DataFrame(model.history.history)\n",
        "history_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "-lk1jzeIPpII",
        "outputId": "8af82bc6-89aa-4485-cd36-d16bc45e0cc8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "metadata": {},
          "execution_count": 28
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "history_df.loc[0: , ['loss', 'val_loss']].plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EwliX36cThen",
        "outputId": "a6b8f950-51b1-4237-e6dd-1cefdeb81706"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50/50 [==============================] - 0s 3ms/step - loss: 0.5116 - accuracy: 0.7693\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.51164311170578, 0.7692797780036926]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "model.evaluate(X_test_transformed_df, y_test_transformed_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ejt5lG4w8SWX",
        "outputId": "a7e93c88-6f96-419e-d99c-34ebcf5913ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50/50 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1569"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "#Making predictions \n",
        "y_predictions = np.argmax(model.predict(X_test_transformed_df), axis =1)\n",
        "len(y_predictions)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        },
        "id": "YMwx3GruA0r2",
        "outputId": "be231b93-e404-44f3-e97b-5737d2e24d89"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "from sklearn.metrics._plot.confusion_matrix import confusion_matrix\n",
        "#Confusion matrix\n",
        "confusion_matrix = confusion_matrix(y_test_transformed_df, y_predictions)\n",
        "confusion_matrix_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix)\n",
        "confusion_matrix_display.plot()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXJjKvaQERWb",
        "outputId": "c564df5b-80f6-4a97-a6a1-35d591828f9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy score : 0.7692797960484385\n",
            "Precision score : 0.0\n",
            "Sensitivity score : 0.0\n",
            "Specificity score : 1.0\n",
            "F1 score : 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "accuracy_score = metrics.accuracy_score(y_test_transformed_df, y_predictions)\n",
        "precision_score = metrics.precision_score(y_test_transformed_df, y_predictions)\n",
        "sensitivity = metrics .recall_score(y_test_transformed_df, y_predictions, pos_label = 1)\n",
        "specificity= metrics .recall_score(y_test_transformed_df, y_predictions, pos_label = 0)\n",
        "f1_score = metrics.f1_score(y_test_transformed_df, y_predictions)\n",
        "print('Accuracy score :', accuracy_score)\n",
        "print('Precision score :', precision_score)\n",
        "print('Sensitivity score :', sensitivity)\n",
        "print('Specificity score :', specificity)\n",
        "print('F1 score :', f1_score)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0LKkebsjFh-T",
        "outputId": "d7df4668-64fb-4bf1-82b8-1f3244f821ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "51/51 [==============================] - 2s 7ms/step - loss: 0.5403 - accuracy: 0.7752 - val_loss: 0.5438 - val_accuracy: 0.7546\n",
            "Epoch 2/500\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.5179 - accuracy: 0.7776 - val_loss: 0.5272 - val_accuracy: 0.7546\n",
            "Epoch 3/500\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.5039 - accuracy: 0.7776 - val_loss: 0.5121 - val_accuracy: 0.7546\n",
            "Epoch 4/500\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.4886 - accuracy: 0.7786 - val_loss: 0.4948 - val_accuracy: 0.7546\n",
            "Epoch 5/500\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.4776 - accuracy: 0.7810 - val_loss: 0.4841 - val_accuracy: 0.7546\n",
            "Epoch 6/500\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.4710 - accuracy: 0.7806 - val_loss: 0.4791 - val_accuracy: 0.7546\n",
            "Epoch 7/500\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.4699 - accuracy: 0.7804 - val_loss: 0.4746 - val_accuracy: 0.7538\n",
            "Epoch 8/500\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.4628 - accuracy: 0.7792 - val_loss: 0.4690 - val_accuracy: 0.7538\n",
            "Epoch 9/500\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.4601 - accuracy: 0.7804 - val_loss: 0.4627 - val_accuracy: 0.7546\n",
            "Epoch 10/500\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.4510 - accuracy: 0.7842 - val_loss: 0.4562 - val_accuracy: 0.7554\n",
            "Epoch 11/500\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.4486 - accuracy: 0.7832 - val_loss: 0.4506 - val_accuracy: 0.7538\n",
            "Epoch 12/500\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.4492 - accuracy: 0.7864 - val_loss: 0.4470 - val_accuracy: 0.7554\n",
            "Epoch 13/500\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.4450 - accuracy: 0.7878 - val_loss: 0.4415 - val_accuracy: 0.7562\n",
            "Epoch 14/500\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.4377 - accuracy: 0.7943 - val_loss: 0.4360 - val_accuracy: 0.7570\n",
            "Epoch 15/500\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.4383 - accuracy: 0.7872 - val_loss: 0.4343 - val_accuracy: 0.7594\n",
            "Epoch 16/500\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.4300 - accuracy: 0.7949 - val_loss: 0.4246 - val_accuracy: 0.7681\n",
            "Epoch 17/500\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.4286 - accuracy: 0.7925 - val_loss: 0.4226 - val_accuracy: 0.7673\n",
            "Epoch 18/500\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.4232 - accuracy: 0.7939 - val_loss: 0.4202 - val_accuracy: 0.7681\n",
            "Epoch 19/500\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.4262 - accuracy: 0.7993 - val_loss: 0.4147 - val_accuracy: 0.7817\n",
            "Epoch 20/500\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.4149 - accuracy: 0.7961 - val_loss: 0.4099 - val_accuracy: 0.8024\n",
            "Epoch 21/500\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.4188 - accuracy: 0.7949 - val_loss: 0.4117 - val_accuracy: 0.7833\n",
            "Epoch 22/500\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.4093 - accuracy: 0.8051 - val_loss: 0.4067 - val_accuracy: 0.8024\n",
            "Epoch 23/500\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.4119 - accuracy: 0.8039 - val_loss: 0.4063 - val_accuracy: 0.7992\n",
            "Epoch 24/500\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.4109 - accuracy: 0.8033 - val_loss: 0.4037 - val_accuracy: 0.8064\n",
            "Epoch 25/500\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.4061 - accuracy: 0.8083 - val_loss: 0.4031 - val_accuracy: 0.8056\n",
            "Epoch 26/500\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.4024 - accuracy: 0.8065 - val_loss: 0.4025 - val_accuracy: 0.8048\n",
            "Epoch 27/500\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.4071 - accuracy: 0.8045 - val_loss: 0.3997 - val_accuracy: 0.8104\n",
            "Epoch 28/500\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.4023 - accuracy: 0.8055 - val_loss: 0.3994 - val_accuracy: 0.8072\n",
            "Epoch 29/500\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.4024 - accuracy: 0.8059 - val_loss: 0.3992 - val_accuracy: 0.8088\n",
            "Epoch 30/500\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.4060 - accuracy: 0.8035 - val_loss: 0.4011 - val_accuracy: 0.8056\n",
            "Epoch 31/500\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.3990 - accuracy: 0.8103 - val_loss: 0.3965 - val_accuracy: 0.8112\n",
            "Epoch 32/500\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.4001 - accuracy: 0.8047 - val_loss: 0.3937 - val_accuracy: 0.8127\n",
            "Epoch 33/500\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.3991 - accuracy: 0.8063 - val_loss: 0.3941 - val_accuracy: 0.8127\n",
            "Epoch 34/500\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.3940 - accuracy: 0.8131 - val_loss: 0.3922 - val_accuracy: 0.8135\n",
            "Epoch 35/500\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.3977 - accuracy: 0.8107 - val_loss: 0.3907 - val_accuracy: 0.8135\n",
            "Epoch 36/500\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.3931 - accuracy: 0.8105 - val_loss: 0.3908 - val_accuracy: 0.8143\n",
            "Epoch 37/500\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.3935 - accuracy: 0.8123 - val_loss: 0.3904 - val_accuracy: 0.8112\n",
            "Epoch 38/500\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.3940 - accuracy: 0.8107 - val_loss: 0.3883 - val_accuracy: 0.8143\n",
            "Epoch 39/500\n",
            "51/51 [==============================] - 0s 3ms/step - loss: 0.3933 - accuracy: 0.8089 - val_loss: 0.3932 - val_accuracy: 0.8104\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.3859 - accuracy: 0.8184\n",
            "50/50 [==============================] - 0s 1ms/step\n",
            "Accuracy score : 0.7692797960484385\n",
            "Precision score : 0.0\n",
            "Sensitivity score : 0.0\n",
            "Specificity score : 1.0\n",
            "F1 score : 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "#Setting initial and output bias \n",
        "initial_bias = np.log([prop_yes/prop_no])\n",
        "#output_bias = keras.initializers.Constant(initial_bias) \n",
        "#Build the model\n",
        "input_shape = len(X_train_transformed_df.columns)\n",
        "model2 = keras.Sequential([layers.Dense(units = 24, input_shape = [input_shape] , activation = 'relu'),\n",
        "                        layers.Dropout(rate = 0.5),\n",
        "                        layers.Dense(units =16, activation = 'relu'),\n",
        "                        layers.Dropout(rate = 0.5),\n",
        "                        layers.Dense(units = 1, activation = 'sigmoid', bias_initializer = keras.initializers.Constant(initial_bias))])\n",
        "#Compile the model\n",
        "model2.compile(optimizer = 'Adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "#Fit the the model \n",
        "early_stopping = keras.callbacks.EarlyStopping(monitor = 'loss', patience = 3) \n",
        "model2.fit(X_train_transformed_df, y_train_transformed_df,\n",
        "          validation_split = 0.20,\n",
        "          epochs  = 500,\n",
        "          batch_size = 100,\n",
        "          callbacks = [early_stopping]\n",
        "          )\n",
        "#Evaluate the model\n",
        "model2.evaluate(X_test_transformed_df, y_test_transformed_df) \n",
        "y_predictions2 = np.argmax(model2.predict(X_test_transformed_df), axis =1)\n",
        "accuracy_score = metrics.accuracy_score(y_test_transformed_df, y_predictions2)\n",
        "precision_score = metrics.precision_score(y_test_transformed_df, y_predictions2)\n",
        "sensitivity = metrics .recall_score(y_test_transformed_df, y_predictions2, pos_label = 1)\n",
        "specificity= metrics .recall_score(y_test_transformed_df, y_predictions2, pos_label = 0)\n",
        "f1_score = metrics.f1_score(y_test_transformed_df, y_predictions2)\n",
        "print('Accuracy score :', accuracy_score)\n",
        "print('Precision score :', precision_score)\n",
        "print('Sensitivity score :', sensitivity)\n",
        "print('Specificity score :', specificity)\n",
        "print('F1 score :', f1_score)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dt9NO48fU5J8",
        "outputId": "df02c1bf-eb89-47ad-ec14-80ffa60153a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: 0.6474570673712021, 1: 2.1954087346024638}\n"
          ]
        }
      ],
      "source": [
        "#Using class weights \n",
        "weight_for_no = (1 / total_no) * (total_yes_no/2.0) \n",
        "weight_for_yes = (1 / total_yes) * (total_yes_no/ 2.0)\n",
        "class_weight = {0: weight_for_no, 1: weight_for_yes}\n",
        "print(class_weight)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rDnbGYwoZ-5f",
        "outputId": "5e5ff82d-bfde-4e0f-8648-18ecf76b4899"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "2/2 [==============================] - 1s 257ms/step - loss: 1.0032 - accuracy: 0.7770 - val_loss: 0.5696 - val_accuracy: 0.7546\n",
            "Epoch 2/500\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 1.0142 - accuracy: 0.7760 - val_loss: 0.5665 - val_accuracy: 0.7546\n",
            "Epoch 3/500\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.9676 - accuracy: 0.7782 - val_loss: 0.5638 - val_accuracy: 0.7546\n",
            "Epoch 4/500\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.9605 - accuracy: 0.7754 - val_loss: 0.5613 - val_accuracy: 0.7546\n",
            "Epoch 5/500\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.9443 - accuracy: 0.7740 - val_loss: 0.5592 - val_accuracy: 0.7546\n",
            "Epoch 6/500\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.9280 - accuracy: 0.7736 - val_loss: 0.5572 - val_accuracy: 0.7546\n",
            "Epoch 7/500\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.9087 - accuracy: 0.7724 - val_loss: 0.5556 - val_accuracy: 0.7546\n",
            "Epoch 8/500\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.8935 - accuracy: 0.7716 - val_loss: 0.5542 - val_accuracy: 0.7546\n",
            "Epoch 9/500\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.8931 - accuracy: 0.7712 - val_loss: 0.5530 - val_accuracy: 0.7546\n",
            "Epoch 10/500\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.8655 - accuracy: 0.7714 - val_loss: 0.5522 - val_accuracy: 0.7546\n",
            "Epoch 11/500\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.8625 - accuracy: 0.7686 - val_loss: 0.5518 - val_accuracy: 0.7546\n",
            "Epoch 12/500\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.8489 - accuracy: 0.7656 - val_loss: 0.5517 - val_accuracy: 0.7546\n",
            "Epoch 13/500\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.8364 - accuracy: 0.7639 - val_loss: 0.5520 - val_accuracy: 0.7546\n",
            "Epoch 14/500\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 0.8255 - accuracy: 0.7639 - val_loss: 0.5524 - val_accuracy: 0.7546\n",
            "Epoch 15/500\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.8166 - accuracy: 0.7629 - val_loss: 0.5532 - val_accuracy: 0.7546\n",
            "Epoch 16/500\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.8082 - accuracy: 0.7555 - val_loss: 0.5541 - val_accuracy: 0.7546\n",
            "Epoch 17/500\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.7981 - accuracy: 0.7525 - val_loss: 0.5554 - val_accuracy: 0.7546\n",
            "Epoch 18/500\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.7896 - accuracy: 0.7459 - val_loss: 0.5567 - val_accuracy: 0.7546\n",
            "Epoch 19/500\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.7769 - accuracy: 0.7457 - val_loss: 0.5583 - val_accuracy: 0.7546\n",
            "Epoch 20/500\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.7723 - accuracy: 0.7379 - val_loss: 0.5599 - val_accuracy: 0.7546\n",
            "Epoch 21/500\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.7656 - accuracy: 0.7338 - val_loss: 0.5616 - val_accuracy: 0.7546\n",
            "Epoch 22/500\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.7598 - accuracy: 0.7232 - val_loss: 0.5632 - val_accuracy: 0.7546\n",
            "Epoch 23/500\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.7446 - accuracy: 0.7304 - val_loss: 0.5647 - val_accuracy: 0.7546\n",
            "Epoch 24/500\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.7391 - accuracy: 0.7246 - val_loss: 0.5663 - val_accuracy: 0.7554\n",
            "Epoch 25/500\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.7427 - accuracy: 0.7236 - val_loss: 0.5677 - val_accuracy: 0.7538\n",
            "Epoch 26/500\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.7408 - accuracy: 0.7172 - val_loss: 0.5689 - val_accuracy: 0.7458\n",
            "Epoch 27/500\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.7438 - accuracy: 0.7150 - val_loss: 0.5698 - val_accuracy: 0.7402\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 0.5626 - accuracy: 0.7623\n",
            "50/50 [==============================] - 0s 1ms/step\n",
            "Accuracy score : 0.7692797960484385\n",
            "Precision score : 0.0\n",
            "Sensitivity score : 0.0\n",
            "Specificity score : 1.0\n",
            "F1 score : 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "##Intial bias + Class weights\n",
        "initial_bias = np.log([prop_yes/prop_no])\n",
        "#output_bias = keras.initializers.Constant(initial_bias) \n",
        "#Build the model\n",
        "input_shape = len(X_train_transformed_df.columns)\n",
        "model3 = keras.Sequential([layers.Dense(units = 24, input_shape = [input_shape] , activation = 'relu'),\n",
        "                        layers.Dropout(rate = 0.5),\n",
        "                        layers.Dense(units =16, activation = 'relu'),\n",
        "                        layers.Dropout(rate = 0.5),\n",
        "                        layers.Dense(units = 1, activation = 'sigmoid', bias_initializer = keras.initializers.Constant(initial_bias))])\n",
        "#Compile the model\n",
        "model3.compile(optimizer = 'Adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "#Fit the the model \n",
        "early_stopping = keras.callbacks.EarlyStopping(monitor = 'loss', patience = 3) \n",
        "model3.fit(X_train_transformed_df, y_train_transformed_df,\n",
        "          validation_split = 0.20,\n",
        "          epochs  = 500,\n",
        "          batch_size = 4000,\n",
        "          callbacks = [early_stopping],\n",
        "           class_weight = class_weight #Resetting class weight \n",
        "          )\n",
        "#Evaluate the model\n",
        "model3.evaluate(X_test_transformed_df, y_test_transformed_df) \n",
        "#Make predictions \n",
        "y_predictions3 = np.argmax(model3.predict(X_test_transformed_df), axis =1)\n",
        "accuracy_score = metrics.accuracy_score(y_test_transformed_df, y_predictions3)\n",
        "precision_score = metrics.precision_score(y_test_transformed_df, y_predictions3)\n",
        "sensitivity = metrics .recall_score(y_test_transformed_df, y_predictions3, pos_label = 1)\n",
        "specificity= metrics .recall_score(y_test_transformed_df, y_predictions3, pos_label = 0)\n",
        "f1_score = metrics.f1_score(y_test_transformed_df, y_predictions3)\n",
        "print('Accuracy score :', accuracy_score)\n",
        "print('Precision score :', precision_score)\n",
        "print('Sensitivity score :', sensitivity)\n",
        "print('Specificity score :', specificity)\n",
        "print('F1 score :', f1_score)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oTi6WJOMiI6j",
        "outputId": "46f054ee-902e-4392-f034-59306b230210"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: imbalanced_learn in /usr/local/lib/python3.9/dist-packages (0.10.1)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.9/dist-packages (from imbalanced_learn) (1.22.4)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from imbalanced_learn) (3.1.0)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.9/dist-packages (from imbalanced_learn) (1.2.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from imbalanced_learn) (1.1.1)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.9/dist-packages (from imbalanced_learn) (1.10.1)\n"
          ]
        }
      ],
      "source": [
        "#Resample the data \n",
        "#Install the library \n",
        "%pip install imbalanced_learn \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ca8DuGJbkVBP",
        "outputId": "25cce04a-83ca-4901-a3e4-d8635a652dd9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.10.1\n"
          ]
        }
      ],
      "source": [
        "#Check the version \n",
        "import imblearn\n",
        "print(imblearn.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jtje7GDolqGG"
      },
      "outputs": [],
      "source": [
        "#Define oversampling strategy \n",
        "from imblearn.over_sampling import SMOTE\n",
        "sm = SMOTE(random_state = 0) \n",
        "X_train_resampled_df, y_train_resampled_df = sm.fit_resample(X_train_transformed_df, y_train_transformed_df) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l5hE16FsoKTz",
        "outputId": "e58da9c4-e20a-4068-8c0e-15245b2b88f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4849\n",
            "4849\n"
          ]
        }
      ],
      "source": [
        "#Check the new dataset\n",
        "#print(X_train_transformed_df.shape)\n",
        "#print(X_train_resampled_df.shape)\n",
        "total_1 = len(y_train_resampled_df[y_train_resampled_df['y'] == 1])\n",
        "total_0 = len(y_train_resampled_df[y_train_resampled_df['y'] == 0])\n",
        "print(total_1)\n",
        "print(total_0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z6CgRlNOpNvH",
        "outputId": "1d7cfd67-98c0-4e53-ab44-c3ec9de54140"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "78/78 [==============================] - 4s 11ms/step - loss: 0.7186 - accuracy: 0.6218 - val_loss: 1.1358 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/500\n",
            "78/78 [==============================] - 1s 8ms/step - loss: 0.6560 - accuracy: 0.6364 - val_loss: 1.0244 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/500\n",
            "78/78 [==============================] - 0s 5ms/step - loss: 0.6305 - accuracy: 0.6516 - val_loss: 0.9685 - val_accuracy: 0.0567\n",
            "Epoch 4/500\n",
            "78/78 [==============================] - 1s 8ms/step - loss: 0.6150 - accuracy: 0.6625 - val_loss: 0.9203 - val_accuracy: 0.3552\n",
            "Epoch 5/500\n",
            "78/78 [==============================] - 0s 6ms/step - loss: 0.6027 - accuracy: 0.6758 - val_loss: 0.8928 - val_accuracy: 0.4021\n",
            "Epoch 6/500\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.5872 - accuracy: 0.6806 - val_loss: 0.9116 - val_accuracy: 0.4072\n",
            "Epoch 7/500\n",
            "78/78 [==============================] - 1s 6ms/step - loss: 0.5889 - accuracy: 0.6820 - val_loss: 0.8807 - val_accuracy: 0.4809\n",
            "Epoch 8/500\n",
            "78/78 [==============================] - 1s 8ms/step - loss: 0.5742 - accuracy: 0.6933 - val_loss: 0.8537 - val_accuracy: 0.5247\n",
            "Epoch 9/500\n",
            "78/78 [==============================] - 1s 11ms/step - loss: 0.5694 - accuracy: 0.6958 - val_loss: 0.8566 - val_accuracy: 0.4804\n",
            "Epoch 10/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.5565 - accuracy: 0.7093 - val_loss: 0.8123 - val_accuracy: 0.5521\n",
            "Epoch 11/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.5581 - accuracy: 0.7007 - val_loss: 0.7471 - val_accuracy: 0.6247\n",
            "Epoch 12/500\n",
            "78/78 [==============================] - 1s 11ms/step - loss: 0.5418 - accuracy: 0.7218 - val_loss: 0.7858 - val_accuracy: 0.5856\n",
            "Epoch 13/500\n",
            "78/78 [==============================] - 0s 6ms/step - loss: 0.5345 - accuracy: 0.7175 - val_loss: 0.7219 - val_accuracy: 0.6335\n",
            "Epoch 14/500\n",
            "78/78 [==============================] - 0s 6ms/step - loss: 0.5275 - accuracy: 0.7300 - val_loss: 0.7492 - val_accuracy: 0.6299\n",
            "Epoch 15/500\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.5253 - accuracy: 0.7279 - val_loss: 0.7306 - val_accuracy: 0.6531\n",
            "Epoch 16/500\n",
            "78/78 [==============================] - 0s 5ms/step - loss: 0.5172 - accuracy: 0.7372 - val_loss: 0.7061 - val_accuracy: 0.6784\n",
            "Epoch 17/500\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.5196 - accuracy: 0.7354 - val_loss: 0.7209 - val_accuracy: 0.6644\n",
            "Epoch 18/500\n",
            "78/78 [==============================] - 0s 5ms/step - loss: 0.5103 - accuracy: 0.7493 - val_loss: 0.7070 - val_accuracy: 0.6778\n",
            "Epoch 19/500\n",
            "78/78 [==============================] - 1s 8ms/step - loss: 0.5018 - accuracy: 0.7493 - val_loss: 0.6785 - val_accuracy: 0.7139\n",
            "Epoch 20/500\n",
            "78/78 [==============================] - 1s 6ms/step - loss: 0.5054 - accuracy: 0.7476 - val_loss: 0.6929 - val_accuracy: 0.7103\n",
            "Epoch 21/500\n",
            "78/78 [==============================] - 0s 6ms/step - loss: 0.4989 - accuracy: 0.7535 - val_loss: 0.6040 - val_accuracy: 0.7907\n",
            "Epoch 22/500\n",
            "78/78 [==============================] - 1s 8ms/step - loss: 0.4934 - accuracy: 0.7586 - val_loss: 0.7104 - val_accuracy: 0.7026\n",
            "Epoch 23/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4991 - accuracy: 0.7526 - val_loss: 0.6008 - val_accuracy: 0.7840\n",
            "Epoch 24/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4888 - accuracy: 0.7574 - val_loss: 0.6600 - val_accuracy: 0.7474\n",
            "Epoch 25/500\n",
            "78/78 [==============================] - 1s 8ms/step - loss: 0.4990 - accuracy: 0.7568 - val_loss: 0.6299 - val_accuracy: 0.7680\n",
            "Epoch 26/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4950 - accuracy: 0.7539 - val_loss: 0.6314 - val_accuracy: 0.7814\n",
            "Epoch 27/500\n",
            "78/78 [==============================] - 1s 7ms/step - loss: 0.4843 - accuracy: 0.7617 - val_loss: 0.6351 - val_accuracy: 0.7856\n",
            "Epoch 28/500\n",
            "78/78 [==============================] - 1s 13ms/step - loss: 0.4882 - accuracy: 0.7631 - val_loss: 0.7179 - val_accuracy: 0.7005\n",
            "Epoch 29/500\n",
            "78/78 [==============================] - 1s 18ms/step - loss: 0.4832 - accuracy: 0.7664 - val_loss: 0.6253 - val_accuracy: 0.7954\n",
            "Epoch 30/500\n",
            "78/78 [==============================] - 2s 22ms/step - loss: 0.4885 - accuracy: 0.7602 - val_loss: 0.6589 - val_accuracy: 0.7696\n",
            "Epoch 31/500\n",
            "78/78 [==============================] - 1s 12ms/step - loss: 0.4830 - accuracy: 0.7685 - val_loss: 0.6246 - val_accuracy: 0.7856\n",
            "Epoch 32/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4735 - accuracy: 0.7767 - val_loss: 0.6633 - val_accuracy: 0.7541\n",
            "Epoch 33/500\n",
            "78/78 [==============================] - 1s 8ms/step - loss: 0.4745 - accuracy: 0.7752 - val_loss: 0.6198 - val_accuracy: 0.7907\n",
            "Epoch 34/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4781 - accuracy: 0.7691 - val_loss: 0.5969 - val_accuracy: 0.8119\n",
            "Epoch 35/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4783 - accuracy: 0.7709 - val_loss: 0.6448 - val_accuracy: 0.7706\n",
            "50/50 [==============================] - 0s 6ms/step - loss: 0.4022 - accuracy: 0.7999\n",
            "50/50 [==============================] - 1s 6ms/step\n",
            "Accuracy score : 0.7692797960484385\n",
            "Precision score : 0.0\n",
            "Sensitivity score : 0.0\n",
            "Specificity score : 1.0\n",
            "F1 score : 0.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "#Using bias initialier, class weights and  resampling \n",
        "input_shape = len(X_train_resampled_df.columns)\n",
        "model4 = keras.Sequential([layers.Dense(units = 24, input_shape = [input_shape] , activation = 'relu'),\n",
        "                        layers.Dropout(rate = 0.5),\n",
        "                        layers.Dense(units =24, activation = 'relu'),\n",
        "                        layers.Dropout(rate = 0.5),\n",
        "                        layers.Dense(units = 24, activation = 'relu'),\n",
        "                        layers.Dropout(rate = 0.5),\n",
        "                        layers.Dense(units = 1, activation = 'sigmoid', bias_initializer = keras.initializers.Constant(initial_bias))])\n",
        "#Compile the model\n",
        "model4.compile(optimizer = 'Adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "#Fit the the model \n",
        "early_stopping = keras.callbacks.EarlyStopping(monitor = 'loss', patience = 3) \n",
        "model4.fit(X_train_resampled_df, y_train_resampled_df,  ##Fiiting using resampled data\n",
        "          validation_split = 0.20,\n",
        "          epochs  = 500,\n",
        "          batch_size = 100,\n",
        "          class_weight = class_weight\n",
        "          callbacks = [early_stopping]\n",
        "          )\n",
        "#Evaluate the model\n",
        "model4.evaluate(X_test_transformed_df, y_test_transformed_df) \n",
        "#Make predictions \n",
        "y_predictions4 = np.argmax(model4.predict(X_test_transformed_df), axis =1)\n",
        "accuracy_score = metrics.accuracy_score(y_test_transformed_df, y_predictions4)\n",
        "precision_score = metrics.precision_score(y_test_transformed_df, y_predictions4)\n",
        "sensitivity = metrics .recall_score(y_test_transformed_df, y_predictions4, pos_label = 1)\n",
        "specificity= metrics .recall_score(y_test_transformed_df, y_predictions4, pos_label = 0)\n",
        "f1_score = metrics.f1_score(y_test_transformed_df, y_predictions4)\n",
        "print('Accuracy score :', accuracy_score)\n",
        "print('Precision score :', precision_score)\n",
        "print('Sensitivity score :', sensitivity)\n",
        "print('Specificity score :', specificity)\n",
        "print('F1 score :', f1_score)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VzYK9lp2zRYg",
        "outputId": "b4d9289b-850a-43d6-e697-be67869dc13d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.3.4-py3-none-any.whl (172 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.2/172.2 KB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: protobuf<=3.20.3 in /usr/local/lib/python3.9/dist-packages (from keras-tuner) (3.20.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from keras-tuner) (2.27.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from keras-tuner) (23.0)\n",
            "Requirement already satisfied: tensorflow>=2.0 in /usr/local/lib/python3.9/dist-packages (from keras-tuner) (2.12.0)\n",
            "Collecting kt-legacy\n",
            "  Downloading kt_legacy-1.0.4-py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.0->keras-tuner) (0.4.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.0->keras-tuner) (3.8.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.0->keras-tuner) (0.32.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.0->keras-tuner) (1.16.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.0->keras-tuner) (23.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.0->keras-tuner) (67.6.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.0->keras-tuner) (1.4.0)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.0->keras-tuner) (2.12.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.0->keras-tuner) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.0->keras-tuner) (1.14.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.0->keras-tuner) (16.0.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.0->keras-tuner) (2.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.0->keras-tuner) (1.53.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.0->keras-tuner) (3.3.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.0->keras-tuner) (2.12.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.0->keras-tuner) (0.4.7)\n",
            "Requirement already satisfied: numpy<1.24,>=1.22 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.0->keras-tuner) (1.22.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.0->keras-tuner) (0.2.0)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.0->keras-tuner) (2.12.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.0->keras-tuner) (1.6.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->keras-tuner) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->keras-tuner) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->keras-tuner) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->keras-tuner) (2022.12.7)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.9/dist-packages (from astunparse>=1.6.0->tensorflow>=2.0->keras-tuner) (0.40.0)\n",
            "Requirement already satisfied: ml-dtypes>=0.0.3 in /usr/local/lib/python3.9/dist-packages (from jax>=0.3.15->tensorflow>=2.0->keras-tuner) (0.0.4)\n",
            "Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.9/dist-packages (from jax>=0.3.15->tensorflow>=2.0->keras-tuner) (1.10.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.0->keras-tuner) (1.8.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.0->keras-tuner) (0.7.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.0->keras-tuner) (3.4.3)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.0->keras-tuner) (2.2.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.0->keras-tuner) (1.0.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.0->keras-tuner) (2.17.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow>=2.0->keras-tuner) (4.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow>=2.0->keras-tuner) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow>=2.0->keras-tuner) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow>=2.0->keras-tuner) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/dist-packages (from markdown>=2.6.8->tensorboard<2.13,>=2.12->tensorflow>=2.0->keras-tuner) (6.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.9/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow>=2.0->keras-tuner) (2.1.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.13,>=2.12->tensorflow>=2.0->keras-tuner) (3.15.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow>=2.0->keras-tuner) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow>=2.0->keras-tuner) (3.2.2)\n",
            "Installing collected packages: kt-legacy, keras-tuner\n",
            "Successfully installed keras-tuner-1.3.4 kt-legacy-1.0.4\n"
          ]
        }
      ],
      "source": [
        "#Use Keras tuner \n",
        "%pip install keras-tuner --upgrade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T4sf7-DL2NcE"
      },
      "outputs": [],
      "source": [
        "#Function \n",
        "def build_model(hp):\n",
        "  X_train_resampled_fs_df = X_train_resampled_df.drop(drop_columns, axis = 1)\n",
        "\n",
        "  return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x3sk7IJj60-J"
      },
      "outputs": [],
      "source": [
        "#Insatiate the tuner \n",
        "import keras_tuner\n",
        "tuner = keras_tuner. Hyperband(build_model,\n",
        "                               objective = 'val_accuracy',\n",
        "                               max_epochs = 10,\n",
        "                               factor = 3,\n",
        "                               directory = 'my_dir',\n",
        "                               project_name = 'assignment1'\n",
        "                               )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QcUuA1to-uBU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7d5e6ac-6f97-473e-fcc6-13ebe2ea8c83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 27 Complete [00h 00m 12s]\n",
            "val_accuracy: 0.780927836894989\n",
            "\n",
            "Best val_accuracy So Far: 0.8551546335220337\n",
            "Total elapsed time: 00h 02m 47s\n",
            "\n",
            "Search: Running Trial #28\n",
            "\n",
            "Value             |Best Value So Far |Hyperparameter\n",
            "232               |520               |units1\n",
            "880               |752               |units2\n",
            "tanh              |relu              |activation\n",
            "0.001             |0.01              |learning_rate\n",
            "10                |2                 |tuner/epochs\n",
            "0                 |0                 |tuner/initial_epoch\n",
            "0                 |2                 |tuner/bracket\n",
            "0                 |0                 |tuner/round\n",
            "\n",
            "Epoch 1/10\n",
            "78/78 [==============================] - 2s 14ms/step - loss: 0.5668 - accuracy: 0.7114 - val_loss: 0.7121 - val_accuracy: 0.6454\n",
            "Epoch 2/10\n",
            "78/78 [==============================] - 1s 14ms/step - loss: 0.5263 - accuracy: 0.7428 - val_loss: 0.7728 - val_accuracy: 0.4866\n",
            "Epoch 3/10\n",
            "78/78 [==============================] - 1s 18ms/step - loss: 0.5185 - accuracy: 0.7468 - val_loss: 0.5999 - val_accuracy: 0.7031\n",
            "Epoch 4/10\n",
            "78/78 [==============================] - 1s 12ms/step - loss: 0.5116 - accuracy: 0.7553 - val_loss: 0.8671 - val_accuracy: 0.5412\n",
            "Epoch 5/10\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.5109 - accuracy: 0.7555 - val_loss: 0.6497 - val_accuracy: 0.6526\n",
            "Epoch 6/10\n",
            "78/78 [==============================] - 1s 11ms/step - loss: 0.5083 - accuracy: 0.7615 - val_loss: 0.7356 - val_accuracy: 0.6216\n",
            "Epoch 7/10\n",
            "78/78 [==============================] - 1s 11ms/step - loss: 0.5077 - accuracy: 0.7573 - val_loss: 0.6817 - val_accuracy: 0.6222\n",
            "Epoch 8/10\n",
            "78/78 [==============================] - 1s 11ms/step - loss: 0.5061 - accuracy: 0.7630 - val_loss: 0.8028 - val_accuracy: 0.5629\n",
            "Epoch 9/10\n",
            " 1/78 [..............................] - ETA: 1s - loss: 0.4608 - accuracy: 0.7600"
          ]
        }
      ],
      "source": [
        "#earch for best model \n",
        "early_stopping = keras.callbacks.EarlyStopping(monitor = 'loss', patience = 3) \n",
        "tuner.search(X_train_resampled_df, y_train_resampled_df,\n",
        "          validation_split = 0.20,\n",
        "          epochs  = 500,\n",
        "          batch_size = 100,\n",
        "          callbacks = [early_stopping]\n",
        "          )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HxU_oVPi_YoW",
        "outputId": "cf8306d5-ff65-48e6-8dc0-cbd6ddeacaf0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "520\n",
            "752\n",
            "relu\n",
            "0.01\n"
          ]
        }
      ],
      "source": [
        "#Get best hyperparameters \n",
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "print(best_hps.get('units1'))\n",
        "print(best_hps.get('units2'))\n",
        "print(best_hps.get('activation'))\n",
        "print(best_hps.get('learning_rate'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DMU4pNfiC1jS",
        "outputId": "578429f4-621b-48db-8251-cca747c4a074"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "78/78 [==============================] - 3s 28ms/step - loss: 0.5485 - accuracy: 0.7274 - val_loss: 0.7730 - val_accuracy: 0.5784\n",
            "Epoch 2/500\n",
            "78/78 [==============================] - 1s 18ms/step - loss: 0.4680 - accuracy: 0.7800 - val_loss: 0.5621 - val_accuracy: 0.7500\n",
            "Epoch 3/500\n",
            "78/78 [==============================] - 1s 15ms/step - loss: 0.4523 - accuracy: 0.7940 - val_loss: 0.5743 - val_accuracy: 0.7500\n",
            "Epoch 4/500\n",
            "78/78 [==============================] - 1s 15ms/step - loss: 0.4495 - accuracy: 0.7921 - val_loss: 0.5819 - val_accuracy: 0.7495\n",
            "Epoch 5/500\n",
            "78/78 [==============================] - 1s 15ms/step - loss: 0.4470 - accuracy: 0.7926 - val_loss: 0.4952 - val_accuracy: 0.7763\n",
            "Epoch 6/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4474 - accuracy: 0.7985 - val_loss: 0.6163 - val_accuracy: 0.6866\n",
            "Epoch 7/500\n",
            "78/78 [==============================] - 1s 15ms/step - loss: 0.4464 - accuracy: 0.7978 - val_loss: 0.4841 - val_accuracy: 0.7521\n",
            "Epoch 8/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4465 - accuracy: 0.8006 - val_loss: 0.5166 - val_accuracy: 0.7691\n",
            "Epoch 9/500\n",
            "78/78 [==============================] - 1s 15ms/step - loss: 0.4400 - accuracy: 0.8028 - val_loss: 0.6381 - val_accuracy: 0.6696\n",
            "Epoch 10/500\n",
            "78/78 [==============================] - 1s 18ms/step - loss: 0.4331 - accuracy: 0.7990 - val_loss: 0.5409 - val_accuracy: 0.7392\n",
            "Epoch 11/500\n",
            "78/78 [==============================] - 2s 25ms/step - loss: 0.4425 - accuracy: 0.8003 - val_loss: 0.4043 - val_accuracy: 0.8031\n",
            "Epoch 12/500\n",
            "78/78 [==============================] - 1s 19ms/step - loss: 0.4463 - accuracy: 0.8001 - val_loss: 0.6476 - val_accuracy: 0.7232\n",
            "Epoch 13/500\n",
            "78/78 [==============================] - 1s 15ms/step - loss: 0.4421 - accuracy: 0.8015 - val_loss: 0.5479 - val_accuracy: 0.6918\n",
            "Epoch 14/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4369 - accuracy: 0.8056 - val_loss: 0.4776 - val_accuracy: 0.7510\n",
            "Epoch 15/500\n",
            "78/78 [==============================] - 1s 15ms/step - loss: 0.4384 - accuracy: 0.8027 - val_loss: 0.6016 - val_accuracy: 0.6747\n",
            "Epoch 16/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4363 - accuracy: 0.8029 - val_loss: 0.4667 - val_accuracy: 0.8314\n",
            "Epoch 17/500\n",
            "78/78 [==============================] - 1s 15ms/step - loss: 0.4348 - accuracy: 0.8051 - val_loss: 0.5735 - val_accuracy: 0.6701\n",
            "Epoch 18/500\n",
            "78/78 [==============================] - 1s 15ms/step - loss: 0.4317 - accuracy: 0.8047 - val_loss: 0.5443 - val_accuracy: 0.7510\n",
            "Epoch 19/500\n",
            "78/78 [==============================] - 1s 15ms/step - loss: 0.4311 - accuracy: 0.8056 - val_loss: 0.4955 - val_accuracy: 0.7747\n",
            "Epoch 20/500\n",
            "78/78 [==============================] - 1s 18ms/step - loss: 0.4344 - accuracy: 0.8023 - val_loss: 0.5302 - val_accuracy: 0.7253\n",
            "Epoch 21/500\n",
            "78/78 [==============================] - 2s 24ms/step - loss: 0.4273 - accuracy: 0.8072 - val_loss: 0.5062 - val_accuracy: 0.7562\n",
            "Epoch 22/500\n",
            "78/78 [==============================] - 2s 19ms/step - loss: 0.4347 - accuracy: 0.8009 - val_loss: 0.4465 - val_accuracy: 0.7954\n",
            "Epoch 23/500\n",
            "78/78 [==============================] - 1s 15ms/step - loss: 0.4341 - accuracy: 0.8076 - val_loss: 0.5195 - val_accuracy: 0.7005\n",
            "Epoch 24/500\n",
            "78/78 [==============================] - 1s 15ms/step - loss: 0.4353 - accuracy: 0.8007 - val_loss: 0.4406 - val_accuracy: 0.7974\n",
            "Epoch 25/500\n",
            "78/78 [==============================] - 1s 15ms/step - loss: 0.4379 - accuracy: 0.8052 - val_loss: 0.5193 - val_accuracy: 0.6598\n",
            "Epoch 26/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4303 - accuracy: 0.8039 - val_loss: 0.4835 - val_accuracy: 0.7026\n",
            "Epoch 27/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4225 - accuracy: 0.8105 - val_loss: 0.4803 - val_accuracy: 0.7381\n",
            "Epoch 28/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4324 - accuracy: 0.8061 - val_loss: 0.5500 - val_accuracy: 0.7144\n",
            "Epoch 29/500\n",
            "78/78 [==============================] - 1s 15ms/step - loss: 0.4296 - accuracy: 0.8055 - val_loss: 0.4499 - val_accuracy: 0.7732\n",
            "Epoch 30/500\n",
            "78/78 [==============================] - 1s 19ms/step - loss: 0.4314 - accuracy: 0.8082 - val_loss: 0.3835 - val_accuracy: 0.7820\n",
            "Epoch 31/500\n",
            "78/78 [==============================] - 2s 25ms/step - loss: 0.4252 - accuracy: 0.8079 - val_loss: 0.4343 - val_accuracy: 0.7753\n",
            "Epoch 32/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.4276 - accuracy: 0.8087 - val_loss: 0.4612 - val_accuracy: 0.7598\n",
            "Epoch 33/500\n",
            "78/78 [==============================] - 1s 15ms/step - loss: 0.4283 - accuracy: 0.8061 - val_loss: 0.4459 - val_accuracy: 0.7763\n",
            "Epoch 34/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4189 - accuracy: 0.8078 - val_loss: 0.4602 - val_accuracy: 0.7309\n",
            "Epoch 35/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4212 - accuracy: 0.8061 - val_loss: 0.4687 - val_accuracy: 0.7485\n",
            "Epoch 36/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4256 - accuracy: 0.8073 - val_loss: 0.5061 - val_accuracy: 0.7454\n",
            "Epoch 37/500\n",
            "78/78 [==============================] - 1s 15ms/step - loss: 0.4232 - accuracy: 0.8054 - val_loss: 0.4795 - val_accuracy: 0.7392\n",
            "Epoch 38/500\n",
            "78/78 [==============================] - 1s 15ms/step - loss: 0.4288 - accuracy: 0.8109 - val_loss: 0.4784 - val_accuracy: 0.8144\n",
            "Epoch 39/500\n",
            "78/78 [==============================] - 1s 15ms/step - loss: 0.4217 - accuracy: 0.8096 - val_loss: 0.4495 - val_accuracy: 0.7505\n",
            "Epoch 40/500\n",
            "78/78 [==============================] - 2s 19ms/step - loss: 0.4246 - accuracy: 0.8051 - val_loss: 0.4465 - val_accuracy: 0.7680\n",
            "Epoch 41/500\n",
            "78/78 [==============================] - 2s 25ms/step - loss: 0.4224 - accuracy: 0.8095 - val_loss: 0.5690 - val_accuracy: 0.6639\n",
            "Epoch 42/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.4248 - accuracy: 0.8094 - val_loss: 0.4173 - val_accuracy: 0.7485\n",
            "Epoch 43/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4330 - accuracy: 0.8067 - val_loss: 0.5746 - val_accuracy: 0.6495\n",
            "Epoch 44/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4306 - accuracy: 0.8054 - val_loss: 0.5236 - val_accuracy: 0.7067\n",
            "Epoch 45/500\n",
            "78/78 [==============================] - 1s 15ms/step - loss: 0.4228 - accuracy: 0.8055 - val_loss: 0.4906 - val_accuracy: 0.7438\n",
            "Epoch 46/500\n",
            "78/78 [==============================] - 1s 15ms/step - loss: 0.4251 - accuracy: 0.8057 - val_loss: 0.4685 - val_accuracy: 0.7077\n",
            "Epoch 47/500\n",
            "78/78 [==============================] - 1s 15ms/step - loss: 0.4249 - accuracy: 0.8106 - val_loss: 0.4874 - val_accuracy: 0.7268\n",
            "Epoch 48/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4255 - accuracy: 0.8045 - val_loss: 0.4918 - val_accuracy: 0.7242\n",
            "Epoch 49/500\n",
            "78/78 [==============================] - 1s 15ms/step - loss: 0.4224 - accuracy: 0.8100 - val_loss: 0.5004 - val_accuracy: 0.7268\n",
            "Epoch 50/500\n",
            "78/78 [==============================] - 1s 19ms/step - loss: 0.4227 - accuracy: 0.8086 - val_loss: 0.3844 - val_accuracy: 0.8686\n",
            "Epoch 51/500\n",
            "78/78 [==============================] - 2s 24ms/step - loss: 0.4179 - accuracy: 0.8123 - val_loss: 0.4898 - val_accuracy: 0.7418\n",
            "Epoch 52/500\n",
            "78/78 [==============================] - 1s 18ms/step - loss: 0.4234 - accuracy: 0.8109 - val_loss: 0.4444 - val_accuracy: 0.7541\n",
            "Epoch 53/500\n",
            "78/78 [==============================] - 1s 15ms/step - loss: 0.4132 - accuracy: 0.8113 - val_loss: 0.5063 - val_accuracy: 0.6907\n",
            "Epoch 54/500\n",
            "78/78 [==============================] - 1s 15ms/step - loss: 0.4279 - accuracy: 0.8073 - val_loss: 0.4299 - val_accuracy: 0.8294\n",
            "Epoch 55/500\n",
            "78/78 [==============================] - 2s 26ms/step - loss: 0.4119 - accuracy: 0.8140 - val_loss: 0.4479 - val_accuracy: 0.6918\n",
            "Epoch 56/500\n",
            "78/78 [==============================] - 2s 30ms/step - loss: 0.4172 - accuracy: 0.8048 - val_loss: 0.4687 - val_accuracy: 0.8000\n",
            "Epoch 57/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4109 - accuracy: 0.8126 - val_loss: 0.4039 - val_accuracy: 0.7974\n",
            "Epoch 58/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4146 - accuracy: 0.8152 - val_loss: 0.4905 - val_accuracy: 0.6990\n",
            "Epoch 59/500\n",
            "78/78 [==============================] - 2s 25ms/step - loss: 0.4213 - accuracy: 0.8105 - val_loss: 0.4088 - val_accuracy: 0.8149\n",
            "Epoch 60/500\n",
            "78/78 [==============================] - 2s 21ms/step - loss: 0.4140 - accuracy: 0.8122 - val_loss: 0.4391 - val_accuracy: 0.7753\n",
            "Epoch 61/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.4091 - accuracy: 0.8180 - val_loss: 0.4668 - val_accuracy: 0.7521\n",
            "Epoch 62/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4147 - accuracy: 0.8095 - val_loss: 0.4088 - val_accuracy: 0.8062\n",
            "Epoch 63/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4199 - accuracy: 0.8096 - val_loss: 0.4063 - val_accuracy: 0.7727\n",
            "Epoch 64/500\n",
            "78/78 [==============================] - 1s 15ms/step - loss: 0.4149 - accuracy: 0.8148 - val_loss: 0.4960 - val_accuracy: 0.7026\n",
            "Epoch 65/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4148 - accuracy: 0.8108 - val_loss: 0.3913 - val_accuracy: 0.8062\n",
            "Epoch 66/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4136 - accuracy: 0.8137 - val_loss: 0.4939 - val_accuracy: 0.6892\n",
            "Epoch 67/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4171 - accuracy: 0.8104 - val_loss: 0.4426 - val_accuracy: 0.7495\n",
            "Epoch 68/500\n",
            "78/78 [==============================] - 2s 21ms/step - loss: 0.4161 - accuracy: 0.8092 - val_loss: 0.4849 - val_accuracy: 0.6716\n",
            "Epoch 69/500\n",
            "78/78 [==============================] - 2s 26ms/step - loss: 0.4124 - accuracy: 0.8132 - val_loss: 0.4613 - val_accuracy: 0.7402\n",
            "Epoch 70/500\n",
            "78/78 [==============================] - 1s 15ms/step - loss: 0.4142 - accuracy: 0.8121 - val_loss: 0.4973 - val_accuracy: 0.7273\n",
            "Epoch 71/500\n",
            "78/78 [==============================] - 1s 15ms/step - loss: 0.4144 - accuracy: 0.8085 - val_loss: 0.4583 - val_accuracy: 0.7227\n",
            "Epoch 72/500\n",
            "78/78 [==============================] - 1s 15ms/step - loss: 0.4167 - accuracy: 0.8127 - val_loss: 0.4619 - val_accuracy: 0.7531\n",
            "Epoch 73/500\n",
            "78/78 [==============================] - 1s 15ms/step - loss: 0.4135 - accuracy: 0.8108 - val_loss: 0.3925 - val_accuracy: 0.8515\n",
            "Epoch 74/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4188 - accuracy: 0.8079 - val_loss: 0.5626 - val_accuracy: 0.6655\n",
            "Epoch 75/500\n",
            "78/78 [==============================] - 1s 15ms/step - loss: 0.4162 - accuracy: 0.8118 - val_loss: 0.4709 - val_accuracy: 0.7258\n",
            "Epoch 76/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4134 - accuracy: 0.8171 - val_loss: 0.4462 - val_accuracy: 0.7582\n",
            "Epoch 77/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4197 - accuracy: 0.8152 - val_loss: 0.4687 - val_accuracy: 0.6974\n",
            "Epoch 78/500\n",
            "78/78 [==============================] - 2s 23ms/step - loss: 0.4093 - accuracy: 0.8143 - val_loss: 0.4541 - val_accuracy: 0.7552\n",
            "Epoch 79/500\n",
            "78/78 [==============================] - 2s 24ms/step - loss: 0.4121 - accuracy: 0.8110 - val_loss: 0.3946 - val_accuracy: 0.8428\n",
            "Epoch 80/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.4112 - accuracy: 0.8135 - val_loss: 0.4625 - val_accuracy: 0.6954\n",
            "Epoch 81/500\n",
            "78/78 [==============================] - 1s 15ms/step - loss: 0.4125 - accuracy: 0.8126 - val_loss: 0.4619 - val_accuracy: 0.7845\n",
            "Epoch 82/500\n",
            "78/78 [==============================] - 1s 15ms/step - loss: 0.4119 - accuracy: 0.8099 - val_loss: 0.4637 - val_accuracy: 0.7619\n",
            "Epoch 83/500\n",
            "78/78 [==============================] - 1s 15ms/step - loss: 0.4069 - accuracy: 0.8131 - val_loss: 0.4938 - val_accuracy: 0.7412\n",
            "Epoch 84/500\n",
            "78/78 [==============================] - 1s 15ms/step - loss: 0.4120 - accuracy: 0.8125 - val_loss: 0.4869 - val_accuracy: 0.7356\n",
            "Epoch 85/500\n",
            "78/78 [==============================] - 1s 15ms/step - loss: 0.4175 - accuracy: 0.8119 - val_loss: 0.5115 - val_accuracy: 0.7356\n",
            "Epoch 86/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.4097 - accuracy: 0.8114 - val_loss: 0.4135 - val_accuracy: 0.7814\n",
            "Epoch 87/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4146 - accuracy: 0.8153 - val_loss: 0.4478 - val_accuracy: 0.6902\n",
            "Epoch 88/500\n",
            "78/78 [==============================] - 2s 24ms/step - loss: 0.4104 - accuracy: 0.8106 - val_loss: 0.4256 - val_accuracy: 0.7918\n",
            "Epoch 89/500\n",
            "78/78 [==============================] - 2s 23ms/step - loss: 0.4176 - accuracy: 0.8159 - val_loss: 0.4354 - val_accuracy: 0.7129\n",
            "Epoch 90/500\n",
            "78/78 [==============================] - 1s 15ms/step - loss: 0.4167 - accuracy: 0.8150 - val_loss: 0.5171 - val_accuracy: 0.6804\n",
            "Epoch 91/500\n",
            "78/78 [==============================] - 1s 15ms/step - loss: 0.4184 - accuracy: 0.8168 - val_loss: 0.3978 - val_accuracy: 0.7716\n",
            "Epoch 92/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4160 - accuracy: 0.8128 - val_loss: 0.4350 - val_accuracy: 0.7624\n",
            "Epoch 93/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4121 - accuracy: 0.8108 - val_loss: 0.4654 - val_accuracy: 0.7830\n",
            "Epoch 94/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4130 - accuracy: 0.8114 - val_loss: 0.5763 - val_accuracy: 0.6722\n",
            "Epoch 95/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.4151 - accuracy: 0.8149 - val_loss: 0.3685 - val_accuracy: 0.8567\n",
            "Epoch 96/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4158 - accuracy: 0.8105 - val_loss: 0.4704 - val_accuracy: 0.7124\n",
            "Epoch 97/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.4129 - accuracy: 0.8139 - val_loss: 0.4316 - val_accuracy: 0.7691\n",
            "Epoch 98/500\n",
            "78/78 [==============================] - 2s 24ms/step - loss: 0.4125 - accuracy: 0.8157 - val_loss: 0.4448 - val_accuracy: 0.8149\n",
            "Epoch 99/500\n",
            "78/78 [==============================] - 2s 22ms/step - loss: 0.4066 - accuracy: 0.8130 - val_loss: 0.5173 - val_accuracy: 0.6526\n",
            "Epoch 100/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4168 - accuracy: 0.8123 - val_loss: 0.4877 - val_accuracy: 0.7376\n",
            "Epoch 101/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4081 - accuracy: 0.8143 - val_loss: 0.4659 - val_accuracy: 0.7103\n",
            "Epoch 102/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.4145 - accuracy: 0.8128 - val_loss: 0.4368 - val_accuracy: 0.7933\n",
            "Epoch 103/500\n",
            "78/78 [==============================] - 1s 15ms/step - loss: 0.4111 - accuracy: 0.8193 - val_loss: 0.5243 - val_accuracy: 0.6722\n",
            "Epoch 104/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.4136 - accuracy: 0.8108 - val_loss: 0.4226 - val_accuracy: 0.7490\n",
            "Epoch 105/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4104 - accuracy: 0.8105 - val_loss: 0.4715 - val_accuracy: 0.7031\n",
            "Epoch 106/500\n",
            "78/78 [==============================] - 1s 15ms/step - loss: 0.4088 - accuracy: 0.8146 - val_loss: 0.4650 - val_accuracy: 0.7557\n",
            "Epoch 107/500\n",
            "78/78 [==============================] - 2s 20ms/step - loss: 0.4159 - accuracy: 0.8153 - val_loss: 0.4033 - val_accuracy: 0.8392\n",
            "Epoch 108/500\n",
            "78/78 [==============================] - 2s 25ms/step - loss: 0.4106 - accuracy: 0.8167 - val_loss: 0.4291 - val_accuracy: 0.7784\n",
            "Epoch 109/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.4052 - accuracy: 0.8170 - val_loss: 0.4633 - val_accuracy: 0.7242\n",
            "Epoch 110/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4086 - accuracy: 0.8128 - val_loss: 0.4830 - val_accuracy: 0.7753\n",
            "Epoch 111/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4030 - accuracy: 0.8181 - val_loss: 0.4561 - val_accuracy: 0.7541\n",
            "Epoch 112/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4058 - accuracy: 0.8161 - val_loss: 0.4285 - val_accuracy: 0.7366\n",
            "Epoch 113/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4013 - accuracy: 0.8162 - val_loss: 0.4632 - val_accuracy: 0.7443\n",
            "Epoch 114/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.4135 - accuracy: 0.8172 - val_loss: 0.4547 - val_accuracy: 0.7856\n",
            "Epoch 115/500\n",
            "78/78 [==============================] - 1s 15ms/step - loss: 0.4134 - accuracy: 0.8134 - val_loss: 0.4463 - val_accuracy: 0.8021\n",
            "Epoch 116/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4100 - accuracy: 0.8139 - val_loss: 0.4742 - val_accuracy: 0.7036\n",
            "Epoch 117/500\n",
            "78/78 [==============================] - 2s 23ms/step - loss: 0.4128 - accuracy: 0.8106 - val_loss: 0.4403 - val_accuracy: 0.8036\n",
            "Epoch 118/500\n",
            "78/78 [==============================] - 2s 25ms/step - loss: 0.4044 - accuracy: 0.8168 - val_loss: 0.4784 - val_accuracy: 0.7273\n",
            "Epoch 119/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.4042 - accuracy: 0.8175 - val_loss: 0.4591 - val_accuracy: 0.7438\n",
            "Epoch 120/500\n",
            "78/78 [==============================] - 1s 15ms/step - loss: 0.4121 - accuracy: 0.8123 - val_loss: 0.4593 - val_accuracy: 0.8149\n",
            "Epoch 121/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4075 - accuracy: 0.8175 - val_loss: 0.4687 - val_accuracy: 0.7753\n",
            "Epoch 122/500\n",
            "78/78 [==============================] - 1s 15ms/step - loss: 0.4095 - accuracy: 0.8145 - val_loss: 0.4465 - val_accuracy: 0.7706\n",
            "Epoch 123/500\n",
            "78/78 [==============================] - 1s 15ms/step - loss: 0.4118 - accuracy: 0.8128 - val_loss: 0.3921 - val_accuracy: 0.7845\n",
            "Epoch 124/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.4139 - accuracy: 0.8153 - val_loss: 0.4810 - val_accuracy: 0.7124\n",
            "Epoch 125/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4075 - accuracy: 0.8181 - val_loss: 0.4463 - val_accuracy: 0.7299\n",
            "Epoch 126/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.4098 - accuracy: 0.8123 - val_loss: 0.4923 - val_accuracy: 0.6959\n",
            "Epoch 127/500\n",
            "78/78 [==============================] - 2s 26ms/step - loss: 0.4055 - accuracy: 0.8161 - val_loss: 0.4550 - val_accuracy: 0.7407\n",
            "Epoch 128/500\n",
            "78/78 [==============================] - 2s 21ms/step - loss: 0.4114 - accuracy: 0.8158 - val_loss: 0.4433 - val_accuracy: 0.7619\n",
            "Epoch 129/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.4074 - accuracy: 0.8166 - val_loss: 0.5284 - val_accuracy: 0.6778\n",
            "Epoch 130/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.4104 - accuracy: 0.8139 - val_loss: 0.4455 - val_accuracy: 0.7629\n",
            "Epoch 131/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.4083 - accuracy: 0.8155 - val_loss: 0.4916 - val_accuracy: 0.7732\n",
            "Epoch 132/500\n",
            "78/78 [==============================] - 1s 15ms/step - loss: 0.4054 - accuracy: 0.8203 - val_loss: 0.4126 - val_accuracy: 0.8134\n",
            "Epoch 133/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4039 - accuracy: 0.8146 - val_loss: 0.4153 - val_accuracy: 0.8232\n",
            "Epoch 134/500\n",
            "78/78 [==============================] - 1s 15ms/step - loss: 0.4029 - accuracy: 0.8155 - val_loss: 0.4900 - val_accuracy: 0.6784\n",
            "Epoch 135/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4053 - accuracy: 0.8159 - val_loss: 0.3913 - val_accuracy: 0.8227\n",
            "Epoch 136/500\n",
            "78/78 [==============================] - 2s 21ms/step - loss: 0.4070 - accuracy: 0.8155 - val_loss: 0.4586 - val_accuracy: 0.7845\n",
            "Epoch 137/500\n",
            "78/78 [==============================] - 2s 25ms/step - loss: 0.4065 - accuracy: 0.8118 - val_loss: 0.4782 - val_accuracy: 0.7088\n",
            "Epoch 138/500\n",
            "78/78 [==============================] - 1s 18ms/step - loss: 0.4040 - accuracy: 0.8137 - val_loss: 0.3995 - val_accuracy: 0.7881\n",
            "Epoch 139/500\n",
            "78/78 [==============================] - 1s 15ms/step - loss: 0.4096 - accuracy: 0.8130 - val_loss: 0.4135 - val_accuracy: 0.8284\n",
            "Epoch 140/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4094 - accuracy: 0.8126 - val_loss: 0.3986 - val_accuracy: 0.7892\n",
            "Epoch 141/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4035 - accuracy: 0.8152 - val_loss: 0.4539 - val_accuracy: 0.7562\n",
            "Epoch 142/500\n",
            "78/78 [==============================] - 1s 15ms/step - loss: 0.3997 - accuracy: 0.8163 - val_loss: 0.4837 - val_accuracy: 0.7046\n",
            "Epoch 143/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4012 - accuracy: 0.8180 - val_loss: 0.4887 - val_accuracy: 0.7206\n",
            "Epoch 144/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4015 - accuracy: 0.8164 - val_loss: 0.3780 - val_accuracy: 0.7990\n",
            "Epoch 145/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4052 - accuracy: 0.8171 - val_loss: 0.4834 - val_accuracy: 0.7015\n",
            "Epoch 146/500\n",
            "78/78 [==============================] - 2s 23ms/step - loss: 0.4032 - accuracy: 0.8183 - val_loss: 0.4398 - val_accuracy: 0.7840\n",
            "Epoch 147/500\n",
            "78/78 [==============================] - 2s 26ms/step - loss: 0.4089 - accuracy: 0.8204 - val_loss: 0.4387 - val_accuracy: 0.7479\n",
            "Epoch 148/500\n",
            "78/78 [==============================] - 1s 15ms/step - loss: 0.4082 - accuracy: 0.8158 - val_loss: 0.4839 - val_accuracy: 0.7747\n",
            "Epoch 149/500\n",
            "78/78 [==============================] - 1s 15ms/step - loss: 0.4156 - accuracy: 0.8153 - val_loss: 0.4794 - val_accuracy: 0.6964\n",
            "Epoch 150/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4071 - accuracy: 0.8150 - val_loss: 0.5062 - val_accuracy: 0.7155\n",
            "Epoch 151/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4071 - accuracy: 0.8136 - val_loss: 0.5049 - val_accuracy: 0.7082\n",
            "Epoch 152/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4057 - accuracy: 0.8172 - val_loss: 0.4512 - val_accuracy: 0.7582\n",
            "Epoch 153/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.4027 - accuracy: 0.8117 - val_loss: 0.4176 - val_accuracy: 0.7680\n",
            "Epoch 154/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.4106 - accuracy: 0.8159 - val_loss: 0.4692 - val_accuracy: 0.7392\n",
            "Epoch 155/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.4104 - accuracy: 0.8119 - val_loss: 0.4470 - val_accuracy: 0.7820\n",
            "Epoch 156/500\n",
            "78/78 [==============================] - 2s 24ms/step - loss: 0.4093 - accuracy: 0.8137 - val_loss: 0.4364 - val_accuracy: 0.7170\n",
            "Epoch 157/500\n",
            "78/78 [==============================] - 2s 22ms/step - loss: 0.4034 - accuracy: 0.8143 - val_loss: 0.4528 - val_accuracy: 0.7479\n",
            "Epoch 158/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4023 - accuracy: 0.8166 - val_loss: 0.4231 - val_accuracy: 0.8088\n",
            "Epoch 159/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.4069 - accuracy: 0.8180 - val_loss: 0.3857 - val_accuracy: 0.8660\n",
            "Epoch 160/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.4075 - accuracy: 0.8152 - val_loss: 0.4101 - val_accuracy: 0.8170\n",
            "Epoch 161/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.3986 - accuracy: 0.8193 - val_loss: 0.4069 - val_accuracy: 0.7990\n",
            "Epoch 162/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.3959 - accuracy: 0.8158 - val_loss: 0.4192 - val_accuracy: 0.7474\n",
            "Epoch 163/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.4132 - accuracy: 0.8094 - val_loss: 0.4590 - val_accuracy: 0.7670\n",
            "Epoch 164/500\n",
            "78/78 [==============================] - 1s 15ms/step - loss: 0.4093 - accuracy: 0.8175 - val_loss: 0.4539 - val_accuracy: 0.7887\n",
            "Epoch 165/500\n",
            "78/78 [==============================] - 2s 22ms/step - loss: 0.4051 - accuracy: 0.8202 - val_loss: 0.4495 - val_accuracy: 0.7856\n",
            "Epoch 166/500\n",
            "78/78 [==============================] - 2s 25ms/step - loss: 0.4056 - accuracy: 0.8125 - val_loss: 0.4112 - val_accuracy: 0.7964\n",
            "Epoch 167/500\n",
            "78/78 [==============================] - 1s 18ms/step - loss: 0.4083 - accuracy: 0.8179 - val_loss: 0.4690 - val_accuracy: 0.7619\n",
            "Epoch 168/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.4040 - accuracy: 0.8130 - val_loss: 0.4771 - val_accuracy: 0.7186\n",
            "Epoch 169/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4072 - accuracy: 0.8144 - val_loss: 0.4487 - val_accuracy: 0.7402\n",
            "Epoch 170/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.4009 - accuracy: 0.8183 - val_loss: 0.4214 - val_accuracy: 0.7598\n",
            "Epoch 171/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4073 - accuracy: 0.8137 - val_loss: 0.3782 - val_accuracy: 0.8232\n",
            "Epoch 172/500\n",
            "78/78 [==============================] - 1s 15ms/step - loss: 0.4062 - accuracy: 0.8158 - val_loss: 0.4411 - val_accuracy: 0.7588\n",
            "Epoch 173/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.3994 - accuracy: 0.8155 - val_loss: 0.4040 - val_accuracy: 0.8046\n",
            "Epoch 174/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.4089 - accuracy: 0.8150 - val_loss: 0.4871 - val_accuracy: 0.7526\n",
            "Epoch 175/500\n",
            "78/78 [==============================] - 2s 25ms/step - loss: 0.4044 - accuracy: 0.8155 - val_loss: 0.4569 - val_accuracy: 0.7768\n",
            "Epoch 176/500\n",
            "78/78 [==============================] - 2s 23ms/step - loss: 0.4050 - accuracy: 0.8162 - val_loss: 0.4599 - val_accuracy: 0.7670\n",
            "Epoch 177/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4026 - accuracy: 0.8171 - val_loss: 0.4882 - val_accuracy: 0.7335\n",
            "Epoch 178/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.4051 - accuracy: 0.8163 - val_loss: 0.4696 - val_accuracy: 0.7139\n",
            "Epoch 179/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.4092 - accuracy: 0.8163 - val_loss: 0.4751 - val_accuracy: 0.8165\n",
            "Epoch 180/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4052 - accuracy: 0.8185 - val_loss: 0.4633 - val_accuracy: 0.7515\n",
            "Epoch 181/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.3998 - accuracy: 0.8195 - val_loss: 0.4337 - val_accuracy: 0.7479\n",
            "Epoch 182/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.4060 - accuracy: 0.8152 - val_loss: 0.4280 - val_accuracy: 0.7598\n",
            "Epoch 183/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.4061 - accuracy: 0.8181 - val_loss: 0.4785 - val_accuracy: 0.6861\n",
            "Epoch 184/500\n",
            "78/78 [==============================] - 2s 21ms/step - loss: 0.3984 - accuracy: 0.8158 - val_loss: 0.4340 - val_accuracy: 0.6974\n",
            "Epoch 185/500\n",
            "78/78 [==============================] - 2s 25ms/step - loss: 0.4022 - accuracy: 0.8143 - val_loss: 0.4038 - val_accuracy: 0.7897\n",
            "Epoch 186/500\n",
            "78/78 [==============================] - 1s 19ms/step - loss: 0.4005 - accuracy: 0.8213 - val_loss: 0.4544 - val_accuracy: 0.7603\n",
            "Epoch 187/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4054 - accuracy: 0.8186 - val_loss: 0.4090 - val_accuracy: 0.7902\n",
            "Epoch 188/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4071 - accuracy: 0.8189 - val_loss: 0.4308 - val_accuracy: 0.7387\n",
            "Epoch 189/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.4065 - accuracy: 0.8109 - val_loss: 0.4109 - val_accuracy: 0.7582\n",
            "Epoch 190/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4066 - accuracy: 0.8189 - val_loss: 0.4084 - val_accuracy: 0.8088\n",
            "Epoch 191/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4005 - accuracy: 0.8166 - val_loss: 0.5178 - val_accuracy: 0.6789\n",
            "Epoch 192/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.4067 - accuracy: 0.8131 - val_loss: 0.4116 - val_accuracy: 0.7845\n",
            "Epoch 193/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.4029 - accuracy: 0.8162 - val_loss: 0.4543 - val_accuracy: 0.7284\n",
            "Epoch 194/500\n",
            "78/78 [==============================] - 2s 25ms/step - loss: 0.4051 - accuracy: 0.8149 - val_loss: 0.3809 - val_accuracy: 0.8175\n",
            "Epoch 195/500\n",
            "78/78 [==============================] - 2s 24ms/step - loss: 0.4061 - accuracy: 0.8175 - val_loss: 0.4580 - val_accuracy: 0.7835\n",
            "Epoch 196/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.4034 - accuracy: 0.8164 - val_loss: 0.4658 - val_accuracy: 0.7608\n",
            "Epoch 197/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.3993 - accuracy: 0.8168 - val_loss: 0.4553 - val_accuracy: 0.7557\n",
            "Epoch 198/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4039 - accuracy: 0.8177 - val_loss: 0.4340 - val_accuracy: 0.8294\n",
            "Epoch 199/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.4004 - accuracy: 0.8168 - val_loss: 0.4308 - val_accuracy: 0.7866\n",
            "Epoch 200/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4001 - accuracy: 0.8212 - val_loss: 0.4889 - val_accuracy: 0.7155\n",
            "Epoch 201/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4032 - accuracy: 0.8172 - val_loss: 0.4414 - val_accuracy: 0.7345\n",
            "Epoch 202/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.3993 - accuracy: 0.8180 - val_loss: 0.4618 - val_accuracy: 0.7155\n",
            "Epoch 203/500\n",
            "78/78 [==============================] - 1s 19ms/step - loss: 0.4030 - accuracy: 0.8146 - val_loss: 0.4438 - val_accuracy: 0.7742\n",
            "Epoch 204/500\n",
            "78/78 [==============================] - 2s 25ms/step - loss: 0.3982 - accuracy: 0.8212 - val_loss: 0.4405 - val_accuracy: 0.8021\n",
            "Epoch 205/500\n",
            "78/78 [==============================] - 2s 20ms/step - loss: 0.4052 - accuracy: 0.8166 - val_loss: 0.4652 - val_accuracy: 0.7742\n",
            "Epoch 206/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.3994 - accuracy: 0.8197 - val_loss: 0.4848 - val_accuracy: 0.6871\n",
            "Epoch 207/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4052 - accuracy: 0.8148 - val_loss: 0.4471 - val_accuracy: 0.7356\n",
            "Epoch 208/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.4054 - accuracy: 0.8153 - val_loss: 0.4742 - val_accuracy: 0.7247\n",
            "Epoch 209/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4085 - accuracy: 0.8177 - val_loss: 0.4426 - val_accuracy: 0.7526\n",
            "Epoch 210/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.4070 - accuracy: 0.8148 - val_loss: 0.3769 - val_accuracy: 0.8088\n",
            "Epoch 211/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.4060 - accuracy: 0.8207 - val_loss: 0.4707 - val_accuracy: 0.7366\n",
            "Epoch 212/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4016 - accuracy: 0.8175 - val_loss: 0.4637 - val_accuracy: 0.7309\n",
            "Epoch 213/500\n",
            "78/78 [==============================] - 2s 25ms/step - loss: 0.4046 - accuracy: 0.8140 - val_loss: 0.3924 - val_accuracy: 0.8046\n",
            "Epoch 214/500\n",
            "78/78 [==============================] - 2s 25ms/step - loss: 0.3983 - accuracy: 0.8175 - val_loss: 0.4205 - val_accuracy: 0.7454\n",
            "Epoch 215/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.4084 - accuracy: 0.8099 - val_loss: 0.4374 - val_accuracy: 0.7521\n",
            "Epoch 216/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4046 - accuracy: 0.8159 - val_loss: 0.4733 - val_accuracy: 0.6758\n",
            "Epoch 217/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.3977 - accuracy: 0.8202 - val_loss: 0.4151 - val_accuracy: 0.7448\n",
            "Epoch 218/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4061 - accuracy: 0.8183 - val_loss: 0.4386 - val_accuracy: 0.7103\n",
            "Epoch 219/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4098 - accuracy: 0.8159 - val_loss: 0.4261 - val_accuracy: 0.7521\n",
            "Epoch 220/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4047 - accuracy: 0.8177 - val_loss: 0.5140 - val_accuracy: 0.6701\n",
            "Epoch 221/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.4071 - accuracy: 0.8141 - val_loss: 0.4807 - val_accuracy: 0.6902\n",
            "Epoch 222/500\n",
            "78/78 [==============================] - 2s 20ms/step - loss: 0.4026 - accuracy: 0.8172 - val_loss: 0.4486 - val_accuracy: 0.7314\n",
            "Epoch 223/500\n",
            "78/78 [==============================] - 2s 25ms/step - loss: 0.4026 - accuracy: 0.8125 - val_loss: 0.4369 - val_accuracy: 0.7794\n",
            "Epoch 224/500\n",
            "78/78 [==============================] - 1s 19ms/step - loss: 0.4102 - accuracy: 0.8179 - val_loss: 0.4318 - val_accuracy: 0.7613\n",
            "Epoch 225/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4049 - accuracy: 0.8163 - val_loss: 0.4623 - val_accuracy: 0.7418\n",
            "Epoch 226/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4013 - accuracy: 0.8173 - val_loss: 0.4673 - val_accuracy: 0.7057\n",
            "Epoch 227/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.4057 - accuracy: 0.8125 - val_loss: 0.4156 - val_accuracy: 0.7639\n",
            "Epoch 228/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.4028 - accuracy: 0.8158 - val_loss: 0.4402 - val_accuracy: 0.7500\n",
            "Epoch 229/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4071 - accuracy: 0.8122 - val_loss: 0.4751 - val_accuracy: 0.7598\n",
            "Epoch 230/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.3997 - accuracy: 0.8201 - val_loss: 0.4165 - val_accuracy: 0.7979\n",
            "Epoch 231/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.4059 - accuracy: 0.8148 - val_loss: 0.4670 - val_accuracy: 0.7464\n",
            "Epoch 232/500\n",
            "78/78 [==============================] - 2s 25ms/step - loss: 0.4042 - accuracy: 0.8155 - val_loss: 0.4721 - val_accuracy: 0.6912\n",
            "Epoch 233/500\n",
            "78/78 [==============================] - 2s 25ms/step - loss: 0.4051 - accuracy: 0.8154 - val_loss: 0.4141 - val_accuracy: 0.7727\n",
            "Epoch 234/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.4045 - accuracy: 0.8139 - val_loss: 0.4976 - val_accuracy: 0.6954\n",
            "Epoch 235/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4017 - accuracy: 0.8153 - val_loss: 0.4651 - val_accuracy: 0.7165\n",
            "Epoch 236/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4028 - accuracy: 0.8136 - val_loss: 0.4297 - val_accuracy: 0.7948\n",
            "Epoch 237/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4012 - accuracy: 0.8201 - val_loss: 0.5184 - val_accuracy: 0.6665\n",
            "Epoch 238/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4077 - accuracy: 0.8162 - val_loss: 0.4681 - val_accuracy: 0.7603\n",
            "Epoch 239/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4019 - accuracy: 0.8203 - val_loss: 0.4505 - val_accuracy: 0.7608\n",
            "Epoch 240/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.4023 - accuracy: 0.8146 - val_loss: 0.4548 - val_accuracy: 0.7175\n",
            "Epoch 241/500\n",
            "78/78 [==============================] - 1s 19ms/step - loss: 0.3966 - accuracy: 0.8220 - val_loss: 0.5208 - val_accuracy: 0.6938\n",
            "Epoch 242/500\n",
            "78/78 [==============================] - 2s 24ms/step - loss: 0.4074 - accuracy: 0.8155 - val_loss: 0.4531 - val_accuracy: 0.7284\n",
            "Epoch 243/500\n",
            "78/78 [==============================] - 2s 20ms/step - loss: 0.4067 - accuracy: 0.8162 - val_loss: 0.4865 - val_accuracy: 0.7474\n",
            "Epoch 244/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.3933 - accuracy: 0.8195 - val_loss: 0.4424 - val_accuracy: 0.7402\n",
            "Epoch 245/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.3959 - accuracy: 0.8208 - val_loss: 0.4309 - val_accuracy: 0.7613\n",
            "Epoch 246/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.4013 - accuracy: 0.8139 - val_loss: 0.4634 - val_accuracy: 0.7742\n",
            "Epoch 247/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4056 - accuracy: 0.8135 - val_loss: 0.4221 - val_accuracy: 0.8093\n",
            "Epoch 248/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.3991 - accuracy: 0.8177 - val_loss: 0.4435 - val_accuracy: 0.7742\n",
            "Epoch 249/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.4001 - accuracy: 0.8176 - val_loss: 0.4207 - val_accuracy: 0.7974\n",
            "Epoch 250/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4042 - accuracy: 0.8162 - val_loss: 0.4673 - val_accuracy: 0.7464\n",
            "Epoch 251/500\n",
            "78/78 [==============================] - 2s 22ms/step - loss: 0.3993 - accuracy: 0.8161 - val_loss: 0.5117 - val_accuracy: 0.6881\n",
            "Epoch 252/500\n",
            "78/78 [==============================] - 2s 25ms/step - loss: 0.4048 - accuracy: 0.8136 - val_loss: 0.4725 - val_accuracy: 0.7067\n",
            "Epoch 253/500\n",
            "78/78 [==============================] - 1s 18ms/step - loss: 0.4054 - accuracy: 0.8180 - val_loss: 0.4085 - val_accuracy: 0.7206\n",
            "Epoch 254/500\n",
            "78/78 [==============================] - 1s 18ms/step - loss: 0.4026 - accuracy: 0.8199 - val_loss: 0.4475 - val_accuracy: 0.7593\n",
            "Epoch 255/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.3968 - accuracy: 0.8176 - val_loss: 0.4995 - val_accuracy: 0.7180\n",
            "Epoch 256/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4073 - accuracy: 0.8123 - val_loss: 0.4571 - val_accuracy: 0.7608\n",
            "Epoch 257/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4044 - accuracy: 0.8198 - val_loss: 0.4356 - val_accuracy: 0.8052\n",
            "Epoch 258/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4089 - accuracy: 0.8177 - val_loss: 0.4072 - val_accuracy: 0.7933\n",
            "Epoch 259/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4052 - accuracy: 0.8167 - val_loss: 0.4806 - val_accuracy: 0.7356\n",
            "Epoch 260/500\n",
            "78/78 [==============================] - 1s 18ms/step - loss: 0.4032 - accuracy: 0.8121 - val_loss: 0.4607 - val_accuracy: 0.7387\n",
            "Epoch 261/500\n",
            "78/78 [==============================] - 2s 25ms/step - loss: 0.3959 - accuracy: 0.8204 - val_loss: 0.4863 - val_accuracy: 0.7526\n",
            "Epoch 262/500\n",
            "78/78 [==============================] - 2s 24ms/step - loss: 0.4059 - accuracy: 0.8106 - val_loss: 0.4317 - val_accuracy: 0.8031\n",
            "Epoch 263/500\n",
            "78/78 [==============================] - 1s 18ms/step - loss: 0.4026 - accuracy: 0.8122 - val_loss: 0.4801 - val_accuracy: 0.7077\n",
            "Epoch 264/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4001 - accuracy: 0.8148 - val_loss: 0.4462 - val_accuracy: 0.7412\n",
            "Epoch 265/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4066 - accuracy: 0.8163 - val_loss: 0.4582 - val_accuracy: 0.7629\n",
            "Epoch 266/500\n",
            "78/78 [==============================] - 1s 18ms/step - loss: 0.4043 - accuracy: 0.8177 - val_loss: 0.3973 - val_accuracy: 0.8206\n",
            "Epoch 267/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.4018 - accuracy: 0.8140 - val_loss: 0.4693 - val_accuracy: 0.7469\n",
            "Epoch 268/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.3992 - accuracy: 0.8158 - val_loss: 0.4734 - val_accuracy: 0.6979\n",
            "Epoch 269/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.3994 - accuracy: 0.8183 - val_loss: 0.4353 - val_accuracy: 0.7856\n",
            "Epoch 270/500\n",
            "78/78 [==============================] - 2s 23ms/step - loss: 0.4014 - accuracy: 0.8177 - val_loss: 0.4701 - val_accuracy: 0.7474\n",
            "Epoch 271/500\n",
            "78/78 [==============================] - 2s 27ms/step - loss: 0.3992 - accuracy: 0.8199 - val_loss: 0.4515 - val_accuracy: 0.7608\n",
            "Epoch 272/500\n",
            "78/78 [==============================] - 1s 18ms/step - loss: 0.4026 - accuracy: 0.8179 - val_loss: 0.4522 - val_accuracy: 0.7603\n",
            "Epoch 273/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.3956 - accuracy: 0.8201 - val_loss: 0.4976 - val_accuracy: 0.7000\n",
            "Epoch 274/500\n",
            "78/78 [==============================] - 1s 18ms/step - loss: 0.4048 - accuracy: 0.8121 - val_loss: 0.4795 - val_accuracy: 0.6990\n",
            "Epoch 275/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.4025 - accuracy: 0.8157 - val_loss: 0.5839 - val_accuracy: 0.6402\n",
            "Epoch 276/500\n",
            "78/78 [==============================] - 1s 18ms/step - loss: 0.4024 - accuracy: 0.8154 - val_loss: 0.4332 - val_accuracy: 0.8026\n",
            "Epoch 277/500\n",
            "78/78 [==============================] - 1s 18ms/step - loss: 0.3993 - accuracy: 0.8180 - val_loss: 0.4531 - val_accuracy: 0.7284\n",
            "Epoch 278/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.3994 - accuracy: 0.8192 - val_loss: 0.4325 - val_accuracy: 0.7598\n",
            "Epoch 279/500\n",
            "78/78 [==============================] - 2s 23ms/step - loss: 0.4015 - accuracy: 0.8170 - val_loss: 0.5119 - val_accuracy: 0.6536\n",
            "Epoch 280/500\n",
            "78/78 [==============================] - 2s 25ms/step - loss: 0.4007 - accuracy: 0.8183 - val_loss: 0.5043 - val_accuracy: 0.6876\n",
            "Epoch 281/500\n",
            "78/78 [==============================] - 2s 19ms/step - loss: 0.3998 - accuracy: 0.8203 - val_loss: 0.4544 - val_accuracy: 0.7598\n",
            "Epoch 282/500\n",
            "78/78 [==============================] - 1s 18ms/step - loss: 0.4064 - accuracy: 0.8166 - val_loss: 0.4703 - val_accuracy: 0.7165\n",
            "Epoch 283/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.3992 - accuracy: 0.8154 - val_loss: 0.4528 - val_accuracy: 0.7284\n",
            "Epoch 284/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.4045 - accuracy: 0.8194 - val_loss: 0.4603 - val_accuracy: 0.7325\n",
            "Epoch 285/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.4016 - accuracy: 0.8143 - val_loss: 0.4169 - val_accuracy: 0.7784\n",
            "Epoch 286/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.4019 - accuracy: 0.8153 - val_loss: 0.4494 - val_accuracy: 0.7593\n",
            "Epoch 287/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.4026 - accuracy: 0.8157 - val_loss: 0.4523 - val_accuracy: 0.7613\n",
            "Epoch 288/500\n",
            "78/78 [==============================] - 1s 19ms/step - loss: 0.4017 - accuracy: 0.8140 - val_loss: 0.4558 - val_accuracy: 0.7309\n",
            "Epoch 289/500\n",
            "78/78 [==============================] - 2s 25ms/step - loss: 0.4032 - accuracy: 0.8153 - val_loss: 0.4387 - val_accuracy: 0.7490\n",
            "Epoch 290/500\n",
            "78/78 [==============================] - 2s 22ms/step - loss: 0.3990 - accuracy: 0.8179 - val_loss: 0.4676 - val_accuracy: 0.7175\n",
            "Epoch 291/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.4072 - accuracy: 0.8170 - val_loss: 0.4575 - val_accuracy: 0.7072\n",
            "Epoch 292/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.4037 - accuracy: 0.8188 - val_loss: 0.4156 - val_accuracy: 0.7923\n",
            "Epoch 293/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.3975 - accuracy: 0.8220 - val_loss: 0.4131 - val_accuracy: 0.7876\n",
            "Epoch 294/500\n",
            "78/78 [==============================] - 1s 18ms/step - loss: 0.4013 - accuracy: 0.8172 - val_loss: 0.4450 - val_accuracy: 0.6856\n",
            "Epoch 295/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.4028 - accuracy: 0.8152 - val_loss: 0.5064 - val_accuracy: 0.7113\n",
            "Epoch 296/500\n",
            "78/78 [==============================] - 1s 18ms/step - loss: 0.4018 - accuracy: 0.8210 - val_loss: 0.4216 - val_accuracy: 0.7789\n",
            "Epoch 297/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.3969 - accuracy: 0.8197 - val_loss: 0.4304 - val_accuracy: 0.7747\n",
            "Epoch 298/500\n",
            "78/78 [==============================] - 2s 24ms/step - loss: 0.4009 - accuracy: 0.8173 - val_loss: 0.4249 - val_accuracy: 0.8186\n",
            "Epoch 299/500\n",
            "78/78 [==============================] - 2s 25ms/step - loss: 0.4017 - accuracy: 0.8159 - val_loss: 0.4054 - val_accuracy: 0.7747\n",
            "Epoch 300/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.3978 - accuracy: 0.8197 - val_loss: 0.4378 - val_accuracy: 0.7443\n",
            "Epoch 301/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.4060 - accuracy: 0.8140 - val_loss: 0.4499 - val_accuracy: 0.7572\n",
            "Epoch 302/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.4007 - accuracy: 0.8158 - val_loss: 0.4376 - val_accuracy: 0.7289\n",
            "Epoch 303/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.4005 - accuracy: 0.8183 - val_loss: 0.4350 - val_accuracy: 0.7789\n",
            "Epoch 304/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.4022 - accuracy: 0.8135 - val_loss: 0.4283 - val_accuracy: 0.7778\n",
            "Epoch 305/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.4054 - accuracy: 0.8194 - val_loss: 0.4189 - val_accuracy: 0.7531\n",
            "Epoch 306/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.3971 - accuracy: 0.8163 - val_loss: 0.4797 - val_accuracy: 0.6851\n",
            "Epoch 307/500\n",
            "78/78 [==============================] - 2s 22ms/step - loss: 0.4121 - accuracy: 0.8103 - val_loss: 0.4468 - val_accuracy: 0.7562\n",
            "Epoch 308/500\n",
            "78/78 [==============================] - 2s 25ms/step - loss: 0.3965 - accuracy: 0.8203 - val_loss: 0.4652 - val_accuracy: 0.7361\n",
            "Epoch 309/500\n",
            "78/78 [==============================] - 2s 20ms/step - loss: 0.4005 - accuracy: 0.8190 - val_loss: 0.4490 - val_accuracy: 0.7361\n",
            "Epoch 310/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.3963 - accuracy: 0.8211 - val_loss: 0.4381 - val_accuracy: 0.7443\n",
            "Epoch 311/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.3953 - accuracy: 0.8206 - val_loss: 0.4404 - val_accuracy: 0.7943\n",
            "Epoch 312/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4086 - accuracy: 0.8137 - val_loss: 0.5283 - val_accuracy: 0.6701\n",
            "Epoch 313/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4073 - accuracy: 0.8170 - val_loss: 0.4210 - val_accuracy: 0.7758\n",
            "Epoch 314/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.4079 - accuracy: 0.8163 - val_loss: 0.4520 - val_accuracy: 0.7433\n",
            "Epoch 315/500\n",
            "78/78 [==============================] - 1s 18ms/step - loss: 0.4072 - accuracy: 0.8189 - val_loss: 0.4184 - val_accuracy: 0.7820\n",
            "Epoch 316/500\n",
            "78/78 [==============================] - 1s 18ms/step - loss: 0.4019 - accuracy: 0.8201 - val_loss: 0.4635 - val_accuracy: 0.7567\n",
            "Epoch 317/500\n",
            "78/78 [==============================] - 2s 25ms/step - loss: 0.4016 - accuracy: 0.8201 - val_loss: 0.4350 - val_accuracy: 0.7242\n",
            "Epoch 318/500\n",
            "78/78 [==============================] - 2s 25ms/step - loss: 0.4028 - accuracy: 0.8203 - val_loss: 0.5069 - val_accuracy: 0.6876\n",
            "Epoch 319/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4066 - accuracy: 0.8143 - val_loss: 0.4367 - val_accuracy: 0.7943\n",
            "Epoch 320/500\n",
            "78/78 [==============================] - 1s 18ms/step - loss: 0.3937 - accuracy: 0.8193 - val_loss: 0.4490 - val_accuracy: 0.7314\n",
            "Epoch 321/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.3987 - accuracy: 0.8195 - val_loss: 0.4436 - val_accuracy: 0.7670\n",
            "Epoch 322/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.3985 - accuracy: 0.8207 - val_loss: 0.4874 - val_accuracy: 0.7098\n",
            "Epoch 323/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.3996 - accuracy: 0.8164 - val_loss: 0.4791 - val_accuracy: 0.7139\n",
            "Epoch 324/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.4051 - accuracy: 0.8113 - val_loss: 0.4744 - val_accuracy: 0.6943\n",
            "Epoch 325/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4026 - accuracy: 0.8155 - val_loss: 0.4507 - val_accuracy: 0.7536\n",
            "Epoch 326/500\n",
            "78/78 [==============================] - 2s 22ms/step - loss: 0.4004 - accuracy: 0.8189 - val_loss: 0.5221 - val_accuracy: 0.7088\n",
            "Epoch 327/500\n",
            "78/78 [==============================] - 2s 25ms/step - loss: 0.3975 - accuracy: 0.8224 - val_loss: 0.4413 - val_accuracy: 0.7546\n",
            "Epoch 328/500\n",
            "78/78 [==============================] - 2s 20ms/step - loss: 0.3980 - accuracy: 0.8141 - val_loss: 0.4667 - val_accuracy: 0.7041\n",
            "Epoch 329/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.3985 - accuracy: 0.8195 - val_loss: 0.3755 - val_accuracy: 0.8443\n",
            "Epoch 330/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4018 - accuracy: 0.8161 - val_loss: 0.4449 - val_accuracy: 0.7809\n",
            "Epoch 331/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.4044 - accuracy: 0.8150 - val_loss: 0.4469 - val_accuracy: 0.7572\n",
            "Epoch 332/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.3968 - accuracy: 0.8210 - val_loss: 0.4740 - val_accuracy: 0.7325\n",
            "Epoch 333/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.3923 - accuracy: 0.8215 - val_loss: 0.4203 - val_accuracy: 0.7809\n",
            "Epoch 334/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.3959 - accuracy: 0.8192 - val_loss: 0.5025 - val_accuracy: 0.6624\n",
            "Epoch 335/500\n",
            "78/78 [==============================] - 1s 18ms/step - loss: 0.4021 - accuracy: 0.8170 - val_loss: 0.4623 - val_accuracy: 0.7093\n",
            "Epoch 336/500\n",
            "78/78 [==============================] - 2s 25ms/step - loss: 0.4026 - accuracy: 0.8204 - val_loss: 0.4552 - val_accuracy: 0.7572\n",
            "Epoch 337/500\n",
            "78/78 [==============================] - 2s 24ms/step - loss: 0.3977 - accuracy: 0.8193 - val_loss: 0.5151 - val_accuracy: 0.6758\n",
            "Epoch 338/500\n",
            "78/78 [==============================] - 1s 18ms/step - loss: 0.4049 - accuracy: 0.8162 - val_loss: 0.4348 - val_accuracy: 0.8134\n",
            "Epoch 339/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.4014 - accuracy: 0.8176 - val_loss: 0.4295 - val_accuracy: 0.7428\n",
            "Epoch 340/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.3940 - accuracy: 0.8170 - val_loss: 0.4384 - val_accuracy: 0.7521\n",
            "Epoch 341/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.4005 - accuracy: 0.8143 - val_loss: 0.4505 - val_accuracy: 0.7778\n",
            "Epoch 342/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.3920 - accuracy: 0.8224 - val_loss: 0.4653 - val_accuracy: 0.7500\n",
            "Epoch 343/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.3996 - accuracy: 0.8195 - val_loss: 0.4487 - val_accuracy: 0.7340\n",
            "Epoch 344/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.4028 - accuracy: 0.8201 - val_loss: 0.4334 - val_accuracy: 0.7644\n",
            "Epoch 345/500\n",
            "78/78 [==============================] - 2s 22ms/step - loss: 0.4024 - accuracy: 0.8125 - val_loss: 0.5047 - val_accuracy: 0.6933\n",
            "Epoch 346/500\n",
            "78/78 [==============================] - 2s 26ms/step - loss: 0.4041 - accuracy: 0.8189 - val_loss: 0.4067 - val_accuracy: 0.7768\n",
            "Epoch 347/500\n",
            "78/78 [==============================] - 2s 20ms/step - loss: 0.3985 - accuracy: 0.8206 - val_loss: 0.4675 - val_accuracy: 0.7515\n",
            "Epoch 348/500\n",
            "78/78 [==============================] - 1s 18ms/step - loss: 0.4052 - accuracy: 0.8149 - val_loss: 0.4538 - val_accuracy: 0.7691\n",
            "Epoch 349/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.4033 - accuracy: 0.8148 - val_loss: 0.4359 - val_accuracy: 0.7856\n",
            "Epoch 350/500\n",
            "78/78 [==============================] - 1s 18ms/step - loss: 0.4065 - accuracy: 0.8114 - val_loss: 0.4584 - val_accuracy: 0.7490\n",
            "Epoch 351/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.3944 - accuracy: 0.8188 - val_loss: 0.5223 - val_accuracy: 0.7057\n",
            "Epoch 352/500\n",
            "78/78 [==============================] - 1s 18ms/step - loss: 0.3968 - accuracy: 0.8210 - val_loss: 0.4332 - val_accuracy: 0.7593\n",
            "Epoch 353/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.3968 - accuracy: 0.8140 - val_loss: 0.4443 - val_accuracy: 0.7149\n",
            "Epoch 354/500\n",
            "78/78 [==============================] - 2s 21ms/step - loss: 0.4005 - accuracy: 0.8134 - val_loss: 0.4694 - val_accuracy: 0.7129\n",
            "Epoch 355/500\n",
            "78/78 [==============================] - 2s 25ms/step - loss: 0.3955 - accuracy: 0.8168 - val_loss: 0.4493 - val_accuracy: 0.7918\n",
            "Epoch 356/500\n",
            "78/78 [==============================] - 2s 22ms/step - loss: 0.3966 - accuracy: 0.8202 - val_loss: 0.4178 - val_accuracy: 0.7557\n",
            "Epoch 357/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.4086 - accuracy: 0.8103 - val_loss: 0.4170 - val_accuracy: 0.7990\n",
            "Epoch 358/500\n",
            "78/78 [==============================] - 1s 18ms/step - loss: 0.4054 - accuracy: 0.8162 - val_loss: 0.4510 - val_accuracy: 0.7108\n",
            "Epoch 359/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.3976 - accuracy: 0.8185 - val_loss: 0.4552 - val_accuracy: 0.7067\n",
            "Epoch 360/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.3992 - accuracy: 0.8194 - val_loss: 0.4617 - val_accuracy: 0.7211\n",
            "Epoch 361/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.3960 - accuracy: 0.8135 - val_loss: 0.4544 - val_accuracy: 0.7356\n",
            "Epoch 362/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.3975 - accuracy: 0.8146 - val_loss: 0.4170 - val_accuracy: 0.7969\n",
            "Epoch 363/500\n",
            "78/78 [==============================] - 1s 18ms/step - loss: 0.3965 - accuracy: 0.8149 - val_loss: 0.4613 - val_accuracy: 0.7196\n",
            "Epoch 364/500\n",
            "78/78 [==============================] - 2s 25ms/step - loss: 0.3981 - accuracy: 0.8199 - val_loss: 0.4212 - val_accuracy: 0.7892\n",
            "Epoch 365/500\n",
            "78/78 [==============================] - 2s 26ms/step - loss: 0.4045 - accuracy: 0.8170 - val_loss: 0.4428 - val_accuracy: 0.6995\n",
            "Epoch 366/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.4052 - accuracy: 0.8162 - val_loss: 0.4536 - val_accuracy: 0.7088\n",
            "Epoch 367/500\n",
            "78/78 [==============================] - 1s 18ms/step - loss: 0.4073 - accuracy: 0.8112 - val_loss: 0.5142 - val_accuracy: 0.6902\n",
            "Epoch 368/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.3968 - accuracy: 0.8164 - val_loss: 0.4271 - val_accuracy: 0.7773\n",
            "Epoch 369/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.3975 - accuracy: 0.8194 - val_loss: 0.3803 - val_accuracy: 0.8500\n",
            "Epoch 370/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4003 - accuracy: 0.8135 - val_loss: 0.4578 - val_accuracy: 0.7072\n",
            "Epoch 371/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.4005 - accuracy: 0.8167 - val_loss: 0.4615 - val_accuracy: 0.7546\n",
            "Epoch 372/500\n",
            "78/78 [==============================] - 1s 18ms/step - loss: 0.3988 - accuracy: 0.8189 - val_loss: 0.4424 - val_accuracy: 0.7588\n",
            "Epoch 373/500\n",
            "78/78 [==============================] - 2s 22ms/step - loss: 0.4039 - accuracy: 0.8185 - val_loss: 0.4145 - val_accuracy: 0.8134\n",
            "Epoch 374/500\n",
            "78/78 [==============================] - 2s 24ms/step - loss: 0.3972 - accuracy: 0.8210 - val_loss: 0.4191 - val_accuracy: 0.7789\n",
            "Epoch 375/500\n",
            "78/78 [==============================] - 2s 21ms/step - loss: 0.3995 - accuracy: 0.8207 - val_loss: 0.4629 - val_accuracy: 0.7582\n",
            "Epoch 376/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.3955 - accuracy: 0.8183 - val_loss: 0.5042 - val_accuracy: 0.7026\n",
            "Epoch 377/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.4051 - accuracy: 0.8155 - val_loss: 0.4231 - val_accuracy: 0.7799\n",
            "Epoch 378/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.3966 - accuracy: 0.8164 - val_loss: 0.4521 - val_accuracy: 0.7273\n",
            "Epoch 379/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.4010 - accuracy: 0.8221 - val_loss: 0.4319 - val_accuracy: 0.7247\n",
            "Epoch 380/500\n",
            "78/78 [==============================] - 1s 18ms/step - loss: 0.3994 - accuracy: 0.8197 - val_loss: 0.4470 - val_accuracy: 0.7572\n",
            "Epoch 381/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.4046 - accuracy: 0.8150 - val_loss: 0.4443 - val_accuracy: 0.7479\n",
            "Epoch 382/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.3965 - accuracy: 0.8186 - val_loss: 0.4196 - val_accuracy: 0.7799\n",
            "Epoch 383/500\n",
            "78/78 [==============================] - 2s 25ms/step - loss: 0.3969 - accuracy: 0.8177 - val_loss: 0.5051 - val_accuracy: 0.7072\n",
            "Epoch 384/500\n",
            "78/78 [==============================] - 2s 25ms/step - loss: 0.3960 - accuracy: 0.8168 - val_loss: 0.4551 - val_accuracy: 0.7459\n",
            "Epoch 385/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.4025 - accuracy: 0.8173 - val_loss: 0.4370 - val_accuracy: 0.7861\n",
            "Epoch 386/500\n",
            "78/78 [==============================] - 1s 18ms/step - loss: 0.3960 - accuracy: 0.8192 - val_loss: 0.3802 - val_accuracy: 0.8139\n",
            "Epoch 387/500\n",
            "78/78 [==============================] - 1s 18ms/step - loss: 0.4021 - accuracy: 0.8193 - val_loss: 0.4257 - val_accuracy: 0.7979\n",
            "Epoch 388/500\n",
            "78/78 [==============================] - 1s 18ms/step - loss: 0.4020 - accuracy: 0.8164 - val_loss: 0.3955 - val_accuracy: 0.8088\n",
            "Epoch 389/500\n",
            "78/78 [==============================] - 1s 18ms/step - loss: 0.3940 - accuracy: 0.8177 - val_loss: 0.4208 - val_accuracy: 0.7938\n",
            "Epoch 390/500\n",
            "78/78 [==============================] - 1s 18ms/step - loss: 0.3984 - accuracy: 0.8194 - val_loss: 0.4443 - val_accuracy: 0.7763\n",
            "Epoch 391/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.3966 - accuracy: 0.8229 - val_loss: 0.4158 - val_accuracy: 0.7794\n",
            "Epoch 392/500\n",
            "78/78 [==============================] - 2s 25ms/step - loss: 0.3950 - accuracy: 0.8208 - val_loss: 0.4354 - val_accuracy: 0.8170\n",
            "Epoch 393/500\n",
            "78/78 [==============================] - 2s 25ms/step - loss: 0.3897 - accuracy: 0.8230 - val_loss: 0.4585 - val_accuracy: 0.7433\n",
            "Epoch 394/500\n",
            "78/78 [==============================] - 1s 18ms/step - loss: 0.3939 - accuracy: 0.8215 - val_loss: 0.4060 - val_accuracy: 0.8129\n",
            "Epoch 395/500\n",
            "78/78 [==============================] - 1s 18ms/step - loss: 0.4057 - accuracy: 0.8239 - val_loss: 0.4615 - val_accuracy: 0.7201\n",
            "Epoch 396/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.3964 - accuracy: 0.8193 - val_loss: 0.4278 - val_accuracy: 0.7624\n",
            "Epoch 397/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.4043 - accuracy: 0.8144 - val_loss: 0.5131 - val_accuracy: 0.7119\n",
            "Epoch 398/500\n",
            "78/78 [==============================] - 1s 18ms/step - loss: 0.3980 - accuracy: 0.8188 - val_loss: 0.4827 - val_accuracy: 0.7345\n",
            "Epoch 399/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.3962 - accuracy: 0.8198 - val_loss: 0.4405 - val_accuracy: 0.7639\n",
            "Epoch 400/500\n",
            "78/78 [==============================] - 1s 18ms/step - loss: 0.3962 - accuracy: 0.8179 - val_loss: 0.4825 - val_accuracy: 0.7361\n",
            "Epoch 401/500\n",
            "78/78 [==============================] - 2s 21ms/step - loss: 0.4006 - accuracy: 0.8149 - val_loss: 0.4627 - val_accuracy: 0.7773\n",
            "Epoch 402/500\n",
            "78/78 [==============================] - 2s 26ms/step - loss: 0.4058 - accuracy: 0.8144 - val_loss: 0.4551 - val_accuracy: 0.7247\n",
            "Epoch 403/500\n",
            "78/78 [==============================] - 2s 20ms/step - loss: 0.4055 - accuracy: 0.8166 - val_loss: 0.4146 - val_accuracy: 0.7938\n",
            "Epoch 404/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.3980 - accuracy: 0.8164 - val_loss: 0.4528 - val_accuracy: 0.7624\n",
            "Epoch 405/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.3950 - accuracy: 0.8237 - val_loss: 0.4670 - val_accuracy: 0.7036\n",
            "Epoch 406/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.3969 - accuracy: 0.8217 - val_loss: 0.4691 - val_accuracy: 0.7412\n",
            "Epoch 407/500\n",
            "78/78 [==============================] - 1s 18ms/step - loss: 0.3967 - accuracy: 0.8192 - val_loss: 0.4424 - val_accuracy: 0.7345\n",
            "Epoch 408/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.4000 - accuracy: 0.8170 - val_loss: 0.4584 - val_accuracy: 0.7211\n",
            "Epoch 409/500\n",
            "78/78 [==============================] - 1s 18ms/step - loss: 0.3992 - accuracy: 0.8212 - val_loss: 0.4995 - val_accuracy: 0.6985\n",
            "Epoch 410/500\n",
            "78/78 [==============================] - 1s 19ms/step - loss: 0.3986 - accuracy: 0.8195 - val_loss: 0.4876 - val_accuracy: 0.7268\n",
            "Epoch 411/500\n",
            "78/78 [==============================] - 2s 25ms/step - loss: 0.3995 - accuracy: 0.8211 - val_loss: 0.5169 - val_accuracy: 0.7010\n",
            "Epoch 412/500\n",
            "78/78 [==============================] - 2s 25ms/step - loss: 0.4029 - accuracy: 0.8179 - val_loss: 0.4230 - val_accuracy: 0.7892\n",
            "Epoch 413/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.3993 - accuracy: 0.8118 - val_loss: 0.4796 - val_accuracy: 0.6727\n",
            "Epoch 414/500\n",
            "78/78 [==============================] - 1s 18ms/step - loss: 0.4017 - accuracy: 0.8150 - val_loss: 0.5613 - val_accuracy: 0.6505\n",
            "Epoch 415/500\n",
            "78/78 [==============================] - 1s 19ms/step - loss: 0.4010 - accuracy: 0.8190 - val_loss: 0.4560 - val_accuracy: 0.7861\n",
            "Epoch 416/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.4013 - accuracy: 0.8157 - val_loss: 0.3977 - val_accuracy: 0.8005\n",
            "Epoch 417/500\n",
            "78/78 [==============================] - 1s 18ms/step - loss: 0.3978 - accuracy: 0.8190 - val_loss: 0.4678 - val_accuracy: 0.7278\n",
            "Epoch 418/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.4023 - accuracy: 0.8154 - val_loss: 0.4683 - val_accuracy: 0.7716\n",
            "Epoch 419/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.3939 - accuracy: 0.8190 - val_loss: 0.4462 - val_accuracy: 0.7588\n",
            "Epoch 420/500\n",
            "78/78 [==============================] - 2s 24ms/step - loss: 0.3914 - accuracy: 0.8168 - val_loss: 0.3974 - val_accuracy: 0.7923\n",
            "Epoch 421/500\n",
            "78/78 [==============================] - 2s 26ms/step - loss: 0.3990 - accuracy: 0.8207 - val_loss: 0.4190 - val_accuracy: 0.7613\n",
            "Epoch 422/500\n",
            "78/78 [==============================] - 1s 19ms/step - loss: 0.3975 - accuracy: 0.8186 - val_loss: 0.4652 - val_accuracy: 0.7387\n",
            "Epoch 423/500\n",
            "78/78 [==============================] - 1s 18ms/step - loss: 0.3970 - accuracy: 0.8158 - val_loss: 0.4431 - val_accuracy: 0.7732\n",
            "Epoch 424/500\n",
            "78/78 [==============================] - 1s 18ms/step - loss: 0.4048 - accuracy: 0.8193 - val_loss: 0.4636 - val_accuracy: 0.6727\n",
            "Epoch 425/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.4038 - accuracy: 0.8176 - val_loss: 0.4263 - val_accuracy: 0.7428\n",
            "Epoch 426/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.4039 - accuracy: 0.8219 - val_loss: 0.4836 - val_accuracy: 0.7082\n",
            "Epoch 427/500\n",
            "78/78 [==============================] - 1s 18ms/step - loss: 0.3963 - accuracy: 0.8190 - val_loss: 0.4656 - val_accuracy: 0.7129\n",
            "Epoch 428/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.4033 - accuracy: 0.8144 - val_loss: 0.4691 - val_accuracy: 0.7057\n",
            "Epoch 429/500\n",
            "78/78 [==============================] - 2s 22ms/step - loss: 0.4020 - accuracy: 0.8172 - val_loss: 0.4559 - val_accuracy: 0.7418\n",
            "Epoch 430/500\n",
            "78/78 [==============================] - 2s 25ms/step - loss: 0.3948 - accuracy: 0.8195 - val_loss: 0.4155 - val_accuracy: 0.8041\n",
            "Epoch 431/500\n",
            "78/78 [==============================] - 2s 22ms/step - loss: 0.3997 - accuracy: 0.8179 - val_loss: 0.4752 - val_accuracy: 0.7304\n",
            "Epoch 432/500\n",
            "78/78 [==============================] - 1s 18ms/step - loss: 0.3970 - accuracy: 0.8225 - val_loss: 0.4791 - val_accuracy: 0.7376\n",
            "Epoch 433/500\n",
            "78/78 [==============================] - 1s 18ms/step - loss: 0.3986 - accuracy: 0.8183 - val_loss: 0.4877 - val_accuracy: 0.7278\n",
            "Epoch 434/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.3957 - accuracy: 0.8248 - val_loss: 0.4695 - val_accuracy: 0.7608\n",
            "Epoch 435/500\n",
            "78/78 [==============================] - 1s 19ms/step - loss: 0.3968 - accuracy: 0.8235 - val_loss: 0.4474 - val_accuracy: 0.7737\n",
            "Epoch 436/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.3990 - accuracy: 0.8217 - val_loss: 0.4521 - val_accuracy: 0.7655\n",
            "Epoch 437/500\n",
            "78/78 [==============================] - 1s 19ms/step - loss: 0.4023 - accuracy: 0.8179 - val_loss: 0.4012 - val_accuracy: 0.7851\n",
            "Epoch 438/500\n",
            "78/78 [==============================] - 2s 22ms/step - loss: 0.3976 - accuracy: 0.8204 - val_loss: 0.4542 - val_accuracy: 0.7742\n",
            "Epoch 439/500\n",
            "78/78 [==============================] - 2s 26ms/step - loss: 0.3954 - accuracy: 0.8226 - val_loss: 0.4447 - val_accuracy: 0.7784\n",
            "Epoch 440/500\n",
            "78/78 [==============================] - 2s 23ms/step - loss: 0.3971 - accuracy: 0.8221 - val_loss: 0.4529 - val_accuracy: 0.7613\n",
            "Epoch 441/500\n",
            "78/78 [==============================] - 1s 18ms/step - loss: 0.3929 - accuracy: 0.8235 - val_loss: 0.4471 - val_accuracy: 0.7629\n",
            "Epoch 442/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.4002 - accuracy: 0.8135 - val_loss: 0.5594 - val_accuracy: 0.6706\n",
            "Epoch 443/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.4042 - accuracy: 0.8140 - val_loss: 0.5528 - val_accuracy: 0.6309\n",
            "Epoch 444/500\n",
            "78/78 [==============================] - 1s 19ms/step - loss: 0.3938 - accuracy: 0.8162 - val_loss: 0.4669 - val_accuracy: 0.7242\n",
            "Epoch 445/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.3996 - accuracy: 0.8161 - val_loss: 0.4522 - val_accuracy: 0.7737\n",
            "Epoch 446/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.4001 - accuracy: 0.8140 - val_loss: 0.4741 - val_accuracy: 0.7428\n",
            "Epoch 447/500\n",
            "78/78 [==============================] - 1s 19ms/step - loss: 0.3985 - accuracy: 0.8181 - val_loss: 0.4362 - val_accuracy: 0.7536\n",
            "Epoch 448/500\n",
            "78/78 [==============================] - 2s 26ms/step - loss: 0.3993 - accuracy: 0.8184 - val_loss: 0.4545 - val_accuracy: 0.7588\n",
            "Epoch 449/500\n",
            "78/78 [==============================] - 2s 25ms/step - loss: 0.4066 - accuracy: 0.8164 - val_loss: 0.4480 - val_accuracy: 0.7763\n",
            "Epoch 450/500\n",
            "78/78 [==============================] - 1s 18ms/step - loss: 0.3934 - accuracy: 0.8232 - val_loss: 0.4225 - val_accuracy: 0.7794\n",
            "Epoch 451/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.4040 - accuracy: 0.8161 - val_loss: 0.5022 - val_accuracy: 0.6634\n",
            "Epoch 452/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.4019 - accuracy: 0.8170 - val_loss: 0.4465 - val_accuracy: 0.7747\n",
            "Epoch 453/500\n",
            "78/78 [==============================] - 1s 18ms/step - loss: 0.3948 - accuracy: 0.8176 - val_loss: 0.4180 - val_accuracy: 0.7918\n",
            "Epoch 454/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.4012 - accuracy: 0.8157 - val_loss: 0.4895 - val_accuracy: 0.7041\n",
            "Epoch 455/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.4059 - accuracy: 0.8152 - val_loss: 0.4604 - val_accuracy: 0.7557\n",
            "Epoch 456/500\n",
            "78/78 [==============================] - 1s 18ms/step - loss: 0.4015 - accuracy: 0.8181 - val_loss: 0.4536 - val_accuracy: 0.7247\n",
            "Epoch 457/500\n",
            "78/78 [==============================] - 2s 25ms/step - loss: 0.4071 - accuracy: 0.8141 - val_loss: 0.4493 - val_accuracy: 0.7448\n",
            "Epoch 458/500\n",
            "78/78 [==============================] - 2s 25ms/step - loss: 0.4014 - accuracy: 0.8228 - val_loss: 0.4471 - val_accuracy: 0.7747\n",
            "Epoch 459/500\n",
            "78/78 [==============================] - 2s 21ms/step - loss: 0.4049 - accuracy: 0.8144 - val_loss: 0.4641 - val_accuracy: 0.7206\n",
            "Epoch 460/500\n",
            "78/78 [==============================] - 1s 18ms/step - loss: 0.3961 - accuracy: 0.8253 - val_loss: 0.4284 - val_accuracy: 0.7454\n",
            "Epoch 461/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.3940 - accuracy: 0.8228 - val_loss: 0.4428 - val_accuracy: 0.7160\n",
            "Epoch 462/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.4035 - accuracy: 0.8193 - val_loss: 0.5059 - val_accuracy: 0.7108\n",
            "Epoch 463/500\n",
            "78/78 [==============================] - 1s 18ms/step - loss: 0.4043 - accuracy: 0.8145 - val_loss: 0.4866 - val_accuracy: 0.7201\n",
            "Epoch 464/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.4009 - accuracy: 0.8159 - val_loss: 0.4363 - val_accuracy: 0.7665\n",
            "Epoch 465/500\n",
            "78/78 [==============================] - 1s 18ms/step - loss: 0.3951 - accuracy: 0.8202 - val_loss: 0.4565 - val_accuracy: 0.7469\n",
            "Epoch 466/500\n",
            "78/78 [==============================] - 2s 22ms/step - loss: 0.4028 - accuracy: 0.8162 - val_loss: 0.4706 - val_accuracy: 0.7206\n",
            "Epoch 467/500\n",
            "78/78 [==============================] - 2s 25ms/step - loss: 0.4013 - accuracy: 0.8141 - val_loss: 0.4571 - val_accuracy: 0.7371\n",
            "Epoch 468/500\n",
            "78/78 [==============================] - 2s 22ms/step - loss: 0.3962 - accuracy: 0.8164 - val_loss: 0.4405 - val_accuracy: 0.8062\n",
            "Epoch 469/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.4063 - accuracy: 0.8176 - val_loss: 0.4872 - val_accuracy: 0.7309\n",
            "Epoch 470/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4051 - accuracy: 0.8144 - val_loss: 0.4010 - val_accuracy: 0.8263\n",
            "Epoch 471/500\n",
            "78/78 [==============================] - 1s 18ms/step - loss: 0.3952 - accuracy: 0.8181 - val_loss: 0.4362 - val_accuracy: 0.7722\n",
            "Epoch 472/500\n",
            "78/78 [==============================] - 1s 18ms/step - loss: 0.4048 - accuracy: 0.8170 - val_loss: 0.4174 - val_accuracy: 0.7928\n",
            "Epoch 473/500\n",
            "78/78 [==============================] - 1s 19ms/step - loss: 0.3947 - accuracy: 0.8184 - val_loss: 0.4990 - val_accuracy: 0.7103\n",
            "Epoch 474/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.3981 - accuracy: 0.8172 - val_loss: 0.4486 - val_accuracy: 0.7186\n",
            "Epoch 475/500\n",
            "78/78 [==============================] - 1s 19ms/step - loss: 0.3922 - accuracy: 0.8181 - val_loss: 0.3791 - val_accuracy: 0.8227\n",
            "Epoch 476/500\n",
            "78/78 [==============================] - 2s 25ms/step - loss: 0.3975 - accuracy: 0.8216 - val_loss: 0.4642 - val_accuracy: 0.7082\n",
            "Epoch 477/500\n",
            "78/78 [==============================] - 2s 25ms/step - loss: 0.3960 - accuracy: 0.8141 - val_loss: 0.4406 - val_accuracy: 0.7562\n",
            "Epoch 478/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.4008 - accuracy: 0.8166 - val_loss: 0.4735 - val_accuracy: 0.7268\n",
            "Epoch 479/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.3972 - accuracy: 0.8163 - val_loss: 0.4488 - val_accuracy: 0.7784\n",
            "Epoch 480/500\n",
            "78/78 [==============================] - 1s 18ms/step - loss: 0.3960 - accuracy: 0.8232 - val_loss: 0.4335 - val_accuracy: 0.7701\n",
            "Epoch 481/500\n",
            "78/78 [==============================] - 1s 19ms/step - loss: 0.3973 - accuracy: 0.8189 - val_loss: 0.5184 - val_accuracy: 0.7222\n",
            "Epoch 482/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.3985 - accuracy: 0.8224 - val_loss: 0.4893 - val_accuracy: 0.7155\n",
            "Epoch 483/500\n",
            "78/78 [==============================] - 1s 18ms/step - loss: 0.3996 - accuracy: 0.8250 - val_loss: 0.4806 - val_accuracy: 0.6995\n",
            "Epoch 484/500\n",
            "78/78 [==============================] - 1s 18ms/step - loss: 0.4069 - accuracy: 0.8180 - val_loss: 0.5442 - val_accuracy: 0.6397\n",
            "Epoch 485/500\n",
            "78/78 [==============================] - 2s 25ms/step - loss: 0.4067 - accuracy: 0.8189 - val_loss: 0.4285 - val_accuracy: 0.7985\n",
            "Epoch 486/500\n",
            "78/78 [==============================] - 2s 26ms/step - loss: 0.4073 - accuracy: 0.8161 - val_loss: 0.4132 - val_accuracy: 0.7536\n",
            "Epoch 487/500\n",
            "78/78 [==============================] - 2s 19ms/step - loss: 0.3971 - accuracy: 0.8184 - val_loss: 0.4766 - val_accuracy: 0.7098\n",
            "Epoch 488/500\n",
            "78/78 [==============================] - 1s 19ms/step - loss: 0.4063 - accuracy: 0.8127 - val_loss: 0.4072 - val_accuracy: 0.8392\n",
            "Epoch 489/500\n",
            "78/78 [==============================] - 1s 18ms/step - loss: 0.3926 - accuracy: 0.8198 - val_loss: 0.3916 - val_accuracy: 0.8211\n",
            "Epoch 490/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.3956 - accuracy: 0.8233 - val_loss: 0.3714 - val_accuracy: 0.8392\n",
            "Epoch 491/500\n",
            "78/78 [==============================] - 1s 18ms/step - loss: 0.4042 - accuracy: 0.8171 - val_loss: 0.4613 - val_accuracy: 0.7655\n",
            "Epoch 492/500\n",
            "78/78 [==============================] - 1s 18ms/step - loss: 0.4032 - accuracy: 0.8149 - val_loss: 0.4536 - val_accuracy: 0.7325\n",
            "Epoch 493/500\n",
            "78/78 [==============================] - 1s 18ms/step - loss: 0.4101 - accuracy: 0.8159 - val_loss: 0.4700 - val_accuracy: 0.7691\n",
            "Epoch 494/500\n",
            "78/78 [==============================] - 2s 23ms/step - loss: 0.3961 - accuracy: 0.8172 - val_loss: 0.4611 - val_accuracy: 0.7433\n",
            "Epoch 495/500\n",
            "78/78 [==============================] - 2s 26ms/step - loss: 0.3983 - accuracy: 0.8176 - val_loss: 0.3974 - val_accuracy: 0.8041\n",
            "Epoch 496/500\n",
            "78/78 [==============================] - 2s 22ms/step - loss: 0.3969 - accuracy: 0.8204 - val_loss: 0.4107 - val_accuracy: 0.8299\n",
            "Epoch 497/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.3956 - accuracy: 0.8158 - val_loss: 0.4872 - val_accuracy: 0.7500\n",
            "Epoch 498/500\n",
            "78/78 [==============================] - 1s 18ms/step - loss: 0.3985 - accuracy: 0.8188 - val_loss: 0.4390 - val_accuracy: 0.7521\n",
            "Epoch 499/500\n",
            "78/78 [==============================] - 1s 18ms/step - loss: 0.3944 - accuracy: 0.8206 - val_loss: 0.4229 - val_accuracy: 0.7557\n",
            "Epoch 500/500\n",
            "78/78 [==============================] - 1s 18ms/step - loss: 0.3977 - accuracy: 0.8202 - val_loss: 0.3917 - val_accuracy: 0.8387\n"
          ]
        }
      ],
      "source": [
        "#Best hyperameters \n",
        "hyper_model = tuner.hypermodel.build(best_hps)\n",
        "history = hyper_model.fit(X_train_resampled_df, y_train_resampled_df,\n",
        "                    epochs =500,\n",
        "                    validation_split =0.2,\n",
        "                    batch_size = 100,\n",
        "                    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9fH80WocSooH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b704c08-93db-45a8-e963-de47ae8209f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50/50 [==============================] - 0s 5ms/step - loss: 0.5784 - accuracy: 0.8031\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5783945322036743, 0.8030592799186707]"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ],
      "source": [
        "hyper_model.evaluate(X_test_transformed_df, y_test_transformed_df)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Get best epoch\n",
        "val_accuracy_per_epoch = history.history['val_accuracy'] \n",
        "best_epoch =val_accuracy_per_epoch.index(max(val_accuracy_per_epoch)) + 1\n",
        "print('Best epoch : ', best_epoch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YjVklx5HATzj",
        "outputId": "3f248c09-2d5a-4ef0-b08f-1a4d8e9efc03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best epoch :  50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Retrain the selected features model using best hyperparameters \n",
        "hyper_model_fs = tuner.hypermodel.build(best_hps)\n",
        "\n",
        "history3 = hyper_model_fs.fit(X_train_resampled_df, y_train_resampled_df,\n",
        "                    epochs =500,\n",
        "                    validation_split =0.2,\n",
        "                    batch_size = 100,\n",
        "                    )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQK2--6zBZja",
        "outputId": "b59f722e-2aa4-472a-9391-cbbf5141f93c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "78/78 [==============================] - 2s 19ms/step - loss: 0.5422 - accuracy: 0.7205 - val_loss: 0.4998 - val_accuracy: 0.8108\n",
            "Epoch 2/50\n",
            "78/78 [==============================] - 1s 15ms/step - loss: 0.4725 - accuracy: 0.7831 - val_loss: 0.6076 - val_accuracy: 0.7376\n",
            "Epoch 3/50\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4613 - accuracy: 0.7896 - val_loss: 0.7077 - val_accuracy: 0.6216\n",
            "Epoch 4/50\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4590 - accuracy: 0.7944 - val_loss: 0.7199 - val_accuracy: 0.6567\n",
            "Epoch 5/50\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4469 - accuracy: 0.7979 - val_loss: 0.5484 - val_accuracy: 0.7196\n",
            "Epoch 6/50\n",
            "78/78 [==============================] - 1s 15ms/step - loss: 0.4447 - accuracy: 0.7993 - val_loss: 0.5893 - val_accuracy: 0.7541\n",
            "Epoch 7/50\n",
            "78/78 [==============================] - 1s 15ms/step - loss: 0.4519 - accuracy: 0.7974 - val_loss: 0.6415 - val_accuracy: 0.6845\n",
            "Epoch 8/50\n",
            "78/78 [==============================] - 2s 23ms/step - loss: 0.4448 - accuracy: 0.8057 - val_loss: 0.5897 - val_accuracy: 0.6933\n",
            "Epoch 9/50\n",
            "78/78 [==============================] - 2s 25ms/step - loss: 0.4476 - accuracy: 0.7938 - val_loss: 0.6770 - val_accuracy: 0.6619\n",
            "Epoch 10/50\n",
            "78/78 [==============================] - 1s 15ms/step - loss: 0.4442 - accuracy: 0.7934 - val_loss: 0.6030 - val_accuracy: 0.6675\n",
            "Epoch 11/50\n",
            "78/78 [==============================] - 1s 15ms/step - loss: 0.4349 - accuracy: 0.8024 - val_loss: 0.4993 - val_accuracy: 0.7351\n",
            "Epoch 12/50\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4375 - accuracy: 0.8018 - val_loss: 0.5520 - val_accuracy: 0.7397\n",
            "Epoch 13/50\n",
            "78/78 [==============================] - 1s 15ms/step - loss: 0.4389 - accuracy: 0.8021 - val_loss: 0.6586 - val_accuracy: 0.6613\n",
            "Epoch 14/50\n",
            "78/78 [==============================] - 1s 15ms/step - loss: 0.4378 - accuracy: 0.8059 - val_loss: 0.5031 - val_accuracy: 0.7021\n",
            "Epoch 15/50\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4343 - accuracy: 0.8029 - val_loss: 0.6119 - val_accuracy: 0.6809\n",
            "Epoch 16/50\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4308 - accuracy: 0.8099 - val_loss: 0.4756 - val_accuracy: 0.7541\n",
            "Epoch 17/50\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4313 - accuracy: 0.8039 - val_loss: 0.5166 - val_accuracy: 0.7314\n",
            "Epoch 18/50\n",
            "78/78 [==============================] - 2s 24ms/step - loss: 0.4244 - accuracy: 0.8073 - val_loss: 0.4791 - val_accuracy: 0.7418\n",
            "Epoch 19/50\n",
            "78/78 [==============================] - 2s 23ms/step - loss: 0.4233 - accuracy: 0.8081 - val_loss: 0.4571 - val_accuracy: 0.7835\n",
            "Epoch 20/50\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4295 - accuracy: 0.8050 - val_loss: 0.4922 - val_accuracy: 0.7696\n",
            "Epoch 21/50\n",
            "78/78 [==============================] - 1s 15ms/step - loss: 0.4332 - accuracy: 0.8050 - val_loss: 0.4776 - val_accuracy: 0.7464\n",
            "Epoch 22/50\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4291 - accuracy: 0.8055 - val_loss: 0.4945 - val_accuracy: 0.7629\n",
            "Epoch 23/50\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4368 - accuracy: 0.8028 - val_loss: 0.4650 - val_accuracy: 0.7696\n",
            "Epoch 24/50\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4259 - accuracy: 0.8112 - val_loss: 0.6356 - val_accuracy: 0.6464\n",
            "Epoch 25/50\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4285 - accuracy: 0.8092 - val_loss: 0.5457 - val_accuracy: 0.7557\n",
            "Epoch 26/50\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4345 - accuracy: 0.8025 - val_loss: 0.5781 - val_accuracy: 0.6546\n",
            "Epoch 27/50\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4320 - accuracy: 0.8109 - val_loss: 0.5658 - val_accuracy: 0.7412\n",
            "Epoch 28/50\n",
            "78/78 [==============================] - 2s 24ms/step - loss: 0.4264 - accuracy: 0.8072 - val_loss: 0.4841 - val_accuracy: 0.7629\n",
            "Epoch 29/50\n",
            "78/78 [==============================] - 2s 21ms/step - loss: 0.4269 - accuracy: 0.8078 - val_loss: 0.5289 - val_accuracy: 0.7443\n",
            "Epoch 30/50\n",
            "78/78 [==============================] - 1s 15ms/step - loss: 0.4235 - accuracy: 0.8097 - val_loss: 0.5375 - val_accuracy: 0.6696\n",
            "Epoch 31/50\n",
            "78/78 [==============================] - 1s 15ms/step - loss: 0.4284 - accuracy: 0.8073 - val_loss: 0.4210 - val_accuracy: 0.7680\n",
            "Epoch 32/50\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4303 - accuracy: 0.8067 - val_loss: 0.5643 - val_accuracy: 0.6727\n",
            "Epoch 33/50\n",
            "78/78 [==============================] - 1s 15ms/step - loss: 0.4260 - accuracy: 0.8087 - val_loss: 0.5529 - val_accuracy: 0.6933\n",
            "Epoch 34/50\n",
            "78/78 [==============================] - 1s 15ms/step - loss: 0.4222 - accuracy: 0.8041 - val_loss: 0.5236 - val_accuracy: 0.7000\n",
            "Epoch 35/50\n",
            "78/78 [==============================] - 1s 15ms/step - loss: 0.4241 - accuracy: 0.8048 - val_loss: 0.4772 - val_accuracy: 0.7402\n",
            "Epoch 36/50\n",
            "78/78 [==============================] - 1s 15ms/step - loss: 0.4211 - accuracy: 0.8045 - val_loss: 0.4775 - val_accuracy: 0.7304\n",
            "Epoch 37/50\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4280 - accuracy: 0.8067 - val_loss: 0.4843 - val_accuracy: 0.7546\n",
            "Epoch 38/50\n",
            "78/78 [==============================] - 2s 24ms/step - loss: 0.4241 - accuracy: 0.8088 - val_loss: 0.5207 - val_accuracy: 0.7093\n",
            "Epoch 39/50\n",
            "78/78 [==============================] - 2s 21ms/step - loss: 0.4285 - accuracy: 0.8091 - val_loss: 0.4737 - val_accuracy: 0.7423\n",
            "Epoch 40/50\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.4294 - accuracy: 0.8087 - val_loss: 0.4455 - val_accuracy: 0.8160\n",
            "Epoch 41/50\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4264 - accuracy: 0.8077 - val_loss: 0.4632 - val_accuracy: 0.7515\n",
            "Epoch 42/50\n",
            "78/78 [==============================] - 1s 15ms/step - loss: 0.4231 - accuracy: 0.8139 - val_loss: 0.4517 - val_accuracy: 0.7088\n",
            "Epoch 43/50\n",
            "78/78 [==============================] - 1s 15ms/step - loss: 0.4216 - accuracy: 0.8117 - val_loss: 0.4804 - val_accuracy: 0.7711\n",
            "Epoch 44/50\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4225 - accuracy: 0.8042 - val_loss: 0.4644 - val_accuracy: 0.8155\n",
            "Epoch 45/50\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.4196 - accuracy: 0.8117 - val_loss: 0.4831 - val_accuracy: 0.7557\n",
            "Epoch 46/50\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4212 - accuracy: 0.8114 - val_loss: 0.4658 - val_accuracy: 0.7809\n",
            "Epoch 47/50\n",
            "78/78 [==============================] - 1s 18ms/step - loss: 0.4203 - accuracy: 0.8118 - val_loss: 0.4987 - val_accuracy: 0.7562\n",
            "Epoch 48/50\n",
            "78/78 [==============================] - 2s 25ms/step - loss: 0.4157 - accuracy: 0.8146 - val_loss: 0.4956 - val_accuracy: 0.7155\n",
            "Epoch 49/50\n",
            "78/78 [==============================] - 1s 19ms/step - loss: 0.4175 - accuracy: 0.8092 - val_loss: 0.4864 - val_accuracy: 0.7521\n",
            "Epoch 50/50\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4141 - accuracy: 0.8068 - val_loss: 0.4362 - val_accuracy: 0.7485\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hyper_model2.evaluate(X_test_transformed_df, y_test_transformed_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28UBqI8NG-F9",
        "outputId": "509ba437-3f82-4098-b577-dac48b2cfb0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50/50 [==============================] - 0s 3ms/step - loss: 0.4427 - accuracy: 0.8222\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4426744878292084, 0.8221797347068787]"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history2_df = pd.DataFrame(history2.history)\n",
        "history2_df.loc[0: , ['loss', 'val_loss']].plot()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "YSyRqdyNIaN9",
        "outputId": "5f78e169-dc4c-4c7e-84fd-611dccf81018"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "metadata": {},
          "execution_count": 72
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "KC2LFb5qImcb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Make predictions\n",
        "y_predictions_hyper= np.argmax(hyper_model2.predict(X_test_transformed_df), axis =1)\n",
        "accuracy_score = metrics.accuracy_score(y_test_transformed_df, y_predictions_hyper)\n",
        "#precision_score = metrics.precision_score(y_test_transformed_df, y_predictions_new)\n",
        "#sensitivity = metrics .recall_score(y_test_transformed_df, y_predictions_new, pos_label = 1)\n",
        "#specificity= metrics .recall_score(y_test_transformed_df, y_predictions_new, pos_label = 0)\n",
        "#f1_score = metrics.f1_score(y_test_transformed_df, y_predictions_new)\n",
        "print('Accuracy score :', accuracy_score)\n",
        "#print('Precision score :', precision_score)\n",
        "#print('Sensitivity score :', sensitivity)\n",
        "#print('Specificity score :', specificity)\n",
        "#print('F1 score :', f1_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bjvi2sXPHQpe",
        "outputId": "dd9c210a-0640-4689-c36e-a9a85f106e24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50/50 [==============================] - 0s 4ms/step\n",
            "Accuracy score : 0.7692797960484385\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics._plot.confusion_matrix import confusion_matrix\n",
        "from sklearn.metrics import classfication_report \n",
        "#Confusion matrix\n",
        "confusion_matrix = confusion_matrix(y_test_transformed_df, y_predictions_hyper)\n",
        "confusion_matrix_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix)\n",
        "confusion_matrix_display.plot()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        },
        "id": "fub64Vo_MCTT",
        "outputId": "a51b255d-2165-4c9e-c729-92e73072f5d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report \n",
        "y_predictions_hyper= hyper_model2.predict(X_test_transformed_df)\n",
        "#Convert predictions into boolean values \n",
        "y_predictions_bool = (y_predictions_hyper >= 0.5) * 1\n",
        "print(classification_report(y_test_transformed_df, y_predictions_bool))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nBGc0E4JVifD",
        "outputId": "d533fde4-264d-4e52-9e2b-36d81aea5c90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50/50 [==============================] - 0s 4ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.86      0.88      1207\n",
            "           1       0.60      0.70      0.65       362\n",
            "\n",
            "    accuracy                           0.82      1569\n",
            "   macro avg       0.75      0.78      0.76      1569\n",
            "weighted avg       0.83      0.82      0.83      1569\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics._plot.confusion_matrix import confusion_matrix \n",
        "#Confusion matrix\n",
        "confusion_matrix2 = confusion_matrix(y_test_transformed_df, y_predictions_bool)\n",
        "confusion_matrix_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix2)\n",
        "confusion_matrix_display.plot()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "dIGiTm2vW4iy",
        "outputId": "c7f9552a-5d87-44aa-99f4-8aa62179aa64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Select best numerical features \n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import f_classif"
      ],
      "metadata": {
        "id": "goV8i-iB-Xty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Selecting numerical features from data \n",
        "X_num = X[num_columns]\n",
        "num_fs = SelectKBest(score_func=f_classif, k = 'all')\n",
        "num_fs.fit(X_num, y)\n",
        "X_num_fs = num_fs.transform(X_num)\n"
      ],
      "metadata": {
        "id": "TXkzex5-Aafe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(num_fs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sVz7YDucEvlF",
        "outputId": "b9167779-bf36-474f-9a41-baa1b45e872d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SelectKBest(k='all')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#view the scores\n",
        "for i in range(len(num_fs.scores_)):\n",
        "  print(i, num_fs.scores_[i])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "putZNvTCDsvY",
        "outputId": "c0009c81-cfe5-4494-ea65-e7f77e2cd880"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 35.41009486354761\n",
            "1 20.799302965692398\n",
            "2 95.85318499508536\n",
            "3 49.403215323425975\n",
            "4 1.099567251921703\n",
            "5 1068.615039964832\n",
            "6 72.14206214475851\n",
            "7 183.87486284370374\n",
            "8 1.2024094834709806\n",
            "9 149.50819157580725\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Numerical columns to drop \n",
        "index = [4, 8]\n",
        "num_columns_drop = num_columns[index]\n",
        "print(num_columns_drop)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-mcGAXHY1-q",
        "outputId": "a9dca112-71ff-4367-d4d3-2420517172f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['contact', 'previous'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#drop_cols = ['minmaxscaler__contact', 'minmaxscaler__previous']\n",
        "drop_cols = ['minmaxscaler__contact', 'minmaxscaler__previous'] \n",
        "X_train_resampled_fs_df = X_train_resampled_df.drop(drop_cols, axis = 1)\n",
        "X_test_transformed_fs_df = X_test_transformed_df.drop(drop_cols, axis = 1)"
      ],
      "metadata": {
        "id": "z_hr3KeYk7NR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Model training -selected features \n",
        "input_shape = len(X_train_resampled_fs_df.columns)\n",
        "model_fs = keras.Sequential([layers.Dense(units = 520, input_shape = [input_shape] , activation = 'relu'),\n",
        "                        layers.Dropout(rate = 0.5),\n",
        "                        layers.Dense(units =24, activation = 'relu'),\n",
        "                        layers.Dropout(rate = 0.5),\n",
        "                        layers.Dense(units = 752, activation = 'relu'),\n",
        "                        layers.Dropout(rate = 0.5),\n",
        "                        layers.Dense(units = 1, activation = 'sigmoid')])\n",
        "#Compile the model\n",
        "optimizer = keras.optimizers.Adam(learning_rate = 0.01 )\n",
        "model_fs.compile(optimizer = optimizer , loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "#Fit the the model \n",
        "early_stopping = keras.callbacks.EarlyStopping(monitor = 'loss', patience = 3) \n",
        "history_fs = model_fs.fit(X_train_resampled_fs_df, y_train_resampled_df,\n",
        "          validation_split = 0.20,\n",
        "          epochs  = 500,\n",
        "          batch_size = 100,\n",
        "          )\n",
        "#Evaluate the model\n",
        "model_fs.evaluate(X_test_transformed_fs_df, y_test_transformed_df) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_TZdj41js9g",
        "outputId": "69670a0f-fd3a-4e14-ffe6-d1273ee932b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "78/78 [==============================] - 2s 12ms/step - loss: 0.5780 - accuracy: 0.7004 - val_loss: 0.6971 - val_accuracy: 0.6485\n",
            "Epoch 2/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.5057 - accuracy: 0.7645 - val_loss: 0.5586 - val_accuracy: 0.6851\n",
            "Epoch 3/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4958 - accuracy: 0.7774 - val_loss: 0.5695 - val_accuracy: 0.6845\n",
            "Epoch 4/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4833 - accuracy: 0.7824 - val_loss: 0.5043 - val_accuracy: 0.7521\n",
            "Epoch 5/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4724 - accuracy: 0.7873 - val_loss: 0.4366 - val_accuracy: 0.7619\n",
            "Epoch 6/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4607 - accuracy: 0.7952 - val_loss: 0.4124 - val_accuracy: 0.7876\n",
            "Epoch 7/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4758 - accuracy: 0.7900 - val_loss: 0.4551 - val_accuracy: 0.7510\n",
            "Epoch 8/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4640 - accuracy: 0.7974 - val_loss: 0.4872 - val_accuracy: 0.7438\n",
            "Epoch 9/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4610 - accuracy: 0.7988 - val_loss: 0.4885 - val_accuracy: 0.7727\n",
            "Epoch 10/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4570 - accuracy: 0.7990 - val_loss: 0.4711 - val_accuracy: 0.7299\n",
            "Epoch 11/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4611 - accuracy: 0.7990 - val_loss: 0.4209 - val_accuracy: 0.7964\n",
            "Epoch 12/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4560 - accuracy: 0.7992 - val_loss: 0.5565 - val_accuracy: 0.6309\n",
            "Epoch 13/500\n",
            "78/78 [==============================] - 1s 15ms/step - loss: 0.4575 - accuracy: 0.7966 - val_loss: 0.6088 - val_accuracy: 0.6603\n",
            "Epoch 14/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4657 - accuracy: 0.7914 - val_loss: 0.4625 - val_accuracy: 0.7392\n",
            "Epoch 15/500\n",
            "78/78 [==============================] - 1s 13ms/step - loss: 0.4527 - accuracy: 0.7975 - val_loss: 0.3874 - val_accuracy: 0.8423\n",
            "Epoch 16/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4593 - accuracy: 0.7941 - val_loss: 0.5451 - val_accuracy: 0.6572\n",
            "Epoch 17/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4500 - accuracy: 0.7934 - val_loss: 0.4111 - val_accuracy: 0.8036\n",
            "Epoch 18/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4524 - accuracy: 0.8023 - val_loss: 0.6125 - val_accuracy: 0.5624\n",
            "Epoch 19/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4546 - accuracy: 0.7929 - val_loss: 0.6086 - val_accuracy: 0.6340\n",
            "Epoch 20/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4615 - accuracy: 0.7965 - val_loss: 0.4702 - val_accuracy: 0.7521\n",
            "Epoch 21/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4572 - accuracy: 0.7949 - val_loss: 0.4367 - val_accuracy: 0.7918\n",
            "Epoch 22/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4645 - accuracy: 0.7894 - val_loss: 0.5129 - val_accuracy: 0.6923\n",
            "Epoch 23/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4501 - accuracy: 0.8012 - val_loss: 0.5370 - val_accuracy: 0.6526\n",
            "Epoch 24/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4503 - accuracy: 0.7988 - val_loss: 0.4447 - val_accuracy: 0.7232\n",
            "Epoch 25/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4550 - accuracy: 0.8011 - val_loss: 0.5624 - val_accuracy: 0.7139\n",
            "Epoch 26/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4534 - accuracy: 0.7965 - val_loss: 0.4545 - val_accuracy: 0.7505\n",
            "Epoch 27/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4540 - accuracy: 0.8024 - val_loss: 0.5122 - val_accuracy: 0.7273\n",
            "Epoch 28/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4594 - accuracy: 0.7934 - val_loss: 0.4819 - val_accuracy: 0.7191\n",
            "Epoch 29/500\n",
            "78/78 [==============================] - 1s 15ms/step - loss: 0.4563 - accuracy: 0.8036 - val_loss: 0.5201 - val_accuracy: 0.6541\n",
            "Epoch 30/500\n",
            "78/78 [==============================] - 1s 15ms/step - loss: 0.4510 - accuracy: 0.8042 - val_loss: 0.6241 - val_accuracy: 0.5660\n",
            "Epoch 31/500\n",
            "78/78 [==============================] - 1s 13ms/step - loss: 0.4523 - accuracy: 0.7960 - val_loss: 0.5905 - val_accuracy: 0.6577\n",
            "Epoch 32/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4498 - accuracy: 0.7975 - val_loss: 0.4999 - val_accuracy: 0.6500\n",
            "Epoch 33/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4494 - accuracy: 0.8003 - val_loss: 0.6446 - val_accuracy: 0.6186\n",
            "Epoch 34/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4498 - accuracy: 0.7974 - val_loss: 0.5099 - val_accuracy: 0.6546\n",
            "Epoch 35/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4456 - accuracy: 0.8061 - val_loss: 0.4731 - val_accuracy: 0.7258\n",
            "Epoch 36/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4458 - accuracy: 0.8039 - val_loss: 0.5438 - val_accuracy: 0.6686\n",
            "Epoch 37/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4467 - accuracy: 0.7999 - val_loss: 0.5626 - val_accuracy: 0.6448\n",
            "Epoch 38/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4540 - accuracy: 0.8020 - val_loss: 0.5293 - val_accuracy: 0.6454\n",
            "Epoch 39/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4604 - accuracy: 0.7931 - val_loss: 0.5646 - val_accuracy: 0.6211\n",
            "Epoch 40/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4455 - accuracy: 0.8001 - val_loss: 0.5046 - val_accuracy: 0.7015\n",
            "Epoch 41/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4496 - accuracy: 0.7992 - val_loss: 0.5008 - val_accuracy: 0.6825\n",
            "Epoch 42/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4449 - accuracy: 0.8052 - val_loss: 0.4793 - val_accuracy: 0.7634\n",
            "Epoch 43/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4462 - accuracy: 0.8052 - val_loss: 0.5286 - val_accuracy: 0.6412\n",
            "Epoch 44/500\n",
            "78/78 [==============================] - 1s 11ms/step - loss: 0.4450 - accuracy: 0.7954 - val_loss: 0.5397 - val_accuracy: 0.7098\n",
            "Epoch 45/500\n",
            "78/78 [==============================] - 1s 15ms/step - loss: 0.4456 - accuracy: 0.8015 - val_loss: 0.4870 - val_accuracy: 0.6840\n",
            "Epoch 46/500\n",
            "78/78 [==============================] - 1s 15ms/step - loss: 0.4423 - accuracy: 0.8042 - val_loss: 0.4695 - val_accuracy: 0.6948\n",
            "Epoch 47/500\n",
            "78/78 [==============================] - 1s 12ms/step - loss: 0.4407 - accuracy: 0.8047 - val_loss: 0.4568 - val_accuracy: 0.7376\n",
            "Epoch 48/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4417 - accuracy: 0.8018 - val_loss: 0.5595 - val_accuracy: 0.6809\n",
            "Epoch 49/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4472 - accuracy: 0.8015 - val_loss: 0.4438 - val_accuracy: 0.7613\n",
            "Epoch 50/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4465 - accuracy: 0.8028 - val_loss: 0.5171 - val_accuracy: 0.6407\n",
            "Epoch 51/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4404 - accuracy: 0.8027 - val_loss: 0.4675 - val_accuracy: 0.6789\n",
            "Epoch 52/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4397 - accuracy: 0.8011 - val_loss: 0.4419 - val_accuracy: 0.7505\n",
            "Epoch 53/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4435 - accuracy: 0.8041 - val_loss: 0.5356 - val_accuracy: 0.6495\n",
            "Epoch 54/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4482 - accuracy: 0.8001 - val_loss: 0.4815 - val_accuracy: 0.7129\n",
            "Epoch 55/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4345 - accuracy: 0.8101 - val_loss: 0.5129 - val_accuracy: 0.6737\n",
            "Epoch 56/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4406 - accuracy: 0.8029 - val_loss: 0.4493 - val_accuracy: 0.7278\n",
            "Epoch 57/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4427 - accuracy: 0.8056 - val_loss: 0.5284 - val_accuracy: 0.6856\n",
            "Epoch 58/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4411 - accuracy: 0.8052 - val_loss: 0.5500 - val_accuracy: 0.6706\n",
            "Epoch 59/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4506 - accuracy: 0.8007 - val_loss: 0.5296 - val_accuracy: 0.6314\n",
            "Epoch 60/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4342 - accuracy: 0.8127 - val_loss: 0.5364 - val_accuracy: 0.6799\n",
            "Epoch 61/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4351 - accuracy: 0.8032 - val_loss: 0.4490 - val_accuracy: 0.7495\n",
            "Epoch 62/500\n",
            "78/78 [==============================] - 1s 15ms/step - loss: 0.4435 - accuracy: 0.8061 - val_loss: 0.5931 - val_accuracy: 0.7041\n",
            "Epoch 63/500\n",
            "78/78 [==============================] - 1s 11ms/step - loss: 0.4413 - accuracy: 0.8059 - val_loss: 0.5506 - val_accuracy: 0.6546\n",
            "Epoch 64/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4443 - accuracy: 0.8012 - val_loss: 0.5362 - val_accuracy: 0.6784\n",
            "Epoch 65/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4365 - accuracy: 0.8048 - val_loss: 0.4945 - val_accuracy: 0.6763\n",
            "Epoch 66/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4399 - accuracy: 0.8097 - val_loss: 0.5420 - val_accuracy: 0.6412\n",
            "Epoch 67/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4316 - accuracy: 0.8110 - val_loss: 0.5300 - val_accuracy: 0.6598\n",
            "Epoch 68/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4380 - accuracy: 0.8085 - val_loss: 0.5572 - val_accuracy: 0.6479\n",
            "Epoch 69/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4359 - accuracy: 0.8018 - val_loss: 0.5611 - val_accuracy: 0.6330\n",
            "Epoch 70/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4384 - accuracy: 0.8046 - val_loss: 0.4612 - val_accuracy: 0.7129\n",
            "Epoch 71/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4360 - accuracy: 0.8052 - val_loss: 0.4707 - val_accuracy: 0.6938\n",
            "Epoch 72/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4401 - accuracy: 0.8023 - val_loss: 0.4687 - val_accuracy: 0.7031\n",
            "Epoch 73/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4437 - accuracy: 0.7992 - val_loss: 0.4193 - val_accuracy: 0.7943\n",
            "Epoch 74/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4386 - accuracy: 0.8015 - val_loss: 0.4552 - val_accuracy: 0.7804\n",
            "Epoch 75/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4319 - accuracy: 0.8032 - val_loss: 0.4432 - val_accuracy: 0.7892\n",
            "Epoch 76/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4427 - accuracy: 0.8054 - val_loss: 0.6016 - val_accuracy: 0.5320\n",
            "Epoch 77/500\n",
            "78/78 [==============================] - 1s 14ms/step - loss: 0.4392 - accuracy: 0.8015 - val_loss: 0.5591 - val_accuracy: 0.6407\n",
            "Epoch 78/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4416 - accuracy: 0.7985 - val_loss: 0.5198 - val_accuracy: 0.6572\n",
            "Epoch 79/500\n",
            "78/78 [==============================] - 1s 14ms/step - loss: 0.4328 - accuracy: 0.8045 - val_loss: 0.4513 - val_accuracy: 0.7211\n",
            "Epoch 80/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4355 - accuracy: 0.8055 - val_loss: 0.4721 - val_accuracy: 0.6747\n",
            "Epoch 81/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4289 - accuracy: 0.8137 - val_loss: 0.4708 - val_accuracy: 0.7789\n",
            "Epoch 82/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4374 - accuracy: 0.8042 - val_loss: 0.5587 - val_accuracy: 0.6680\n",
            "Epoch 83/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4367 - accuracy: 0.8024 - val_loss: 0.4888 - val_accuracy: 0.6567\n",
            "Epoch 84/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4316 - accuracy: 0.8056 - val_loss: 0.4859 - val_accuracy: 0.6381\n",
            "Epoch 85/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4364 - accuracy: 0.8052 - val_loss: 0.5563 - val_accuracy: 0.6448\n",
            "Epoch 86/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4425 - accuracy: 0.8073 - val_loss: 0.4937 - val_accuracy: 0.6995\n",
            "Epoch 87/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4366 - accuracy: 0.8043 - val_loss: 0.4689 - val_accuracy: 0.7758\n",
            "Epoch 88/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4397 - accuracy: 0.8088 - val_loss: 0.6210 - val_accuracy: 0.6268\n",
            "Epoch 89/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4444 - accuracy: 0.8014 - val_loss: 0.5045 - val_accuracy: 0.7113\n",
            "Epoch 90/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4386 - accuracy: 0.8055 - val_loss: 0.6091 - val_accuracy: 0.5964\n",
            "Epoch 91/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4289 - accuracy: 0.8127 - val_loss: 0.4956 - val_accuracy: 0.6814\n",
            "Epoch 92/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4369 - accuracy: 0.8078 - val_loss: 0.5532 - val_accuracy: 0.6186\n",
            "Epoch 93/500\n",
            "78/78 [==============================] - 1s 14ms/step - loss: 0.4321 - accuracy: 0.8100 - val_loss: 0.6071 - val_accuracy: 0.5902\n",
            "Epoch 94/500\n",
            "78/78 [==============================] - 1s 14ms/step - loss: 0.4384 - accuracy: 0.8016 - val_loss: 0.4632 - val_accuracy: 0.6768\n",
            "Epoch 95/500\n",
            "78/78 [==============================] - 1s 15ms/step - loss: 0.4354 - accuracy: 0.8046 - val_loss: 0.5488 - val_accuracy: 0.6665\n",
            "Epoch 96/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4374 - accuracy: 0.8076 - val_loss: 0.5479 - val_accuracy: 0.6402\n",
            "Epoch 97/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4331 - accuracy: 0.8011 - val_loss: 0.4830 - val_accuracy: 0.7103\n",
            "Epoch 98/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4323 - accuracy: 0.8077 - val_loss: 0.4854 - val_accuracy: 0.7418\n",
            "Epoch 99/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4296 - accuracy: 0.8096 - val_loss: 0.4836 - val_accuracy: 0.7351\n",
            "Epoch 100/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4309 - accuracy: 0.8074 - val_loss: 0.4539 - val_accuracy: 0.7026\n",
            "Epoch 101/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4362 - accuracy: 0.8025 - val_loss: 0.4377 - val_accuracy: 0.7634\n",
            "Epoch 102/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4400 - accuracy: 0.8115 - val_loss: 0.5693 - val_accuracy: 0.6485\n",
            "Epoch 103/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4347 - accuracy: 0.8082 - val_loss: 0.4861 - val_accuracy: 0.6912\n",
            "Epoch 104/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4353 - accuracy: 0.8057 - val_loss: 0.5137 - val_accuracy: 0.7124\n",
            "Epoch 105/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4311 - accuracy: 0.8095 - val_loss: 0.4949 - val_accuracy: 0.7170\n",
            "Epoch 106/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4330 - accuracy: 0.8074 - val_loss: 0.4996 - val_accuracy: 0.6928\n",
            "Epoch 107/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4356 - accuracy: 0.8024 - val_loss: 0.5188 - val_accuracy: 0.6438\n",
            "Epoch 108/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4320 - accuracy: 0.8064 - val_loss: 0.4796 - val_accuracy: 0.7273\n",
            "Epoch 109/500\n",
            "78/78 [==============================] - 1s 13ms/step - loss: 0.4276 - accuracy: 0.8094 - val_loss: 0.5031 - val_accuracy: 0.6881\n",
            "Epoch 110/500\n",
            "78/78 [==============================] - 1s 15ms/step - loss: 0.4402 - accuracy: 0.8027 - val_loss: 0.5008 - val_accuracy: 0.7144\n",
            "Epoch 111/500\n",
            "78/78 [==============================] - 1s 15ms/step - loss: 0.4281 - accuracy: 0.8086 - val_loss: 0.5297 - val_accuracy: 0.6892\n",
            "Epoch 112/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4353 - accuracy: 0.8056 - val_loss: 0.5376 - val_accuracy: 0.6784\n",
            "Epoch 113/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4286 - accuracy: 0.8074 - val_loss: 0.4710 - val_accuracy: 0.7242\n",
            "Epoch 114/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4428 - accuracy: 0.7996 - val_loss: 0.4757 - val_accuracy: 0.7325\n",
            "Epoch 115/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4395 - accuracy: 0.8088 - val_loss: 0.4801 - val_accuracy: 0.7335\n",
            "Epoch 116/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4321 - accuracy: 0.8100 - val_loss: 0.5005 - val_accuracy: 0.7113\n",
            "Epoch 117/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4312 - accuracy: 0.8097 - val_loss: 0.6229 - val_accuracy: 0.6361\n",
            "Epoch 118/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4280 - accuracy: 0.8067 - val_loss: 0.4742 - val_accuracy: 0.7521\n",
            "Epoch 119/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4331 - accuracy: 0.8065 - val_loss: 0.4796 - val_accuracy: 0.7423\n",
            "Epoch 120/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4339 - accuracy: 0.8063 - val_loss: 0.4924 - val_accuracy: 0.7304\n",
            "Epoch 121/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4311 - accuracy: 0.8082 - val_loss: 0.5712 - val_accuracy: 0.6948\n",
            "Epoch 122/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4264 - accuracy: 0.8088 - val_loss: 0.5624 - val_accuracy: 0.6320\n",
            "Epoch 123/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4320 - accuracy: 0.8048 - val_loss: 0.5169 - val_accuracy: 0.6402\n",
            "Epoch 124/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4262 - accuracy: 0.8060 - val_loss: 0.5315 - val_accuracy: 0.6655\n",
            "Epoch 125/500\n",
            "78/78 [==============================] - 1s 13ms/step - loss: 0.4292 - accuracy: 0.8108 - val_loss: 0.4845 - val_accuracy: 0.6856\n",
            "Epoch 126/500\n",
            "78/78 [==============================] - 1s 15ms/step - loss: 0.4272 - accuracy: 0.8099 - val_loss: 0.5322 - val_accuracy: 0.6742\n",
            "Epoch 127/500\n",
            "78/78 [==============================] - 1s 15ms/step - loss: 0.4352 - accuracy: 0.8067 - val_loss: 0.5423 - val_accuracy: 0.6515\n",
            "Epoch 128/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4299 - accuracy: 0.8074 - val_loss: 0.5340 - val_accuracy: 0.6026\n",
            "Epoch 129/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4302 - accuracy: 0.8027 - val_loss: 0.5405 - val_accuracy: 0.6129\n",
            "Epoch 130/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4288 - accuracy: 0.8091 - val_loss: 0.5119 - val_accuracy: 0.6706\n",
            "Epoch 131/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4329 - accuracy: 0.8099 - val_loss: 0.4486 - val_accuracy: 0.7247\n",
            "Epoch 132/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4287 - accuracy: 0.8028 - val_loss: 0.4960 - val_accuracy: 0.7046\n",
            "Epoch 133/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4387 - accuracy: 0.8025 - val_loss: 0.5453 - val_accuracy: 0.6469\n",
            "Epoch 134/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4452 - accuracy: 0.8018 - val_loss: 0.4649 - val_accuracy: 0.7180\n",
            "Epoch 135/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4229 - accuracy: 0.8130 - val_loss: 0.4905 - val_accuracy: 0.7052\n",
            "Epoch 136/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4441 - accuracy: 0.8002 - val_loss: 0.4964 - val_accuracy: 0.6851\n",
            "Epoch 137/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4284 - accuracy: 0.8083 - val_loss: 0.5242 - val_accuracy: 0.6907\n",
            "Epoch 138/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4271 - accuracy: 0.8052 - val_loss: 0.4401 - val_accuracy: 0.7722\n",
            "Epoch 139/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4312 - accuracy: 0.8109 - val_loss: 0.5819 - val_accuracy: 0.6237\n",
            "Epoch 140/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4322 - accuracy: 0.8048 - val_loss: 0.5077 - val_accuracy: 0.6845\n",
            "Epoch 141/500\n",
            "78/78 [==============================] - 1s 12ms/step - loss: 0.4375 - accuracy: 0.8042 - val_loss: 0.5337 - val_accuracy: 0.6510\n",
            "Epoch 142/500\n",
            "78/78 [==============================] - 1s 15ms/step - loss: 0.4389 - accuracy: 0.8043 - val_loss: 0.5260 - val_accuracy: 0.7139\n",
            "Epoch 143/500\n",
            "78/78 [==============================] - 1s 14ms/step - loss: 0.4295 - accuracy: 0.8054 - val_loss: 0.4973 - val_accuracy: 0.7062\n",
            "Epoch 144/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4313 - accuracy: 0.8091 - val_loss: 0.4914 - val_accuracy: 0.6845\n",
            "Epoch 145/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4344 - accuracy: 0.8069 - val_loss: 0.5345 - val_accuracy: 0.6515\n",
            "Epoch 146/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4286 - accuracy: 0.8068 - val_loss: 0.4998 - val_accuracy: 0.6861\n",
            "Epoch 147/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4277 - accuracy: 0.8074 - val_loss: 0.4653 - val_accuracy: 0.7052\n",
            "Epoch 148/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4381 - accuracy: 0.7997 - val_loss: 0.4818 - val_accuracy: 0.7103\n",
            "Epoch 149/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4299 - accuracy: 0.8101 - val_loss: 0.4943 - val_accuracy: 0.6985\n",
            "Epoch 150/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4226 - accuracy: 0.8131 - val_loss: 0.6396 - val_accuracy: 0.5799\n",
            "Epoch 151/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4280 - accuracy: 0.8094 - val_loss: 0.5230 - val_accuracy: 0.6778\n",
            "Epoch 152/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4328 - accuracy: 0.8043 - val_loss: 0.5059 - val_accuracy: 0.6665\n",
            "Epoch 153/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4339 - accuracy: 0.8086 - val_loss: 0.5450 - val_accuracy: 0.6655\n",
            "Epoch 154/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4364 - accuracy: 0.8072 - val_loss: 0.5076 - val_accuracy: 0.6608\n",
            "Epoch 155/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4305 - accuracy: 0.8091 - val_loss: 0.6878 - val_accuracy: 0.4825\n",
            "Epoch 156/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4297 - accuracy: 0.8052 - val_loss: 0.4734 - val_accuracy: 0.7057\n",
            "Epoch 157/500\n",
            "78/78 [==============================] - 1s 11ms/step - loss: 0.4278 - accuracy: 0.8087 - val_loss: 0.5072 - val_accuracy: 0.6655\n",
            "Epoch 158/500\n",
            "78/78 [==============================] - 1s 14ms/step - loss: 0.4286 - accuracy: 0.8134 - val_loss: 0.6283 - val_accuracy: 0.6222\n",
            "Epoch 159/500\n",
            "78/78 [==============================] - 1s 15ms/step - loss: 0.4344 - accuracy: 0.8105 - val_loss: 0.4719 - val_accuracy: 0.7479\n",
            "Epoch 160/500\n",
            "78/78 [==============================] - 1s 12ms/step - loss: 0.4321 - accuracy: 0.8106 - val_loss: 0.4947 - val_accuracy: 0.7387\n",
            "Epoch 161/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4369 - accuracy: 0.8065 - val_loss: 0.4526 - val_accuracy: 0.7655\n",
            "Epoch 162/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4358 - accuracy: 0.8077 - val_loss: 0.4650 - val_accuracy: 0.7412\n",
            "Epoch 163/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4359 - accuracy: 0.8055 - val_loss: 0.5498 - val_accuracy: 0.6670\n",
            "Epoch 164/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4350 - accuracy: 0.8079 - val_loss: 0.4885 - val_accuracy: 0.7062\n",
            "Epoch 165/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4299 - accuracy: 0.8099 - val_loss: 0.5282 - val_accuracy: 0.6619\n",
            "Epoch 166/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4324 - accuracy: 0.8072 - val_loss: 0.5250 - val_accuracy: 0.7005\n",
            "Epoch 167/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4393 - accuracy: 0.8036 - val_loss: 0.5047 - val_accuracy: 0.6902\n",
            "Epoch 168/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4344 - accuracy: 0.8079 - val_loss: 0.5079 - val_accuracy: 0.6608\n",
            "Epoch 169/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4353 - accuracy: 0.8099 - val_loss: 0.4823 - val_accuracy: 0.7227\n",
            "Epoch 170/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4288 - accuracy: 0.8048 - val_loss: 0.5791 - val_accuracy: 0.5773\n",
            "Epoch 171/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4358 - accuracy: 0.8059 - val_loss: 0.5054 - val_accuracy: 0.6995\n",
            "Epoch 172/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4354 - accuracy: 0.8048 - val_loss: 0.5302 - val_accuracy: 0.6598\n",
            "Epoch 173/500\n",
            "78/78 [==============================] - 1s 11ms/step - loss: 0.4394 - accuracy: 0.8056 - val_loss: 0.5470 - val_accuracy: 0.6428\n",
            "Epoch 174/500\n",
            "78/78 [==============================] - 1s 15ms/step - loss: 0.4352 - accuracy: 0.8030 - val_loss: 0.5162 - val_accuracy: 0.7180\n",
            "Epoch 175/500\n",
            "78/78 [==============================] - 1s 15ms/step - loss: 0.4276 - accuracy: 0.8069 - val_loss: 0.4634 - val_accuracy: 0.7227\n",
            "Epoch 176/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4512 - accuracy: 0.7996 - val_loss: 0.5984 - val_accuracy: 0.6304\n",
            "Epoch 177/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4277 - accuracy: 0.8101 - val_loss: 0.5527 - val_accuracy: 0.6526\n",
            "Epoch 178/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4386 - accuracy: 0.7993 - val_loss: 0.5244 - val_accuracy: 0.6732\n",
            "Epoch 179/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4283 - accuracy: 0.8164 - val_loss: 0.4689 - val_accuracy: 0.7253\n",
            "Epoch 180/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4273 - accuracy: 0.8090 - val_loss: 0.5227 - val_accuracy: 0.6670\n",
            "Epoch 181/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4298 - accuracy: 0.8091 - val_loss: 0.5783 - val_accuracy: 0.6191\n",
            "Epoch 182/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4324 - accuracy: 0.8047 - val_loss: 0.4934 - val_accuracy: 0.6505\n",
            "Epoch 183/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4340 - accuracy: 0.8081 - val_loss: 0.4852 - val_accuracy: 0.7196\n",
            "Epoch 184/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4323 - accuracy: 0.8063 - val_loss: 0.6262 - val_accuracy: 0.5933\n",
            "Epoch 185/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4319 - accuracy: 0.8037 - val_loss: 0.5372 - val_accuracy: 0.6485\n",
            "Epoch 186/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4322 - accuracy: 0.8056 - val_loss: 0.4812 - val_accuracy: 0.6794\n",
            "Epoch 187/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4311 - accuracy: 0.8078 - val_loss: 0.4930 - val_accuracy: 0.7840\n",
            "Epoch 188/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4317 - accuracy: 0.8079 - val_loss: 0.5841 - val_accuracy: 0.6603\n",
            "Epoch 189/500\n",
            "78/78 [==============================] - 1s 13ms/step - loss: 0.4351 - accuracy: 0.8024 - val_loss: 0.6251 - val_accuracy: 0.6072\n",
            "Epoch 190/500\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.4433 - accuracy: 0.7954 - val_loss: 0.5318 - val_accuracy: 0.6979\n",
            "Epoch 191/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4322 - accuracy: 0.8077 - val_loss: 0.4753 - val_accuracy: 0.7088\n",
            "Epoch 192/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4314 - accuracy: 0.8091 - val_loss: 0.5786 - val_accuracy: 0.6887\n",
            "Epoch 193/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4293 - accuracy: 0.8108 - val_loss: 0.5328 - val_accuracy: 0.6433\n",
            "Epoch 194/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4294 - accuracy: 0.8074 - val_loss: 0.4903 - val_accuracy: 0.7222\n",
            "Epoch 195/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4283 - accuracy: 0.8113 - val_loss: 0.5086 - val_accuracy: 0.7046\n",
            "Epoch 196/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4342 - accuracy: 0.8113 - val_loss: 0.4486 - val_accuracy: 0.7649\n",
            "Epoch 197/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4326 - accuracy: 0.8127 - val_loss: 0.5130 - val_accuracy: 0.7356\n",
            "Epoch 198/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4298 - accuracy: 0.8085 - val_loss: 0.5379 - val_accuracy: 0.6706\n",
            "Epoch 199/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4281 - accuracy: 0.8097 - val_loss: 0.4680 - val_accuracy: 0.7330\n",
            "Epoch 200/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4248 - accuracy: 0.8118 - val_loss: 0.5513 - val_accuracy: 0.6892\n",
            "Epoch 201/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4244 - accuracy: 0.8101 - val_loss: 0.5038 - val_accuracy: 0.6686\n",
            "Epoch 202/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4306 - accuracy: 0.8097 - val_loss: 0.5390 - val_accuracy: 0.6789\n",
            "Epoch 203/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4320 - accuracy: 0.8074 - val_loss: 0.5501 - val_accuracy: 0.6665\n",
            "Epoch 204/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4312 - accuracy: 0.8109 - val_loss: 0.5734 - val_accuracy: 0.6598\n",
            "Epoch 205/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4385 - accuracy: 0.8003 - val_loss: 0.4494 - val_accuracy: 0.7072\n",
            "Epoch 206/500\n",
            "78/78 [==============================] - 1s 14ms/step - loss: 0.4300 - accuracy: 0.8127 - val_loss: 0.4964 - val_accuracy: 0.7242\n",
            "Epoch 207/500\n",
            "78/78 [==============================] - 1s 15ms/step - loss: 0.4321 - accuracy: 0.8131 - val_loss: 0.5848 - val_accuracy: 0.6918\n",
            "Epoch 208/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4355 - accuracy: 0.8115 - val_loss: 0.5496 - val_accuracy: 0.6907\n",
            "Epoch 209/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4394 - accuracy: 0.8032 - val_loss: 0.4642 - val_accuracy: 0.7263\n",
            "Epoch 210/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4395 - accuracy: 0.8032 - val_loss: 0.5515 - val_accuracy: 0.6680\n",
            "Epoch 211/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4282 - accuracy: 0.8073 - val_loss: 0.5341 - val_accuracy: 0.6753\n",
            "Epoch 212/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4305 - accuracy: 0.8094 - val_loss: 0.5875 - val_accuracy: 0.6521\n",
            "Epoch 213/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4337 - accuracy: 0.8057 - val_loss: 0.5069 - val_accuracy: 0.6773\n",
            "Epoch 214/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4269 - accuracy: 0.8140 - val_loss: 0.4773 - val_accuracy: 0.7634\n",
            "Epoch 215/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4326 - accuracy: 0.8095 - val_loss: 0.5765 - val_accuracy: 0.5954\n",
            "Epoch 216/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4361 - accuracy: 0.8003 - val_loss: 0.5015 - val_accuracy: 0.6959\n",
            "Epoch 217/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4332 - accuracy: 0.8055 - val_loss: 0.4847 - val_accuracy: 0.6964\n",
            "Epoch 218/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4303 - accuracy: 0.8096 - val_loss: 0.5059 - val_accuracy: 0.6845\n",
            "Epoch 219/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4197 - accuracy: 0.8183 - val_loss: 0.5048 - val_accuracy: 0.6820\n",
            "Epoch 220/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4256 - accuracy: 0.8078 - val_loss: 0.5749 - val_accuracy: 0.6340\n",
            "Epoch 221/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4267 - accuracy: 0.8099 - val_loss: 0.5124 - val_accuracy: 0.7113\n",
            "Epoch 222/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4277 - accuracy: 0.8108 - val_loss: 0.5131 - val_accuracy: 0.6809\n",
            "Epoch 223/500\n",
            "78/78 [==============================] - 1s 13ms/step - loss: 0.4288 - accuracy: 0.8115 - val_loss: 0.5584 - val_accuracy: 0.6330\n",
            "Epoch 224/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4327 - accuracy: 0.8081 - val_loss: 0.5128 - val_accuracy: 0.6861\n",
            "Epoch 225/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4358 - accuracy: 0.8039 - val_loss: 0.6366 - val_accuracy: 0.6113\n",
            "Epoch 226/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4346 - accuracy: 0.8038 - val_loss: 0.5054 - val_accuracy: 0.6809\n",
            "Epoch 227/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4307 - accuracy: 0.8099 - val_loss: 0.5163 - val_accuracy: 0.7258\n",
            "Epoch 228/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4256 - accuracy: 0.8100 - val_loss: 0.4687 - val_accuracy: 0.7309\n",
            "Epoch 229/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4301 - accuracy: 0.8126 - val_loss: 0.4229 - val_accuracy: 0.7531\n",
            "Epoch 230/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4275 - accuracy: 0.8152 - val_loss: 0.5542 - val_accuracy: 0.6649\n",
            "Epoch 231/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4243 - accuracy: 0.8121 - val_loss: 0.4881 - val_accuracy: 0.6557\n",
            "Epoch 232/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4384 - accuracy: 0.8032 - val_loss: 0.4349 - val_accuracy: 0.7773\n",
            "Epoch 233/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4309 - accuracy: 0.8130 - val_loss: 0.4667 - val_accuracy: 0.7340\n",
            "Epoch 234/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4232 - accuracy: 0.8131 - val_loss: 0.6084 - val_accuracy: 0.6820\n",
            "Epoch 235/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4271 - accuracy: 0.8136 - val_loss: 0.5778 - val_accuracy: 0.6490\n",
            "Epoch 236/500\n",
            "78/78 [==============================] - 1s 11ms/step - loss: 0.4394 - accuracy: 0.8043 - val_loss: 0.5147 - val_accuracy: 0.7160\n",
            "Epoch 237/500\n",
            "78/78 [==============================] - 1s 15ms/step - loss: 0.4406 - accuracy: 0.8090 - val_loss: 0.5403 - val_accuracy: 0.6345\n",
            "Epoch 238/500\n",
            "78/78 [==============================] - 1s 14ms/step - loss: 0.4357 - accuracy: 0.8052 - val_loss: 0.6249 - val_accuracy: 0.6155\n",
            "Epoch 239/500\n",
            "78/78 [==============================] - 1s 13ms/step - loss: 0.4306 - accuracy: 0.8087 - val_loss: 0.5583 - val_accuracy: 0.6990\n",
            "Epoch 240/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4354 - accuracy: 0.8050 - val_loss: 0.5088 - val_accuracy: 0.7031\n",
            "Epoch 241/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4291 - accuracy: 0.8090 - val_loss: 0.4955 - val_accuracy: 0.7062\n",
            "Epoch 242/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4324 - accuracy: 0.8037 - val_loss: 0.5172 - val_accuracy: 0.6881\n",
            "Epoch 243/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4260 - accuracy: 0.8076 - val_loss: 0.5762 - val_accuracy: 0.6268\n",
            "Epoch 244/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4324 - accuracy: 0.8052 - val_loss: 0.5270 - val_accuracy: 0.7103\n",
            "Epoch 245/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4230 - accuracy: 0.8085 - val_loss: 0.6708 - val_accuracy: 0.6237\n",
            "Epoch 246/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4321 - accuracy: 0.8090 - val_loss: 0.4879 - val_accuracy: 0.7247\n",
            "Epoch 247/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4302 - accuracy: 0.8096 - val_loss: 0.4656 - val_accuracy: 0.7134\n",
            "Epoch 248/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4252 - accuracy: 0.8072 - val_loss: 0.6099 - val_accuracy: 0.6536\n",
            "Epoch 249/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4379 - accuracy: 0.8055 - val_loss: 0.4944 - val_accuracy: 0.7222\n",
            "Epoch 250/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4380 - accuracy: 0.8083 - val_loss: 0.5656 - val_accuracy: 0.6686\n",
            "Epoch 251/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4278 - accuracy: 0.8068 - val_loss: 0.4684 - val_accuracy: 0.7026\n",
            "Epoch 252/500\n",
            "78/78 [==============================] - 1s 14ms/step - loss: 0.4334 - accuracy: 0.8103 - val_loss: 0.5153 - val_accuracy: 0.6572\n",
            "Epoch 253/500\n",
            "78/78 [==============================] - 1s 14ms/step - loss: 0.4302 - accuracy: 0.8074 - val_loss: 0.4883 - val_accuracy: 0.7242\n",
            "Epoch 254/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4294 - accuracy: 0.8122 - val_loss: 0.4815 - val_accuracy: 0.7041\n",
            "Epoch 255/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4337 - accuracy: 0.8113 - val_loss: 0.5904 - val_accuracy: 0.5979\n",
            "Epoch 256/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4519 - accuracy: 0.7918 - val_loss: 0.5179 - val_accuracy: 0.7485\n",
            "Epoch 257/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4484 - accuracy: 0.8057 - val_loss: 0.5483 - val_accuracy: 0.6912\n",
            "Epoch 258/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4303 - accuracy: 0.8085 - val_loss: 0.5020 - val_accuracy: 0.7015\n",
            "Epoch 259/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4319 - accuracy: 0.8110 - val_loss: 0.4890 - val_accuracy: 0.7515\n",
            "Epoch 260/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4286 - accuracy: 0.8148 - val_loss: 0.5393 - val_accuracy: 0.7191\n",
            "Epoch 261/500\n",
            "78/78 [==============================] - 1s 11ms/step - loss: 0.4243 - accuracy: 0.8119 - val_loss: 0.5777 - val_accuracy: 0.6515\n",
            "Epoch 262/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4316 - accuracy: 0.8087 - val_loss: 0.4346 - val_accuracy: 0.7433\n",
            "Epoch 263/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4757 - accuracy: 0.8059 - val_loss: 0.5339 - val_accuracy: 0.7041\n",
            "Epoch 264/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4498 - accuracy: 0.8092 - val_loss: 0.5577 - val_accuracy: 0.6531\n",
            "Epoch 265/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4423 - accuracy: 0.8087 - val_loss: 0.4757 - val_accuracy: 0.7423\n",
            "Epoch 266/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4348 - accuracy: 0.8128 - val_loss: 0.6475 - val_accuracy: 0.5974\n",
            "Epoch 267/500\n",
            "78/78 [==============================] - 1s 11ms/step - loss: 0.4427 - accuracy: 0.8050 - val_loss: 0.5263 - val_accuracy: 0.6624\n",
            "Epoch 268/500\n",
            "78/78 [==============================] - 1s 15ms/step - loss: 0.4320 - accuracy: 0.8100 - val_loss: 0.5326 - val_accuracy: 0.6840\n",
            "Epoch 269/500\n",
            "78/78 [==============================] - 1s 15ms/step - loss: 0.4358 - accuracy: 0.8097 - val_loss: 0.4984 - val_accuracy: 0.6933\n",
            "Epoch 270/500\n",
            "78/78 [==============================] - 1s 15ms/step - loss: 0.4432 - accuracy: 0.8057 - val_loss: 0.5313 - val_accuracy: 0.7021\n",
            "Epoch 271/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4428 - accuracy: 0.8059 - val_loss: 0.5770 - val_accuracy: 0.6526\n",
            "Epoch 272/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4224 - accuracy: 0.8123 - val_loss: 0.5866 - val_accuracy: 0.6593\n",
            "Epoch 273/500\n",
            "78/78 [==============================] - 1s 11ms/step - loss: 0.4328 - accuracy: 0.8095 - val_loss: 0.5350 - val_accuracy: 0.6572\n",
            "Epoch 274/500\n",
            "78/78 [==============================] - 1s 11ms/step - loss: 0.4349 - accuracy: 0.8060 - val_loss: 0.4596 - val_accuracy: 0.7629\n",
            "Epoch 275/500\n",
            "78/78 [==============================] - 1s 11ms/step - loss: 0.4353 - accuracy: 0.8141 - val_loss: 0.4787 - val_accuracy: 0.7804\n",
            "Epoch 276/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4318 - accuracy: 0.8112 - val_loss: 0.5604 - val_accuracy: 0.6830\n",
            "Epoch 277/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4392 - accuracy: 0.8015 - val_loss: 0.5053 - val_accuracy: 0.7381\n",
            "Epoch 278/500\n",
            "78/78 [==============================] - 1s 11ms/step - loss: 0.4348 - accuracy: 0.8128 - val_loss: 0.5966 - val_accuracy: 0.6387\n",
            "Epoch 279/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4284 - accuracy: 0.8020 - val_loss: 0.5513 - val_accuracy: 0.6861\n",
            "Epoch 280/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4259 - accuracy: 0.8148 - val_loss: 0.6000 - val_accuracy: 0.6402\n",
            "Epoch 281/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4405 - accuracy: 0.8057 - val_loss: 0.5785 - val_accuracy: 0.6742\n",
            "Epoch 282/500\n",
            "78/78 [==============================] - 1s 11ms/step - loss: 0.4304 - accuracy: 0.8103 - val_loss: 0.6032 - val_accuracy: 0.5799\n",
            "Epoch 283/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4301 - accuracy: 0.8055 - val_loss: 0.4336 - val_accuracy: 0.7521\n",
            "Epoch 284/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4348 - accuracy: 0.8095 - val_loss: 0.4829 - val_accuracy: 0.6706\n",
            "Epoch 285/500\n",
            "78/78 [==============================] - 1s 12ms/step - loss: 0.4386 - accuracy: 0.8041 - val_loss: 0.5086 - val_accuracy: 0.6985\n",
            "Epoch 286/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4226 - accuracy: 0.8106 - val_loss: 0.4728 - val_accuracy: 0.7454\n",
            "Epoch 287/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4285 - accuracy: 0.8092 - val_loss: 0.5896 - val_accuracy: 0.6314\n",
            "Epoch 288/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4276 - accuracy: 0.8150 - val_loss: 0.5200 - val_accuracy: 0.7387\n",
            "Epoch 289/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4298 - accuracy: 0.8092 - val_loss: 0.6137 - val_accuracy: 0.6536\n",
            "Epoch 290/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4288 - accuracy: 0.8088 - val_loss: 0.5450 - val_accuracy: 0.6536\n",
            "Epoch 291/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4286 - accuracy: 0.8123 - val_loss: 0.5364 - val_accuracy: 0.6851\n",
            "Epoch 292/500\n",
            "78/78 [==============================] - 1s 11ms/step - loss: 0.4296 - accuracy: 0.8139 - val_loss: 0.5686 - val_accuracy: 0.6820\n",
            "Epoch 293/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4272 - accuracy: 0.8134 - val_loss: 0.4833 - val_accuracy: 0.7345\n",
            "Epoch 294/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4319 - accuracy: 0.8067 - val_loss: 0.4778 - val_accuracy: 0.7680\n",
            "Epoch 295/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4319 - accuracy: 0.8104 - val_loss: 0.6191 - val_accuracy: 0.6119\n",
            "Epoch 296/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4333 - accuracy: 0.8101 - val_loss: 0.5112 - val_accuracy: 0.7082\n",
            "Epoch 297/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4214 - accuracy: 0.8095 - val_loss: 0.5115 - val_accuracy: 0.7062\n",
            "Epoch 298/500\n",
            "78/78 [==============================] - 1s 14ms/step - loss: 0.4275 - accuracy: 0.8090 - val_loss: 0.5418 - val_accuracy: 0.6928\n",
            "Epoch 299/500\n",
            "78/78 [==============================] - 1s 15ms/step - loss: 0.4318 - accuracy: 0.8041 - val_loss: 0.5203 - val_accuracy: 0.7093\n",
            "Epoch 300/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4253 - accuracy: 0.8122 - val_loss: 0.5681 - val_accuracy: 0.6314\n",
            "Epoch 301/500\n",
            "78/78 [==============================] - 1s 11ms/step - loss: 0.4333 - accuracy: 0.8060 - val_loss: 0.5907 - val_accuracy: 0.6706\n",
            "Epoch 302/500\n",
            "78/78 [==============================] - 1s 11ms/step - loss: 0.4313 - accuracy: 0.8109 - val_loss: 0.5461 - val_accuracy: 0.7000\n",
            "Epoch 303/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4294 - accuracy: 0.8108 - val_loss: 0.5290 - val_accuracy: 0.7129\n",
            "Epoch 304/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4278 - accuracy: 0.8112 - val_loss: 0.5369 - val_accuracy: 0.7201\n",
            "Epoch 305/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4284 - accuracy: 0.8055 - val_loss: 0.5452 - val_accuracy: 0.6639\n",
            "Epoch 306/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4248 - accuracy: 0.8096 - val_loss: 0.4677 - val_accuracy: 0.7010\n",
            "Epoch 307/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4236 - accuracy: 0.8108 - val_loss: 0.4986 - val_accuracy: 0.7098\n",
            "Epoch 308/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4280 - accuracy: 0.8126 - val_loss: 0.5370 - val_accuracy: 0.6856\n",
            "Epoch 309/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4250 - accuracy: 0.8112 - val_loss: 0.5306 - val_accuracy: 0.6768\n",
            "Epoch 310/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4372 - accuracy: 0.8097 - val_loss: 0.4679 - val_accuracy: 0.6943\n",
            "Epoch 311/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4267 - accuracy: 0.8141 - val_loss: 0.5205 - val_accuracy: 0.6964\n",
            "Epoch 312/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4305 - accuracy: 0.8125 - val_loss: 0.5020 - val_accuracy: 0.7531\n",
            "Epoch 313/500\n",
            "78/78 [==============================] - 1s 13ms/step - loss: 0.4271 - accuracy: 0.8121 - val_loss: 0.5225 - val_accuracy: 0.6495\n",
            "Epoch 314/500\n",
            "78/78 [==============================] - 1s 15ms/step - loss: 0.4254 - accuracy: 0.8141 - val_loss: 0.5790 - val_accuracy: 0.6866\n",
            "Epoch 315/500\n",
            "78/78 [==============================] - 1s 14ms/step - loss: 0.4261 - accuracy: 0.8082 - val_loss: 0.5396 - val_accuracy: 0.6206\n",
            "Epoch 316/500\n",
            "78/78 [==============================] - 1s 11ms/step - loss: 0.4397 - accuracy: 0.8036 - val_loss: 0.6502 - val_accuracy: 0.6366\n",
            "Epoch 317/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4307 - accuracy: 0.8085 - val_loss: 0.5547 - val_accuracy: 0.6495\n",
            "Epoch 318/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4429 - accuracy: 0.8088 - val_loss: 0.4957 - val_accuracy: 0.7356\n",
            "Epoch 319/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4369 - accuracy: 0.8072 - val_loss: 0.5983 - val_accuracy: 0.6562\n",
            "Epoch 320/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4487 - accuracy: 0.8018 - val_loss: 0.5140 - val_accuracy: 0.6732\n",
            "Epoch 321/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4417 - accuracy: 0.8021 - val_loss: 0.5417 - val_accuracy: 0.7351\n",
            "Epoch 322/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4387 - accuracy: 0.8052 - val_loss: 0.4595 - val_accuracy: 0.7139\n",
            "Epoch 323/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4402 - accuracy: 0.8047 - val_loss: 0.5125 - val_accuracy: 0.6835\n",
            "Epoch 324/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4355 - accuracy: 0.8097 - val_loss: 0.4577 - val_accuracy: 0.7397\n",
            "Epoch 325/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4364 - accuracy: 0.8009 - val_loss: 0.5123 - val_accuracy: 0.6778\n",
            "Epoch 326/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4261 - accuracy: 0.8090 - val_loss: 0.5689 - val_accuracy: 0.6716\n",
            "Epoch 327/500\n",
            "78/78 [==============================] - 1s 11ms/step - loss: 0.4254 - accuracy: 0.8131 - val_loss: 0.4769 - val_accuracy: 0.7253\n",
            "Epoch 328/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4287 - accuracy: 0.8135 - val_loss: 0.4461 - val_accuracy: 0.7351\n",
            "Epoch 329/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4375 - accuracy: 0.8096 - val_loss: 0.5646 - val_accuracy: 0.6351\n",
            "Epoch 330/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4279 - accuracy: 0.8144 - val_loss: 0.4998 - val_accuracy: 0.7299\n",
            "Epoch 331/500\n",
            "78/78 [==============================] - 1s 14ms/step - loss: 0.4467 - accuracy: 0.8055 - val_loss: 0.4439 - val_accuracy: 0.7680\n",
            "Epoch 332/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4311 - accuracy: 0.8100 - val_loss: 0.6129 - val_accuracy: 0.6356\n",
            "Epoch 333/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4422 - accuracy: 0.8002 - val_loss: 0.4827 - val_accuracy: 0.7268\n",
            "Epoch 334/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4312 - accuracy: 0.8103 - val_loss: 0.5000 - val_accuracy: 0.6727\n",
            "Epoch 335/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4366 - accuracy: 0.8037 - val_loss: 0.5422 - val_accuracy: 0.6830\n",
            "Epoch 336/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4335 - accuracy: 0.8086 - val_loss: 0.5962 - val_accuracy: 0.6258\n",
            "Epoch 337/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4419 - accuracy: 0.8003 - val_loss: 0.4808 - val_accuracy: 0.7052\n",
            "Epoch 338/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4370 - accuracy: 0.8063 - val_loss: 0.5120 - val_accuracy: 0.6809\n",
            "Epoch 339/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4333 - accuracy: 0.8043 - val_loss: 0.5659 - val_accuracy: 0.6031\n",
            "Epoch 340/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4298 - accuracy: 0.8101 - val_loss: 0.4680 - val_accuracy: 0.7253\n",
            "Epoch 341/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4323 - accuracy: 0.8097 - val_loss: 0.5788 - val_accuracy: 0.5907\n",
            "Epoch 342/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4348 - accuracy: 0.8073 - val_loss: 0.4984 - val_accuracy: 0.7196\n",
            "Epoch 343/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4296 - accuracy: 0.8114 - val_loss: 0.5213 - val_accuracy: 0.6907\n",
            "Epoch 344/500\n",
            "78/78 [==============================] - 1s 15ms/step - loss: 0.4326 - accuracy: 0.8088 - val_loss: 0.5535 - val_accuracy: 0.6655\n",
            "Epoch 345/500\n",
            "78/78 [==============================] - 1s 15ms/step - loss: 0.4326 - accuracy: 0.8119 - val_loss: 0.5767 - val_accuracy: 0.6675\n",
            "Epoch 346/500\n",
            "78/78 [==============================] - 1s 15ms/step - loss: 0.4375 - accuracy: 0.8037 - val_loss: 0.6097 - val_accuracy: 0.6572\n",
            "Epoch 347/500\n",
            "78/78 [==============================] - 1s 11ms/step - loss: 0.4423 - accuracy: 0.8079 - val_loss: 0.6298 - val_accuracy: 0.6799\n",
            "Epoch 348/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4327 - accuracy: 0.8083 - val_loss: 0.5421 - val_accuracy: 0.7155\n",
            "Epoch 349/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4345 - accuracy: 0.8104 - val_loss: 0.6410 - val_accuracy: 0.6546\n",
            "Epoch 350/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4276 - accuracy: 0.8059 - val_loss: 0.5806 - val_accuracy: 0.6985\n",
            "Epoch 351/500\n",
            "78/78 [==============================] - 1s 11ms/step - loss: 0.4296 - accuracy: 0.8100 - val_loss: 0.4978 - val_accuracy: 0.7134\n",
            "Epoch 352/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4271 - accuracy: 0.8118 - val_loss: 0.5292 - val_accuracy: 0.6706\n",
            "Epoch 353/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4221 - accuracy: 0.8168 - val_loss: 0.5358 - val_accuracy: 0.6768\n",
            "Epoch 354/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4236 - accuracy: 0.8128 - val_loss: 0.5819 - val_accuracy: 0.6722\n",
            "Epoch 355/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4282 - accuracy: 0.8132 - val_loss: 0.5724 - val_accuracy: 0.6469\n",
            "Epoch 356/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4259 - accuracy: 0.8110 - val_loss: 0.5404 - val_accuracy: 0.7072\n",
            "Epoch 357/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4318 - accuracy: 0.8072 - val_loss: 0.5011 - val_accuracy: 0.6809\n",
            "Epoch 358/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4295 - accuracy: 0.8114 - val_loss: 0.5312 - val_accuracy: 0.6660\n",
            "Epoch 359/500\n",
            "78/78 [==============================] - 1s 11ms/step - loss: 0.4245 - accuracy: 0.8109 - val_loss: 0.5361 - val_accuracy: 0.6907\n",
            "Epoch 360/500\n",
            "78/78 [==============================] - 1s 14ms/step - loss: 0.4362 - accuracy: 0.8117 - val_loss: 0.5526 - val_accuracy: 0.6294\n",
            "Epoch 361/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4377 - accuracy: 0.8047 - val_loss: 0.5198 - val_accuracy: 0.6526\n",
            "Epoch 362/500\n",
            "78/78 [==============================] - 1s 14ms/step - loss: 0.4318 - accuracy: 0.8043 - val_loss: 0.5645 - val_accuracy: 0.6572\n",
            "Epoch 363/500\n",
            "78/78 [==============================] - 1s 11ms/step - loss: 0.4381 - accuracy: 0.8025 - val_loss: 0.5299 - val_accuracy: 0.6964\n",
            "Epoch 364/500\n",
            "78/78 [==============================] - 1s 11ms/step - loss: 0.4341 - accuracy: 0.8130 - val_loss: 0.5252 - val_accuracy: 0.7072\n",
            "Epoch 365/500\n",
            "78/78 [==============================] - 1s 11ms/step - loss: 0.4504 - accuracy: 0.8061 - val_loss: 0.6444 - val_accuracy: 0.5046\n",
            "Epoch 366/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4485 - accuracy: 0.8056 - val_loss: 0.5675 - val_accuracy: 0.6242\n",
            "Epoch 367/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4353 - accuracy: 0.8083 - val_loss: 0.5908 - val_accuracy: 0.6691\n",
            "Epoch 368/500\n",
            "78/78 [==============================] - 1s 11ms/step - loss: 0.4396 - accuracy: 0.8112 - val_loss: 0.5445 - val_accuracy: 0.6402\n",
            "Epoch 369/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4334 - accuracy: 0.8077 - val_loss: 0.5631 - val_accuracy: 0.6773\n",
            "Epoch 370/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4349 - accuracy: 0.8104 - val_loss: 0.5440 - val_accuracy: 0.7134\n",
            "Epoch 371/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4356 - accuracy: 0.8094 - val_loss: 0.5132 - val_accuracy: 0.6897\n",
            "Epoch 372/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4310 - accuracy: 0.8121 - val_loss: 0.6183 - val_accuracy: 0.6722\n",
            "Epoch 373/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4364 - accuracy: 0.8104 - val_loss: 0.5361 - val_accuracy: 0.6619\n",
            "Epoch 374/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4478 - accuracy: 0.8064 - val_loss: 0.5458 - val_accuracy: 0.6670\n",
            "Epoch 375/500\n",
            "78/78 [==============================] - 1s 15ms/step - loss: 0.4321 - accuracy: 0.8109 - val_loss: 0.6378 - val_accuracy: 0.5969\n",
            "Epoch 376/500\n",
            "78/78 [==============================] - 1s 15ms/step - loss: 0.4265 - accuracy: 0.8104 - val_loss: 0.5178 - val_accuracy: 0.6881\n",
            "Epoch 377/500\n",
            "78/78 [==============================] - 1s 15ms/step - loss: 0.4257 - accuracy: 0.8076 - val_loss: 0.5161 - val_accuracy: 0.6959\n",
            "Epoch 378/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4269 - accuracy: 0.8088 - val_loss: 0.5599 - val_accuracy: 0.6866\n",
            "Epoch 379/500\n",
            "78/78 [==============================] - 1s 11ms/step - loss: 0.4315 - accuracy: 0.8097 - val_loss: 0.4569 - val_accuracy: 0.7603\n",
            "Epoch 380/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4273 - accuracy: 0.8118 - val_loss: 0.5488 - val_accuracy: 0.6402\n",
            "Epoch 381/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4308 - accuracy: 0.8104 - val_loss: 0.4644 - val_accuracy: 0.7160\n",
            "Epoch 382/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4425 - accuracy: 0.8109 - val_loss: 0.4910 - val_accuracy: 0.7160\n",
            "Epoch 383/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4375 - accuracy: 0.7999 - val_loss: 0.5532 - val_accuracy: 0.6278\n",
            "Epoch 384/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4374 - accuracy: 0.7997 - val_loss: 0.4959 - val_accuracy: 0.7046\n",
            "Epoch 385/500\n",
            "78/78 [==============================] - 1s 11ms/step - loss: 0.4314 - accuracy: 0.8078 - val_loss: 0.5207 - val_accuracy: 0.7253\n",
            "Epoch 386/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4270 - accuracy: 0.8091 - val_loss: 0.4766 - val_accuracy: 0.7392\n",
            "Epoch 387/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4346 - accuracy: 0.8103 - val_loss: 0.5404 - val_accuracy: 0.6897\n",
            "Epoch 388/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4339 - accuracy: 0.8117 - val_loss: 0.4758 - val_accuracy: 0.7670\n",
            "Epoch 389/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4373 - accuracy: 0.8086 - val_loss: 0.5572 - val_accuracy: 0.6938\n",
            "Epoch 390/500\n",
            "78/78 [==============================] - 1s 15ms/step - loss: 0.4424 - accuracy: 0.8029 - val_loss: 0.5889 - val_accuracy: 0.6438\n",
            "Epoch 391/500\n",
            "78/78 [==============================] - 1s 15ms/step - loss: 0.4343 - accuracy: 0.8121 - val_loss: 0.5621 - val_accuracy: 0.6753\n",
            "Epoch 392/500\n",
            "78/78 [==============================] - 1s 15ms/step - loss: 0.4394 - accuracy: 0.8070 - val_loss: 0.5457 - val_accuracy: 0.6753\n",
            "Epoch 393/500\n",
            "78/78 [==============================] - 1s 11ms/step - loss: 0.4336 - accuracy: 0.8055 - val_loss: 0.5514 - val_accuracy: 0.7088\n",
            "Epoch 394/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4357 - accuracy: 0.8122 - val_loss: 0.4968 - val_accuracy: 0.7289\n",
            "Epoch 395/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4389 - accuracy: 0.8095 - val_loss: 0.5395 - val_accuracy: 0.7062\n",
            "Epoch 396/500\n",
            "78/78 [==============================] - 1s 11ms/step - loss: 0.4283 - accuracy: 0.8117 - val_loss: 0.5936 - val_accuracy: 0.6629\n",
            "Epoch 397/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4250 - accuracy: 0.8155 - val_loss: 0.4501 - val_accuracy: 0.7773\n",
            "Epoch 398/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4287 - accuracy: 0.8146 - val_loss: 0.5450 - val_accuracy: 0.7093\n",
            "Epoch 399/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4372 - accuracy: 0.8045 - val_loss: 0.5487 - val_accuracy: 0.7191\n",
            "Epoch 400/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4333 - accuracy: 0.8068 - val_loss: 0.5396 - val_accuracy: 0.7242\n",
            "Epoch 401/500\n",
            "78/78 [==============================] - 1s 11ms/step - loss: 0.4419 - accuracy: 0.8048 - val_loss: 0.5321 - val_accuracy: 0.7191\n",
            "Epoch 402/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4315 - accuracy: 0.8109 - val_loss: 0.5641 - val_accuracy: 0.6644\n",
            "Epoch 403/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4368 - accuracy: 0.8081 - val_loss: 0.5188 - val_accuracy: 0.6799\n",
            "Epoch 404/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4358 - accuracy: 0.8046 - val_loss: 0.5125 - val_accuracy: 0.7186\n",
            "Epoch 405/500\n",
            "78/78 [==============================] - 1s 13ms/step - loss: 0.4320 - accuracy: 0.8123 - val_loss: 0.4523 - val_accuracy: 0.7799\n",
            "Epoch 406/500\n",
            "78/78 [==============================] - 1s 14ms/step - loss: 0.4685 - accuracy: 0.8085 - val_loss: 0.5363 - val_accuracy: 0.7031\n",
            "Epoch 407/500\n",
            "78/78 [==============================] - 1s 15ms/step - loss: 0.4339 - accuracy: 0.8077 - val_loss: 0.5511 - val_accuracy: 0.6448\n",
            "Epoch 408/500\n",
            "78/78 [==============================] - 1s 13ms/step - loss: 0.4369 - accuracy: 0.8109 - val_loss: 0.5390 - val_accuracy: 0.6495\n",
            "Epoch 409/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4341 - accuracy: 0.8099 - val_loss: 0.4586 - val_accuracy: 0.7402\n",
            "Epoch 410/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4363 - accuracy: 0.8132 - val_loss: 0.5621 - val_accuracy: 0.6490\n",
            "Epoch 411/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4277 - accuracy: 0.8153 - val_loss: 0.5827 - val_accuracy: 0.6268\n",
            "Epoch 412/500\n",
            "78/78 [==============================] - 1s 11ms/step - loss: 0.4356 - accuracy: 0.8059 - val_loss: 0.5806 - val_accuracy: 0.6747\n",
            "Epoch 413/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4284 - accuracy: 0.8117 - val_loss: 0.5409 - val_accuracy: 0.7134\n",
            "Epoch 414/500\n",
            "78/78 [==============================] - 1s 11ms/step - loss: 0.4350 - accuracy: 0.8110 - val_loss: 0.5250 - val_accuracy: 0.7165\n",
            "Epoch 415/500\n",
            "78/78 [==============================] - 1s 11ms/step - loss: 0.4358 - accuracy: 0.8100 - val_loss: 0.5117 - val_accuracy: 0.6943\n",
            "Epoch 416/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4382 - accuracy: 0.8128 - val_loss: 0.6205 - val_accuracy: 0.6397\n",
            "Epoch 417/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4322 - accuracy: 0.8130 - val_loss: 0.5335 - val_accuracy: 0.7397\n",
            "Epoch 418/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4359 - accuracy: 0.8148 - val_loss: 0.5494 - val_accuracy: 0.6912\n",
            "Epoch 419/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4403 - accuracy: 0.8101 - val_loss: 0.4939 - val_accuracy: 0.7474\n",
            "Epoch 420/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4370 - accuracy: 0.8063 - val_loss: 0.5361 - val_accuracy: 0.6763\n",
            "Epoch 421/500\n",
            "78/78 [==============================] - 1s 15ms/step - loss: 0.4349 - accuracy: 0.8091 - val_loss: 0.5137 - val_accuracy: 0.7196\n",
            "Epoch 422/500\n",
            "78/78 [==============================] - 1s 14ms/step - loss: 0.4401 - accuracy: 0.8110 - val_loss: 0.5846 - val_accuracy: 0.6907\n",
            "Epoch 423/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4347 - accuracy: 0.8139 - val_loss: 0.5070 - val_accuracy: 0.7082\n",
            "Epoch 424/500\n",
            "78/78 [==============================] - 1s 11ms/step - loss: 0.4348 - accuracy: 0.8101 - val_loss: 0.5203 - val_accuracy: 0.7510\n",
            "Epoch 425/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4401 - accuracy: 0.8115 - val_loss: 0.4949 - val_accuracy: 0.7464\n",
            "Epoch 426/500\n",
            "78/78 [==============================] - 1s 11ms/step - loss: 0.4403 - accuracy: 0.8161 - val_loss: 0.4834 - val_accuracy: 0.7747\n",
            "Epoch 427/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4357 - accuracy: 0.8118 - val_loss: 0.5741 - val_accuracy: 0.6897\n",
            "Epoch 428/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4376 - accuracy: 0.8099 - val_loss: 0.5250 - val_accuracy: 0.6639\n",
            "Epoch 429/500\n",
            "78/78 [==============================] - 1s 11ms/step - loss: 0.4332 - accuracy: 0.8108 - val_loss: 0.5701 - val_accuracy: 0.6887\n",
            "Epoch 430/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4382 - accuracy: 0.8078 - val_loss: 0.6531 - val_accuracy: 0.6851\n",
            "Epoch 431/500\n",
            "78/78 [==============================] - 1s 11ms/step - loss: 0.4378 - accuracy: 0.8121 - val_loss: 0.4643 - val_accuracy: 0.6918\n",
            "Epoch 432/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4428 - accuracy: 0.8018 - val_loss: 0.5340 - val_accuracy: 0.7320\n",
            "Epoch 433/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4352 - accuracy: 0.8059 - val_loss: 0.5415 - val_accuracy: 0.7438\n",
            "Epoch 434/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4272 - accuracy: 0.8100 - val_loss: 0.4801 - val_accuracy: 0.7289\n",
            "Epoch 435/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4707 - accuracy: 0.8068 - val_loss: 0.6146 - val_accuracy: 0.6052\n",
            "Epoch 436/500\n",
            "78/78 [==============================] - 1s 14ms/step - loss: 0.4462 - accuracy: 0.8016 - val_loss: 0.5164 - val_accuracy: 0.6418\n",
            "Epoch 437/500\n",
            "78/78 [==============================] - 1s 15ms/step - loss: 0.4411 - accuracy: 0.8046 - val_loss: 0.4898 - val_accuracy: 0.7201\n",
            "Epoch 438/500\n",
            "78/78 [==============================] - 1s 15ms/step - loss: 0.4480 - accuracy: 0.8023 - val_loss: 0.5998 - val_accuracy: 0.6325\n",
            "Epoch 439/500\n",
            "78/78 [==============================] - 1s 12ms/step - loss: 0.4394 - accuracy: 0.8052 - val_loss: 0.5624 - val_accuracy: 0.6428\n",
            "Epoch 440/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4370 - accuracy: 0.8052 - val_loss: 0.5695 - val_accuracy: 0.6794\n",
            "Epoch 441/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4380 - accuracy: 0.8056 - val_loss: 0.5049 - val_accuracy: 0.7397\n",
            "Epoch 442/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4298 - accuracy: 0.8095 - val_loss: 0.4618 - val_accuracy: 0.7479\n",
            "Epoch 443/500\n",
            "78/78 [==============================] - 1s 11ms/step - loss: 0.4308 - accuracy: 0.8137 - val_loss: 0.5709 - val_accuracy: 0.6711\n",
            "Epoch 444/500\n",
            "78/78 [==============================] - 1s 11ms/step - loss: 0.4392 - accuracy: 0.8097 - val_loss: 0.5972 - val_accuracy: 0.6222\n",
            "Epoch 445/500\n",
            "78/78 [==============================] - 1s 11ms/step - loss: 0.4399 - accuracy: 0.8067 - val_loss: 0.6912 - val_accuracy: 0.5985\n",
            "Epoch 446/500\n",
            "78/78 [==============================] - 1s 11ms/step - loss: 0.4442 - accuracy: 0.8064 - val_loss: 0.5319 - val_accuracy: 0.7186\n",
            "Epoch 447/500\n",
            "78/78 [==============================] - 1s 11ms/step - loss: 0.4355 - accuracy: 0.8099 - val_loss: 0.4867 - val_accuracy: 0.7469\n",
            "Epoch 448/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4365 - accuracy: 0.8074 - val_loss: 0.5769 - val_accuracy: 0.6959\n",
            "Epoch 449/500\n",
            "78/78 [==============================] - 1s 11ms/step - loss: 0.4389 - accuracy: 0.8069 - val_loss: 0.5347 - val_accuracy: 0.7438\n",
            "Epoch 450/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4529 - accuracy: 0.8060 - val_loss: 0.5589 - val_accuracy: 0.6923\n",
            "Epoch 451/500\n",
            "78/78 [==============================] - 1s 14ms/step - loss: 0.4476 - accuracy: 0.8106 - val_loss: 0.5634 - val_accuracy: 0.6701\n",
            "Epoch 452/500\n",
            "78/78 [==============================] - 1s 15ms/step - loss: 0.4455 - accuracy: 0.8103 - val_loss: 0.5742 - val_accuracy: 0.6366\n",
            "Epoch 453/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4379 - accuracy: 0.8039 - val_loss: 0.7007 - val_accuracy: 0.5196\n",
            "Epoch 454/500\n",
            "78/78 [==============================] - 1s 13ms/step - loss: 0.4737 - accuracy: 0.8043 - val_loss: 0.5543 - val_accuracy: 0.6464\n",
            "Epoch 455/500\n",
            "78/78 [==============================] - 1s 11ms/step - loss: 0.4656 - accuracy: 0.8072 - val_loss: 0.5532 - val_accuracy: 0.6649\n",
            "Epoch 456/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4401 - accuracy: 0.8091 - val_loss: 0.5980 - val_accuracy: 0.6289\n",
            "Epoch 457/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4475 - accuracy: 0.8055 - val_loss: 0.5570 - val_accuracy: 0.6526\n",
            "Epoch 458/500\n",
            "78/78 [==============================] - 1s 11ms/step - loss: 0.4410 - accuracy: 0.8094 - val_loss: 0.5904 - val_accuracy: 0.6624\n",
            "Epoch 459/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4367 - accuracy: 0.8092 - val_loss: 0.5465 - val_accuracy: 0.6716\n",
            "Epoch 460/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4381 - accuracy: 0.8122 - val_loss: 0.5247 - val_accuracy: 0.7237\n",
            "Epoch 461/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4375 - accuracy: 0.8183 - val_loss: 0.5928 - val_accuracy: 0.6619\n",
            "Epoch 462/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4366 - accuracy: 0.8086 - val_loss: 0.5864 - val_accuracy: 0.6820\n",
            "Epoch 463/500\n",
            "78/78 [==============================] - 1s 11ms/step - loss: 0.4325 - accuracy: 0.8152 - val_loss: 0.5269 - val_accuracy: 0.7335\n",
            "Epoch 464/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4433 - accuracy: 0.8041 - val_loss: 0.6021 - val_accuracy: 0.6103\n",
            "Epoch 465/500\n",
            "78/78 [==============================] - 1s 11ms/step - loss: 0.4317 - accuracy: 0.8132 - val_loss: 0.4883 - val_accuracy: 0.7180\n",
            "Epoch 466/500\n",
            "78/78 [==============================] - 1s 13ms/step - loss: 0.4575 - accuracy: 0.8072 - val_loss: 0.5920 - val_accuracy: 0.6562\n",
            "Epoch 467/500\n",
            "78/78 [==============================] - 1s 15ms/step - loss: 0.4388 - accuracy: 0.8078 - val_loss: 0.5665 - val_accuracy: 0.6954\n",
            "Epoch 468/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4322 - accuracy: 0.8122 - val_loss: 0.6044 - val_accuracy: 0.6485\n",
            "Epoch 469/500\n",
            "78/78 [==============================] - 1s 14ms/step - loss: 0.4349 - accuracy: 0.8153 - val_loss: 0.5406 - val_accuracy: 0.6912\n",
            "Epoch 470/500\n",
            "78/78 [==============================] - 1s 11ms/step - loss: 0.4334 - accuracy: 0.8086 - val_loss: 0.5207 - val_accuracy: 0.7201\n",
            "Epoch 471/500\n",
            "78/78 [==============================] - 1s 11ms/step - loss: 0.4342 - accuracy: 0.8073 - val_loss: 0.4885 - val_accuracy: 0.6706\n",
            "Epoch 472/500\n",
            "78/78 [==============================] - 1s 11ms/step - loss: 0.4368 - accuracy: 0.8086 - val_loss: 0.5507 - val_accuracy: 0.6490\n",
            "Epoch 473/500\n",
            "78/78 [==============================] - 1s 11ms/step - loss: 0.4373 - accuracy: 0.8088 - val_loss: 0.5297 - val_accuracy: 0.7144\n",
            "Epoch 474/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4420 - accuracy: 0.8091 - val_loss: 0.5044 - val_accuracy: 0.6954\n",
            "Epoch 475/500\n",
            "78/78 [==============================] - 1s 11ms/step - loss: 0.4335 - accuracy: 0.8112 - val_loss: 0.5952 - val_accuracy: 0.6572\n",
            "Epoch 476/500\n",
            "78/78 [==============================] - 1s 11ms/step - loss: 0.4390 - accuracy: 0.8067 - val_loss: 0.4931 - val_accuracy: 0.6845\n",
            "Epoch 477/500\n",
            "78/78 [==============================] - 1s 11ms/step - loss: 0.4299 - accuracy: 0.8126 - val_loss: 0.5580 - val_accuracy: 0.6428\n",
            "Epoch 478/500\n",
            "78/78 [==============================] - 1s 11ms/step - loss: 0.4380 - accuracy: 0.8070 - val_loss: 0.5305 - val_accuracy: 0.7495\n",
            "Epoch 479/500\n",
            "78/78 [==============================] - 1s 11ms/step - loss: 0.4306 - accuracy: 0.8122 - val_loss: 0.4950 - val_accuracy: 0.7077\n",
            "Epoch 480/500\n",
            "78/78 [==============================] - 1s 11ms/step - loss: 0.4328 - accuracy: 0.8082 - val_loss: 0.4712 - val_accuracy: 0.7165\n",
            "Epoch 481/500\n",
            "78/78 [==============================] - 1s 14ms/step - loss: 0.4326 - accuracy: 0.8087 - val_loss: 0.5529 - val_accuracy: 0.6964\n",
            "Epoch 482/500\n",
            "78/78 [==============================] - 1s 15ms/step - loss: 0.4312 - accuracy: 0.8085 - val_loss: 0.5433 - val_accuracy: 0.7088\n",
            "Epoch 483/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4359 - accuracy: 0.8042 - val_loss: 0.5237 - val_accuracy: 0.6711\n",
            "Epoch 484/500\n",
            "78/78 [==============================] - 1s 12ms/step - loss: 0.4299 - accuracy: 0.8108 - val_loss: 0.5571 - val_accuracy: 0.6696\n",
            "Epoch 485/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4284 - accuracy: 0.8081 - val_loss: 0.6034 - val_accuracy: 0.6464\n",
            "Epoch 486/500\n",
            "78/78 [==============================] - 1s 11ms/step - loss: 0.4207 - accuracy: 0.8167 - val_loss: 0.5377 - val_accuracy: 0.7041\n",
            "Epoch 487/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4277 - accuracy: 0.8090 - val_loss: 0.5208 - val_accuracy: 0.7325\n",
            "Epoch 488/500\n",
            "78/78 [==============================] - 1s 11ms/step - loss: 0.4376 - accuracy: 0.8055 - val_loss: 0.5960 - val_accuracy: 0.6299\n",
            "Epoch 489/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4304 - accuracy: 0.8081 - val_loss: 0.5200 - val_accuracy: 0.6830\n",
            "Epoch 490/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4293 - accuracy: 0.8067 - val_loss: 0.5139 - val_accuracy: 0.6912\n",
            "Epoch 491/500\n",
            "78/78 [==============================] - 1s 11ms/step - loss: 0.4319 - accuracy: 0.8060 - val_loss: 0.5529 - val_accuracy: 0.6546\n",
            "Epoch 492/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4382 - accuracy: 0.8033 - val_loss: 0.5088 - val_accuracy: 0.6871\n",
            "Epoch 493/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4356 - accuracy: 0.8063 - val_loss: 0.6683 - val_accuracy: 0.7149\n",
            "Epoch 494/500\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4349 - accuracy: 0.8064 - val_loss: 0.5463 - val_accuracy: 0.7144\n",
            "Epoch 495/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4353 - accuracy: 0.8148 - val_loss: 0.4722 - val_accuracy: 0.7237\n",
            "Epoch 496/500\n",
            "78/78 [==============================] - 1s 12ms/step - loss: 0.4278 - accuracy: 0.8149 - val_loss: 0.5401 - val_accuracy: 0.6593\n",
            "Epoch 497/500\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4323 - accuracy: 0.8036 - val_loss: 0.4823 - val_accuracy: 0.7031\n",
            "Epoch 498/500\n",
            "78/78 [==============================] - 1s 15ms/step - loss: 0.4373 - accuracy: 0.8067 - val_loss: 0.5488 - val_accuracy: 0.6495\n",
            "Epoch 499/500\n",
            "78/78 [==============================] - 1s 14ms/step - loss: 0.4303 - accuracy: 0.8076 - val_loss: 0.5123 - val_accuracy: 0.6948\n",
            "Epoch 500/500\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4318 - accuracy: 0.8153 - val_loss: 0.5218 - val_accuracy: 0.7082\n",
            "50/50 [==============================] - 0s 3ms/step - loss: 0.6469 - accuracy: 0.8222\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6468731760978699, 0.8221797347068787]"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Categorical features \n",
        "history_fs_df = pd.DataFrame(history_fs.history)\n"
      ],
      "metadata": {
        "id": "JN6Tr90Bpbk8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report \n",
        "y_predictions_fs= model_fs.predict(X_test_transformed_fs_df)\n",
        "#Convert predictions into boolean values \n",
        "y_predictions_bool_fs = (y_predictions_fs >= 0.5) * 1\n",
        "print(classification_report(y_test_transformed_df, y_predictions_bool_fs))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JDY1QcP9q3FU",
        "outputId": "dc3840b5-f5db-4bfd-e02e-57ae034a8904"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50/50 [==============================] - 0s 3ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.88      0.89      1207\n",
            "           1       0.62      0.65      0.64       362\n",
            "\n",
            "    accuracy                           0.83      1569\n",
            "   macro avg       0.76      0.77      0.76      1569\n",
            "weighted avg       0.83      0.83      0.83      1569\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Get best epoch for selected featues\n",
        "val_accuracy_per_epoch_fs = history_fs.history['val_accuracy'] \n",
        "best_epoch_fs =val_accuracy_per_epoch_fs.index(max(val_accuracy_per_epoch_fs)) + 1\n",
        "print('Best epoch for selected features : ', best_epoch_fs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "baTmOQR-vRnd",
        "outputId": "d480cef9-f1fc-4d33-901e-d9013d0b3e7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best epoch for selected features :  142\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Retrain model using selected features and best epoch\n",
        "history_fs2 = model_fs.fit(X_train_resampled_fs_df, y_train_resampled_df,\n",
        "          validation_split = 0.20,\n",
        "          epochs  = best_epoch_fs,\n",
        "          batch_size = 100,\n",
        "          )\n",
        "#Evaluate the model\n",
        "model_fs.evaluate(X_test_transformed_fs_df, y_test_transformed_df) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dWXlOE8Sv-5W",
        "outputId": "619967ed-05b4-4c0f-da93-94bb2d5e9f7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/142\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4408 - accuracy: 0.8055 - val_loss: 0.5591 - val_accuracy: 0.7562\n",
            "Epoch 2/142\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4392 - accuracy: 0.8033 - val_loss: 0.5890 - val_accuracy: 0.6582\n",
            "Epoch 3/142\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4384 - accuracy: 0.8043 - val_loss: 0.5462 - val_accuracy: 0.7495\n",
            "Epoch 4/142\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4270 - accuracy: 0.8115 - val_loss: 0.6157 - val_accuracy: 0.6907\n",
            "Epoch 5/142\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4260 - accuracy: 0.8131 - val_loss: 0.4923 - val_accuracy: 0.7536\n",
            "Epoch 6/142\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4331 - accuracy: 0.8041 - val_loss: 0.5438 - val_accuracy: 0.7804\n",
            "Epoch 7/142\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4374 - accuracy: 0.8059 - val_loss: 0.5778 - val_accuracy: 0.7211\n",
            "Epoch 8/142\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4306 - accuracy: 0.8033 - val_loss: 0.4935 - val_accuracy: 0.7938\n",
            "Epoch 9/142\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4371 - accuracy: 0.8020 - val_loss: 0.5017 - val_accuracy: 0.7294\n",
            "Epoch 10/142\n",
            "78/78 [==============================] - 1s 11ms/step - loss: 0.4330 - accuracy: 0.8046 - val_loss: 0.5683 - val_accuracy: 0.7438\n",
            "Epoch 11/142\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4248 - accuracy: 0.8074 - val_loss: 0.5750 - val_accuracy: 0.7428\n",
            "Epoch 12/142\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4340 - accuracy: 0.8046 - val_loss: 0.5503 - val_accuracy: 0.7314\n",
            "Epoch 13/142\n",
            "78/78 [==============================] - 1s 12ms/step - loss: 0.4405 - accuracy: 0.8010 - val_loss: 0.5605 - val_accuracy: 0.7918\n",
            "Epoch 14/142\n",
            "78/78 [==============================] - 1s 15ms/step - loss: 0.4272 - accuracy: 0.8063 - val_loss: 0.5014 - val_accuracy: 0.7825\n",
            "Epoch 15/142\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4390 - accuracy: 0.8103 - val_loss: 0.6193 - val_accuracy: 0.6778\n",
            "Epoch 16/142\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4298 - accuracy: 0.8072 - val_loss: 0.5740 - val_accuracy: 0.6985\n",
            "Epoch 17/142\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4287 - accuracy: 0.8052 - val_loss: 0.5643 - val_accuracy: 0.7113\n",
            "Epoch 18/142\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4335 - accuracy: 0.8054 - val_loss: 0.5780 - val_accuracy: 0.7144\n",
            "Epoch 19/142\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4313 - accuracy: 0.8057 - val_loss: 0.5907 - val_accuracy: 0.7046\n",
            "Epoch 20/142\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4365 - accuracy: 0.8095 - val_loss: 0.5883 - val_accuracy: 0.7124\n",
            "Epoch 21/142\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4554 - accuracy: 0.8064 - val_loss: 0.6442 - val_accuracy: 0.6593\n",
            "Epoch 22/142\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4353 - accuracy: 0.8100 - val_loss: 0.5567 - val_accuracy: 0.7031\n",
            "Epoch 23/142\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4349 - accuracy: 0.8061 - val_loss: 0.6407 - val_accuracy: 0.6273\n",
            "Epoch 24/142\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4388 - accuracy: 0.7997 - val_loss: 0.5737 - val_accuracy: 0.6990\n",
            "Epoch 25/142\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4301 - accuracy: 0.8067 - val_loss: 0.5491 - val_accuracy: 0.7464\n",
            "Epoch 26/142\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4413 - accuracy: 0.8086 - val_loss: 0.5252 - val_accuracy: 0.7887\n",
            "Epoch 27/142\n",
            "78/78 [==============================] - 2s 22ms/step - loss: 0.4337 - accuracy: 0.8108 - val_loss: 0.4978 - val_accuracy: 0.7747\n",
            "Epoch 28/142\n",
            "78/78 [==============================] - 2s 20ms/step - loss: 0.4361 - accuracy: 0.8018 - val_loss: 0.6695 - val_accuracy: 0.7134\n",
            "Epoch 29/142\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.4476 - accuracy: 0.8087 - val_loss: 0.5400 - val_accuracy: 0.7495\n",
            "Epoch 30/142\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4385 - accuracy: 0.8064 - val_loss: 0.5670 - val_accuracy: 0.7129\n",
            "Epoch 31/142\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4272 - accuracy: 0.8082 - val_loss: 0.5754 - val_accuracy: 0.6722\n",
            "Epoch 32/142\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4380 - accuracy: 0.8020 - val_loss: 0.5975 - val_accuracy: 0.6758\n",
            "Epoch 33/142\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4346 - accuracy: 0.8059 - val_loss: 0.5786 - val_accuracy: 0.6814\n",
            "Epoch 34/142\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4317 - accuracy: 0.8118 - val_loss: 0.5673 - val_accuracy: 0.7093\n",
            "Epoch 35/142\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4274 - accuracy: 0.8088 - val_loss: 0.4926 - val_accuracy: 0.7165\n",
            "Epoch 36/142\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4340 - accuracy: 0.8070 - val_loss: 0.5369 - val_accuracy: 0.7113\n",
            "Epoch 37/142\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4354 - accuracy: 0.8094 - val_loss: 0.5416 - val_accuracy: 0.7139\n",
            "Epoch 38/142\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4328 - accuracy: 0.8088 - val_loss: 0.5630 - val_accuracy: 0.7206\n",
            "Epoch 39/142\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4260 - accuracy: 0.8055 - val_loss: 0.5902 - val_accuracy: 0.6655\n",
            "Epoch 40/142\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4292 - accuracy: 0.8115 - val_loss: 0.5697 - val_accuracy: 0.6918\n",
            "Epoch 41/142\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4336 - accuracy: 0.8088 - val_loss: 0.6074 - val_accuracy: 0.6639\n",
            "Epoch 42/142\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4317 - accuracy: 0.8108 - val_loss: 0.5582 - val_accuracy: 0.7407\n",
            "Epoch 43/142\n",
            "78/78 [==============================] - 1s 15ms/step - loss: 0.4408 - accuracy: 0.8027 - val_loss: 0.5759 - val_accuracy: 0.6938\n",
            "Epoch 44/142\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.4345 - accuracy: 0.8096 - val_loss: 0.6530 - val_accuracy: 0.6624\n",
            "Epoch 45/142\n",
            "78/78 [==============================] - 1s 13ms/step - loss: 0.4305 - accuracy: 0.8104 - val_loss: 0.5387 - val_accuracy: 0.7469\n",
            "Epoch 46/142\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4288 - accuracy: 0.8061 - val_loss: 0.6039 - val_accuracy: 0.6747\n",
            "Epoch 47/142\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4385 - accuracy: 0.8060 - val_loss: 0.5010 - val_accuracy: 0.7119\n",
            "Epoch 48/142\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4321 - accuracy: 0.8076 - val_loss: 0.5651 - val_accuracy: 0.7381\n",
            "Epoch 49/142\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4391 - accuracy: 0.8064 - val_loss: 0.6709 - val_accuracy: 0.6021\n",
            "Epoch 50/142\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4359 - accuracy: 0.8039 - val_loss: 0.5472 - val_accuracy: 0.7644\n",
            "Epoch 51/142\n",
            "78/78 [==============================] - 1s 11ms/step - loss: 0.4326 - accuracy: 0.8094 - val_loss: 0.5684 - val_accuracy: 0.7108\n",
            "Epoch 52/142\n",
            "78/78 [==============================] - 1s 11ms/step - loss: 0.4292 - accuracy: 0.8099 - val_loss: 0.5863 - val_accuracy: 0.7273\n",
            "Epoch 53/142\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4314 - accuracy: 0.8052 - val_loss: 0.6477 - val_accuracy: 0.6835\n",
            "Epoch 54/142\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4314 - accuracy: 0.8082 - val_loss: 0.5431 - val_accuracy: 0.7186\n",
            "Epoch 55/142\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4332 - accuracy: 0.8042 - val_loss: 0.5895 - val_accuracy: 0.6773\n",
            "Epoch 56/142\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4360 - accuracy: 0.8074 - val_loss: 0.5843 - val_accuracy: 0.6773\n",
            "Epoch 57/142\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4314 - accuracy: 0.8096 - val_loss: 0.5108 - val_accuracy: 0.7216\n",
            "Epoch 58/142\n",
            "78/78 [==============================] - 1s 13ms/step - loss: 0.4334 - accuracy: 0.8068 - val_loss: 0.5711 - val_accuracy: 0.6923\n",
            "Epoch 59/142\n",
            "78/78 [==============================] - 1s 15ms/step - loss: 0.4347 - accuracy: 0.8078 - val_loss: 0.5598 - val_accuracy: 0.6840\n",
            "Epoch 60/142\n",
            "78/78 [==============================] - 1s 15ms/step - loss: 0.4341 - accuracy: 0.8076 - val_loss: 0.5259 - val_accuracy: 0.7356\n",
            "Epoch 61/142\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4404 - accuracy: 0.8060 - val_loss: 0.6270 - val_accuracy: 0.6170\n",
            "Epoch 62/142\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4396 - accuracy: 0.7978 - val_loss: 0.5220 - val_accuracy: 0.7093\n",
            "Epoch 63/142\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4439 - accuracy: 0.8078 - val_loss: 0.5642 - val_accuracy: 0.7289\n",
            "Epoch 64/142\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4396 - accuracy: 0.8079 - val_loss: 0.5239 - val_accuracy: 0.7433\n",
            "Epoch 65/142\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4365 - accuracy: 0.8051 - val_loss: 0.6351 - val_accuracy: 0.6845\n",
            "Epoch 66/142\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4313 - accuracy: 0.8105 - val_loss: 0.5654 - val_accuracy: 0.7304\n",
            "Epoch 67/142\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4301 - accuracy: 0.8083 - val_loss: 0.6129 - val_accuracy: 0.6902\n",
            "Epoch 68/142\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4336 - accuracy: 0.8086 - val_loss: 0.5532 - val_accuracy: 0.7113\n",
            "Epoch 69/142\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4333 - accuracy: 0.8086 - val_loss: 0.6379 - val_accuracy: 0.7284\n",
            "Epoch 70/142\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4359 - accuracy: 0.8122 - val_loss: 0.6056 - val_accuracy: 0.6933\n",
            "Epoch 71/142\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4292 - accuracy: 0.8042 - val_loss: 0.6084 - val_accuracy: 0.6789\n",
            "Epoch 72/142\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4378 - accuracy: 0.8069 - val_loss: 0.5473 - val_accuracy: 0.7108\n",
            "Epoch 73/142\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4280 - accuracy: 0.8070 - val_loss: 0.5574 - val_accuracy: 0.6794\n",
            "Epoch 74/142\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4318 - accuracy: 0.8042 - val_loss: 0.6171 - val_accuracy: 0.7057\n",
            "Epoch 75/142\n",
            "78/78 [==============================] - 1s 15ms/step - loss: 0.4310 - accuracy: 0.8079 - val_loss: 0.5194 - val_accuracy: 0.7515\n",
            "Epoch 76/142\n",
            "78/78 [==============================] - 1s 13ms/step - loss: 0.4449 - accuracy: 0.7975 - val_loss: 0.6035 - val_accuracy: 0.6299\n",
            "Epoch 77/142\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4400 - accuracy: 0.7971 - val_loss: 0.5763 - val_accuracy: 0.6814\n",
            "Epoch 78/142\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4396 - accuracy: 0.8039 - val_loss: 0.4864 - val_accuracy: 0.7825\n",
            "Epoch 79/142\n",
            "78/78 [==============================] - 1s 11ms/step - loss: 0.4312 - accuracy: 0.8092 - val_loss: 0.5702 - val_accuracy: 0.7098\n",
            "Epoch 80/142\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4318 - accuracy: 0.8106 - val_loss: 0.5586 - val_accuracy: 0.6990\n",
            "Epoch 81/142\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4394 - accuracy: 0.7999 - val_loss: 0.5962 - val_accuracy: 0.6856\n",
            "Epoch 82/142\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4377 - accuracy: 0.8048 - val_loss: 0.6397 - val_accuracy: 0.6820\n",
            "Epoch 83/142\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4334 - accuracy: 0.8085 - val_loss: 0.5145 - val_accuracy: 0.7397\n",
            "Epoch 84/142\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4321 - accuracy: 0.8103 - val_loss: 0.5402 - val_accuracy: 0.7706\n",
            "Epoch 85/142\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4391 - accuracy: 0.8047 - val_loss: 0.5556 - val_accuracy: 0.7412\n",
            "Epoch 86/142\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4454 - accuracy: 0.8057 - val_loss: 0.5962 - val_accuracy: 0.7103\n",
            "Epoch 87/142\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4282 - accuracy: 0.8072 - val_loss: 0.5985 - val_accuracy: 0.6830\n",
            "Epoch 88/142\n",
            "78/78 [==============================] - 1s 11ms/step - loss: 0.4236 - accuracy: 0.8103 - val_loss: 0.5915 - val_accuracy: 0.6701\n",
            "Epoch 89/142\n",
            "78/78 [==============================] - 1s 14ms/step - loss: 0.4278 - accuracy: 0.8063 - val_loss: 0.5292 - val_accuracy: 0.7459\n",
            "Epoch 90/142\n",
            "78/78 [==============================] - 1s 15ms/step - loss: 0.4368 - accuracy: 0.8052 - val_loss: 0.5741 - val_accuracy: 0.7216\n",
            "Epoch 91/142\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4371 - accuracy: 0.8042 - val_loss: 0.6142 - val_accuracy: 0.6593\n",
            "Epoch 92/142\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4306 - accuracy: 0.8074 - val_loss: 0.5764 - val_accuracy: 0.7072\n",
            "Epoch 93/142\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4398 - accuracy: 0.8039 - val_loss: 0.5429 - val_accuracy: 0.7268\n",
            "Epoch 94/142\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4315 - accuracy: 0.8104 - val_loss: 0.6872 - val_accuracy: 0.6510\n",
            "Epoch 95/142\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4269 - accuracy: 0.8101 - val_loss: 0.5690 - val_accuracy: 0.7057\n",
            "Epoch 96/142\n",
            "78/78 [==============================] - 1s 11ms/step - loss: 0.4296 - accuracy: 0.8046 - val_loss: 0.4595 - val_accuracy: 0.7773\n",
            "Epoch 97/142\n",
            "78/78 [==============================] - 1s 11ms/step - loss: 0.4415 - accuracy: 0.8104 - val_loss: 0.5750 - val_accuracy: 0.6634\n",
            "Epoch 98/142\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4387 - accuracy: 0.8007 - val_loss: 0.6445 - val_accuracy: 0.5912\n",
            "Epoch 99/142\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4384 - accuracy: 0.8021 - val_loss: 0.5354 - val_accuracy: 0.7479\n",
            "Epoch 100/142\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4386 - accuracy: 0.8068 - val_loss: 0.5079 - val_accuracy: 0.7119\n",
            "Epoch 101/142\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4329 - accuracy: 0.8029 - val_loss: 0.5878 - val_accuracy: 0.6871\n",
            "Epoch 102/142\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4420 - accuracy: 0.8011 - val_loss: 0.6054 - val_accuracy: 0.7015\n",
            "Epoch 103/142\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4413 - accuracy: 0.8039 - val_loss: 0.5015 - val_accuracy: 0.7660\n",
            "Epoch 104/142\n",
            "78/78 [==============================] - 1s 12ms/step - loss: 0.4311 - accuracy: 0.8101 - val_loss: 0.5523 - val_accuracy: 0.7186\n",
            "Epoch 105/142\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4391 - accuracy: 0.8070 - val_loss: 0.5761 - val_accuracy: 0.7036\n",
            "Epoch 106/142\n",
            "78/78 [==============================] - 1s 17ms/step - loss: 0.4354 - accuracy: 0.8083 - val_loss: 0.6068 - val_accuracy: 0.6686\n",
            "Epoch 107/142\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4319 - accuracy: 0.8094 - val_loss: 0.5382 - val_accuracy: 0.7546\n",
            "Epoch 108/142\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4256 - accuracy: 0.8173 - val_loss: 0.5151 - val_accuracy: 0.7500\n",
            "Epoch 109/142\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4347 - accuracy: 0.8021 - val_loss: 0.6237 - val_accuracy: 0.6871\n",
            "Epoch 110/142\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4348 - accuracy: 0.8081 - val_loss: 0.5701 - val_accuracy: 0.7139\n",
            "Epoch 111/142\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4343 - accuracy: 0.8067 - val_loss: 0.5859 - val_accuracy: 0.6835\n",
            "Epoch 112/142\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4264 - accuracy: 0.8136 - val_loss: 0.5259 - val_accuracy: 0.7722\n",
            "Epoch 113/142\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4378 - accuracy: 0.8047 - val_loss: 0.5859 - val_accuracy: 0.6686\n",
            "Epoch 114/142\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4395 - accuracy: 0.8011 - val_loss: 0.5862 - val_accuracy: 0.6835\n",
            "Epoch 115/142\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4306 - accuracy: 0.8047 - val_loss: 0.5635 - val_accuracy: 0.7222\n",
            "Epoch 116/142\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4362 - accuracy: 0.8027 - val_loss: 0.5969 - val_accuracy: 0.6959\n",
            "Epoch 117/142\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4342 - accuracy: 0.8041 - val_loss: 0.5589 - val_accuracy: 0.7448\n",
            "Epoch 118/142\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4387 - accuracy: 0.8018 - val_loss: 0.6515 - val_accuracy: 0.6608\n",
            "Epoch 119/142\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4315 - accuracy: 0.8103 - val_loss: 0.5727 - val_accuracy: 0.7330\n",
            "Epoch 120/142\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4312 - accuracy: 0.8110 - val_loss: 0.5500 - val_accuracy: 0.7046\n",
            "Epoch 121/142\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4361 - accuracy: 0.8028 - val_loss: 0.4774 - val_accuracy: 0.7789\n",
            "Epoch 122/142\n",
            "78/78 [==============================] - 1s 13ms/step - loss: 0.4343 - accuracy: 0.8041 - val_loss: 0.5695 - val_accuracy: 0.7139\n",
            "Epoch 123/142\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4427 - accuracy: 0.8041 - val_loss: 0.5011 - val_accuracy: 0.7825\n",
            "Epoch 124/142\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4293 - accuracy: 0.8095 - val_loss: 0.5077 - val_accuracy: 0.7407\n",
            "Epoch 125/142\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4310 - accuracy: 0.8046 - val_loss: 0.5400 - val_accuracy: 0.7356\n",
            "Epoch 126/142\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4349 - accuracy: 0.8059 - val_loss: 0.5415 - val_accuracy: 0.7758\n",
            "Epoch 127/142\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4271 - accuracy: 0.8132 - val_loss: 0.4808 - val_accuracy: 0.8031\n",
            "Epoch 128/142\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4321 - accuracy: 0.8057 - val_loss: 0.5537 - val_accuracy: 0.7613\n",
            "Epoch 129/142\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4460 - accuracy: 0.7985 - val_loss: 0.5896 - val_accuracy: 0.6866\n",
            "Epoch 130/142\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4359 - accuracy: 0.8007 - val_loss: 0.5251 - val_accuracy: 0.7747\n",
            "Epoch 131/142\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4316 - accuracy: 0.8088 - val_loss: 0.5663 - val_accuracy: 0.7407\n",
            "Epoch 132/142\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4371 - accuracy: 0.8023 - val_loss: 0.5442 - val_accuracy: 0.7464\n",
            "Epoch 133/142\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4385 - accuracy: 0.8057 - val_loss: 0.5460 - val_accuracy: 0.7773\n",
            "Epoch 134/142\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4334 - accuracy: 0.8087 - val_loss: 0.5607 - val_accuracy: 0.7139\n",
            "Epoch 135/142\n",
            "78/78 [==============================] - 1s 12ms/step - loss: 0.4351 - accuracy: 0.8060 - val_loss: 0.5864 - val_accuracy: 0.6876\n",
            "Epoch 136/142\n",
            "78/78 [==============================] - 1s 15ms/step - loss: 0.4352 - accuracy: 0.8097 - val_loss: 0.6098 - val_accuracy: 0.7057\n",
            "Epoch 137/142\n",
            "78/78 [==============================] - 1s 16ms/step - loss: 0.4257 - accuracy: 0.8100 - val_loss: 0.5157 - val_accuracy: 0.8010\n",
            "Epoch 138/142\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4331 - accuracy: 0.8060 - val_loss: 0.5531 - val_accuracy: 0.7598\n",
            "Epoch 139/142\n",
            "78/78 [==============================] - 1s 9ms/step - loss: 0.4311 - accuracy: 0.8057 - val_loss: 0.5071 - val_accuracy: 0.7768\n",
            "Epoch 140/142\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4307 - accuracy: 0.8078 - val_loss: 0.5623 - val_accuracy: 0.7541\n",
            "Epoch 141/142\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4295 - accuracy: 0.8126 - val_loss: 0.5457 - val_accuracy: 0.7593\n",
            "Epoch 142/142\n",
            "78/78 [==============================] - 1s 10ms/step - loss: 0.4263 - accuracy: 0.8077 - val_loss: 0.5719 - val_accuracy: 0.7201\n",
            "50/50 [==============================] - 0s 2ms/step - loss: 1.6949 - accuracy: 0.8203\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.6948686838150024, 0.8202676773071289]"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNn0mqMDqVppu8I5w8oUym1",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}